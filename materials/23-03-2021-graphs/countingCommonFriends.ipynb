{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 30 pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"natasha pritykovskaya Link Prediction app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"natasha pritykovskaya Spark Dataframe app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-3.newprolab.com:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>natasha pritykovskaya Spark Dataframe app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8c8813ff60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = \"/lectures/lecture04/trainGraph\"\n",
    "usersToPredictPath = \"/lectures/lecture04/prediction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType(fields=[\n",
    "    StructField(\"user\", IntegerType()),\n",
    "    StructField(\"friendsString\", StringType())\n",
    "])\n",
    "\n",
    "data = spark.read.format(\"csv\") \\\n",
    "        .schema(schema) \\\n",
    "        .option(\"delimiter\", \"\\t\") \\\n",
    "        .load(graphPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|user|       friendsString|\n",
      "+----+--------------------+\n",
      "|1654|{(14082,0),(27448...|\n",
      "|3030|{(3050,0),(5466,0...|\n",
      "|4150|{(4698,0),(48091,...|\n",
      "|5750|{(1600,1024),(426...|\n",
      "|5942|{(11729,0),(53391...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, collect_list, sort_array, size, split, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "def cutStartEndBrackets(series):\n",
    "    return series.str[2:-2]\n",
    "\n",
    "cutStartEndBracketsUDF = pandas_udf(cutStartEndBrackets, StringType())\n",
    "\n",
    "userFriend = \\\n",
    "    data.select(col(\"user\"), split(cutStartEndBracketsUDF(col(\"friendsString\")), \"\\),\\(\").alias(\"friendsMasks\"))\\\n",
    "    .withColumn(\"friendMask\", explode('friendsMasks'))\\\n",
    "    .withColumn(\"friend\", split(col(\"friendMask\"), \",\")[0])\\\n",
    "    .select(col(\"user\"), col(\"friend\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/step1.png\" width=700/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersWithCommonFriend = userFriend\\\n",
    "    .groupBy(\"friend\")\\\n",
    "    .agg(collect_list(\"user\").alias(\"usersWithCommonFriend\")) \\\n",
    "    .select(\"usersWithCommonFriend\")\\\n",
    "    .where(size(col(\"usersWithCommonFriend\")) >= 2)\\\n",
    "    .select(sort_array(\"usersWithCommonFriend\").alias(\"sortedUsersWithCommonFriend\"))\\\n",
    "    .drop(\"usersWithCommonFriend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/step2.png\" width=700/>\n",
    "<img src=\"pics/step3.png\" width=700/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|sortedUsersWithCommonFriend|\n",
      "+---------------------------+\n",
      "|          [131318, 2038934]|\n",
      "|       [11979968, 11979968]|\n",
      "|       [4471643, 4864911...|\n",
      "|           [39812, 3996243]|\n",
      "|       [34660, 960407, 1...|\n",
      "|         [215426, 10989590]|\n",
      "|       [294833, 3541819,...|\n",
      "|           [585940, 595464]|\n",
      "|         [7941296, 7941296]|\n",
      "|       [213875, 3310959,...|\n",
      "|       [1406846, 2044978...|\n",
      "|       [1208384, 1208384...|\n",
      "|        [2625623, 16545603]|\n",
      "|        [9787095, 11510201]|\n",
      "|       [1093525, 1543499...|\n",
      "|       [10599936, 10599936]|\n",
      "|       [5021715, 5262480...|\n",
      "|        [1651903, 10655397]|\n",
      "|       [1919, 582013, 35...|\n",
      "|         [3243642, 5845843]|\n",
      "+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersWithCommonFriend.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_users_to_pred = StructType(fields=[\n",
    "    StructField(\"user\", IntegerType()),\n",
    "])\n",
    "\n",
    "usersToPredict = spark.read.format(\"csv\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(usersToPredictPath) \\\n",
    "    .select(col(\"user\").cast(\"integer\")) \\\n",
    "    .rdd.map(lambda t : t.user).collect()\n",
    "\n",
    "usersToPredictBC = spark.sparkContext.broadcast(set(usersToPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType\n",
    "\n",
    "def pairsWithCommonFriend(usersWithCommonFriend):\n",
    "    pairs = []\n",
    "    for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "        for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "            if user1Index != user2Index:\n",
    "                if (usersWithCommonFriend[user1Index] in usersToPredictBC.value or \\\n",
    "                usersWithCommonFriend[user2Index] in usersToPredictBC.value):\n",
    "                    pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "    return pairs\n",
    "\n",
    "schema = ArrayType(ArrayType(IntegerType()))\n",
    "\n",
    "pairsWithCommonFriendUdf = udf(pairsWithCommonFriend, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/step4_2.png\" width=700/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|pairWithCommonFriend|count|\n",
      "+--------------------+-----+\n",
      "|  [1674438, 3595421]|    2|\n",
      "|   [364107, 2001627]|    1|\n",
      "|  [1041597, 1601542]|   18|\n",
      "|  [1987589, 2390769]|    2|\n",
      "| [2001627, 13719295]|    1|\n",
      "| [5673646, 13719295]|    1|\n",
      "|[14510074, 16471947]|    3|\n",
      "| [9244264, 10688913]|    1|\n",
      "|  [2912872, 7445742]|  236|\n",
      "| [2894369, 11791325]|   22|\n",
      "|[11791325, 13363661]|   12|\n",
      "|  [3056954, 4206583]|   14|\n",
      "|  [3279070, 9582976]|  120|\n",
      "| [4483293, 12881491]|    5|\n",
      "|[10063577, 13662697]|    4|\n",
      "|[11906845, 14021773]|   16|\n",
      "|    [18300, 1188271]|   14|\n",
      "|  [2428246, 2944744]|    2|\n",
      "|   [998048, 3392160]|   48|\n",
      "| [3121147, 16614662]|    9|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "\n",
    "def pairsWithCommonFriend(series):\n",
    "    pairs_lists = []\n",
    "    for usersWithCommonFriend in series:\n",
    "        pairs = []\n",
    "        for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "            for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "                if user1Index != user2Index:\n",
    "                    if usersWithCommonFriend[user1Index] in usersToPredictBC.value or \\\n",
    "                    usersWithCommonFriend[user2Index] in usersToPredictBC.value:\n",
    "                        pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "        pairs_lists.append(pairs)\n",
    "    return pd.Series(pairs_lists)\n",
    "        \n",
    "pairsWithCommonFriendUdf = pandas_udf(pairsWithCommonFriend, schema)\n",
    "\n",
    "commonFriendsCounts = usersWithCommonFriend\\\n",
    "            .select(pairsWithCommonFriendUdf(\"sortedUsersWithCommonFriend\").alias(\"pairsWithCommonFriend\"))\\\n",
    "            .where(size(col(\"pairsWithCommonFriend\")) > 0)    \n",
    "\n",
    "commonFriendsCounts\\\n",
    "    .withColumn(\"pairWithCommonFriend\", explode(\"pairsWithCommonFriend\"))\\\n",
    "    .drop(col(\"pairsWithCommonFriend\"))\\\n",
    "    .groupBy(col(\"pairWithCommonFriend\"))\\\n",
    "    .count()\\\n",
    "    .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairsWithCommonFriend(series):\n",
    "    pairs_lists = []\n",
    "    for usersWithCommonFriend in series:\n",
    "        pairs = []\n",
    "        for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "            for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "                if user1Index != user2Index:\n",
    "                    pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "        pairs_lists.append(pairs)\n",
    "    return pd.Series(pairs_lists)\n",
    "         \n",
    "pairsWithCommonFriendUdf = pandas_udf(pairsWithCommonFriend, schema_pandas)\n",
    "\n",
    "commonFriendsCounts = usersWithCommonFriend\\\n",
    "            .select(pairsWithCommonFriendUdf(\"sortedUsersWithCommonFriend\").alias(\"pairsWithCommonFriend\"))\\\n",
    "            .where(size(col(\"pairsWithCommonFriend\")) > 0)    \n",
    "\n",
    "commonFriendsCounts\\\n",
    "    .withColumn(\"pairWithCommonFriend\", explode(\"pairsWithCommonFriend\"))\\\n",
    "    .drop(col(\"pairsWithCommonFriend\"))\\\n",
    "    .groupBy(col(\"pairWithCommonFriend\"))\\\n",
    "    .count()\\\n",
    "    .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def pairsWithCommonFriendUpgraded(series, modulo):\n",
    "    pairs_lists = []\n",
    "\n",
    "    for usersWithCommonFriend in series:\n",
    "        pairs = []\n",
    "        for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "             for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "                    if user1Index != user2Index and user1Index % 13 == modulo:\n",
    "                        pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "        pairs_lists.append(pairs)\n",
    "    return pd.Series(pairs_lists)\n",
    "\n",
    "\n",
    "for i in range(13):\n",
    "    pairsWithCommonFriendUdfUpgraded = pandas_udf(partial(pairsWithCommonFriendUpgraded, modulo=i), schema)\n",
    "\n",
    "    commonFriendsCounts = usersWithCommonFriend\\\n",
    "            .select(pairsWithCommonFriendUdfUpgraded(\"sortedUsersWithCommonFriend\").alias(\"pairsWithCommonFriend\"))\\\n",
    "            .where(size(col(\"pairsWithCommonFriend\")) > 0)\\\n",
    "            .write.parquet(\"pairs/\" + str(i), mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16229065"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(\"pairs/*\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4565054"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(\"pairs/0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|pairWithCommonFriend|count|\n",
      "+--------------------+-----+\n",
      "| [1481111, 15756137]|    1|\n",
      "| [8039479, 10812715]|    4|\n",
      "| [9102327, 16272182]|    1|\n",
      "|   [709520, 1563367]|    2|\n",
      "|    [200736, 228410]|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"pairs/*\")\\\n",
    "    .withColumn(\"pairWithCommonFriend\", explode(\"pairsWithCommonFriend\"))\\\n",
    "    .drop(col(\"pairsWithCommonFriend\"))\\\n",
    "    .groupBy(col(\"pairWithCommonFriend\"))\\\n",
    "    .count()\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

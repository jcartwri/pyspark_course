{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"nazim lab02\") \n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_to_make_recs = [[23126, u'en', u'Compass - powerful SASS library that makes your life easier'], \n",
    " [21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2'], \n",
    " [16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'], \n",
    " [11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'], \n",
    " [16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus'], \n",
    " [13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_rdd = spark.read.json(\"/labs/slaba02/DO_record_per_line.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"desc\", outputCol=\"words_desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.transform(courses_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words_desc\", outputCol=\"rawFeatures\", numFeatures=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizedData = hashingTF.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfModel = idf.fit(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm\")\n",
    "data = normalizer.transform(rescaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_id = [str(i[0]) for i in courses_to_make_recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_udf = f.udf(lambda x,y: float(x.dot(y)), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selected_id in courses_id:\n",
    "    selected_vector = data.filter(f.col('id') == selected_id).select(f.col('norm').alias('target_norm'))\n",
    "\n",
    "    joined_df = data.filter(f.col('id') != selected_id) \\\n",
    "                    .select('id', 'norm') \\\n",
    "                    .crossJoin(selected_vector)\n",
    "\n",
    "    dot_df = joined_df.select(dot_udf('norm', 'target_norm').alias(\"dot_norm\"),\n",
    "                 'id')\n",
    "\n",
    "    most_similar_id_list = dot_df.sort(f.desc('dot_norm')).select('id').take(10)\n",
    "    \n",
    "    most_similar_id_list = [i.id for i in most_similar_id_list]\n",
    "    \n",
    "    submit_dict[selected_id] = most_similar_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23126': [13782, 13665, 24419, 20638, 2724, 25782, 2633, 2723, 13348, 15909],\n",
       " '21617': [21609,\n",
       "  21608,\n",
       "  21616,\n",
       "  21492,\n",
       "  21624,\n",
       "  21623,\n",
       "  21630,\n",
       "  21628,\n",
       "  21508,\n",
       "  21857],\n",
       " '16627': [11431, 12247, 13021, 25010, 11575, 5687, 9598, 5372, 12863, 16769],\n",
       " '11556': [16488, 13461, 468, 10447, 387, 22710, 9289, 5936, 23357, 7833],\n",
       " '16704': [3864, 23407, 1365, 20645, 1426, 20105, 8217, 1236, 1164, 23864],\n",
       " '13702': [864, 1216, 7173, 8313, 1052, 17017, 19613, 21017, 17015, 8082]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/home/nazim.dzhavadov/lab02.json\", mode='w') as file:\n",
    "    json.dump(submit_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

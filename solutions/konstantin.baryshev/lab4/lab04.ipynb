{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 10 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"baryshev konstantin\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"baryshev konstantin\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\tage\tuid\tuser_json\r\n",
      "F\t18-24\td50192e5-c44e-4ae8-ae7a-7cfe67c8b777\t{\"visits\": [{\"url\": \"http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\", \"timestamp\": 1419688144068}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426666298001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426666298000}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426661722001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426661722000}]}\r\n",
      "cat: Unable to write to output stream.\r\n",
      "cat: `-cat': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#!hdfs dfs -cat /labs/slaba04/gender_age_dataset.txt -cat | head -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    ArrayType,\n",
    "    LongType,\n",
    "    IntegerType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"age\", StringType()),\n",
    "    StructField(\"uid\", StringType()),\n",
    "    StructField(\"user_json\", StringType()),\n",
    "])\n",
    "train = spark.read.csv('/labs/slaba04/gender_age_dataset.txt', header = True, sep=\"\\t\", schema = schema)\n",
    "#train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "|gender|  age|                 uid|           user_json|              visits|\n",
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "|     F|18-24|d50192e5-c44e-4ae...|{\"visits\": [{\"url...|[{\"url\":\"http://z...|\n",
      "|     M|25-34|d502331d-621e-472...|{\"visits\": [{\"url...|[{\"url\":\"http://s...|\n",
      "|     F|25-34|d50237ea-747e-48a...|{\"visits\": [{\"url...|[{\"url\":\"http://r...|\n",
      "|     F|25-34|d502f29f-d57a-46b...|{\"visits\": [{\"url...|[{\"url\":\"http://t...|\n",
      "|     M| >=55|d503c3b2-a0c2-4f4...|{\"visits\": [{\"url...|[{\"url\":\"https://...|\n",
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = train.withColumn('visits', f.get_json_object(\"user_json\", \"$.visits\"))\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- user_json: string (nullable = true)\n",
      " |-- visits: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def get_urls(x):\n",
    "    lst = eval(x)\n",
    "    original_urls =  [urlparse(a['url'])[1] for a in lst]\n",
    "    return ' '.join(original_urls)\n",
    "geturls = udf(get_urls)\n",
    "\n",
    "def get_times(x):\n",
    "    lst = eval(x)\n",
    "    return [a[\"timestamp\"] for a in lst]\n",
    "gettimes = udf(get_times)\n",
    "\n",
    "train = train.withColumn('urls',geturls('visits'))\\\n",
    ".withColumn('dates',gettimes('visits'))\\\n",
    ".select('gender', 'age','uid','urls','dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"urls\", outputCol=\"words\")\n",
    "train2 = tokenizer.transform(train)\n",
    "\n",
    "hashingTF = HashingTF(numFeatures=10000, binary = False, inputCol=tokenizer.getOutputCol(), outputCol=\"url_vector\")\n",
    "train2 = hashingTF.transform(train2)\n",
    "\n",
    "idf = IDF(inputCol = 'url_vector', outputCol = 'features').fit(train2)\n",
    "train_vect = idf.transform(train2)\n",
    "\n",
    "#train_vect.show(2, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|  age|count(DISTINCT uid)|\n",
      "+-----+-------------------+\n",
      "| >=55|               1679|\n",
      "|45-54|               4744|\n",
      "|35-44|               9360|\n",
      "|25-34|              15457|\n",
      "|18-24|               4898|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "grouped = train_vect.groupBy(\"age\").agg(countDistinct(\"uid\"))\n",
    "grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#почистим данные \n",
    "train_vect = train_vect.where(f.col(\"age\") != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dict = {'F':0, 'M':1}\n",
    "age_dict = {'18-24':0, '25-34':1, '35-44':2, '45-54':3, '>=55':4}\n",
    "def encode_gender(x):\n",
    "    return gen_dict[x]\n",
    "\n",
    "encodegender = udf(encode_gender, returnType=IntegerType())\n",
    "\n",
    "def encode_age(x):\n",
    "    return age_dict[x]\n",
    "encodeage = udf(encode_age, returnType=IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vect = train_vect.withColumn('gender_enc',encodegender('gender')).withColumn('age_enc',encodeage('age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_gender = GBTClassifier(featuresCol=\"features\", labelCol=\"gender_enc\", maxIter=20, maxDepth=9)\n",
    "model_gen = gbt_gender.fit(cv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_age = RandomForestClassifier(numTrees = 100, featuresCol=\"features\", labelCol=\"age_enc\")\n",
    "model_age = rfc_age.fit(cv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-node-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_konstantin.baryshev\",\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "kafka_sdf = spark.readStream.format(\"kafka\").options(**read_kafka_params).load()\n",
    "#kafka_sdf = spark.read.format(\"kafka\").options(**read_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "deserialized = kafka_sdf.select(f.col(\"value\").cast(\"string\").alias(\"value\"))\n",
    "\n",
    "parsed = deserialized.select(\n",
    "            f.get_json_object(f.col(\"value\"), \"$.uid\").alias(\"uid\"),\n",
    "            f.get_json_object(f.col(\"value\"), \"$.visits\").alias(\"visits\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = parsed.withColumn('urls',geturls('visits'))\\\n",
    "             .withColumn('dates',gettimes('visits')).select('uid','urls','dates')\n",
    "# test.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = tokenizer.transform(test)\n",
    "test2 = hashingTF.transform(test2)\n",
    "test_vect = idf.transform(test2)\n",
    "# test_vect.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gen = model_gen.transform(test_vect)\n",
    "res_gen_2 = res_gen.select(\"uid\", \"features\", f.col(\"prediction\").alias(\"gender_num\"))\n",
    "res_age = model_age.transform(res_gen_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_age = {value: key for key, value in age_dict.items()}\n",
    "inv_gen = {value: key for key, value in gen_dict.items()}\n",
    "def code_gender(x):\n",
    "    return inv_gen[x]\n",
    "codegender = udf(code_gender, StringType())\n",
    "def code_age(x):\n",
    "    return inv_age[x]\n",
    "codeage = udf(code_age, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = res_age.select(\"uid\", f.col(\"prediction\").alias(\"age\"), \"gender_num\")\\\n",
    "                .withColumn(\"gender\", codegender(\"gender_num\"))\\\n",
    "                .withColumn(\"age\", codeage(\"age\"))\\\n",
    "                .drop(\"gender_num\")\n",
    "# batch_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fb57e3377f0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_kafka_params = {\n",
    "   \"kafka.bootstrap.servers\": 'spark-node-1.newprolab.com:6667',\n",
    "   \"topic\": \"konstantin.baryshev\"\n",
    "}\n",
    "to_kafka = batch_df.select(f.to_json(f.struct('uid', 'gender', 'age')).cast(\"string\").alias(\"value\"))\\\n",
    "    .writeStream.format(\"kafka\").options(**write_kafka_params)\\\n",
    "    .option(\"checkpointLocation\", \"streaming/chk/chk_kafka\")\\\n",
    "    .outputMode(\"append\").start()\n",
    "\n",
    "to_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in spark.streams.active:\n",
    "    s.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

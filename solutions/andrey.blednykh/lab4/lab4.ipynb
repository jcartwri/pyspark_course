{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.executor.instances\", \"6\")\n",
    "conf.set(\"spark.executor.cores\", \"3\")\n",
    "conf.set(\"spark.executor.memory\", \"6g\")\n",
    "conf.set(\"spark.driver.cores\", \"3\")\n",
    "conf.set(\"spark.driver.memory\", \"6g\")\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(conf = conf)\\\n",
    "    .appName(\"Lab 04 Streaming\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -head /labs/slaba04/gender_age_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import HashingTF, StringIndexer, IndexToString\n",
    "from pyspark.ml.classification import RandomForestClassifier \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('gender', StringType()), \n",
    "    StructField('age', StringType()),\n",
    "    StructField('uid', StringType()),\n",
    "    StructField('user_json', StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .schema(schema)\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"delimiter\", \"\\\\t\")\\\n",
    "    .load(\"/labs/slaba04/gender_age_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.show(2, 200, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_schema = StructType([\n",
    "    StructField(\"visits\", ArrayType(\n",
    "      StructType([\n",
    "          StructField(\"url\", StringType(), True),\n",
    "          StructField(\"timestamp\", LongType(), True)\n",
    "      ])\n",
    "   ))\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data = train_data\\\n",
    "    .withColumn('visits', from_json(col('user_json'), schema=visits_schema))\\\n",
    "    .withColumn('visit', explode('visits.visits').alias('visit'))\\\n",
    "    .withColumn('host', \n",
    "                regexp_replace(expr('parse_url(visit.url, \"HOST\")').alias('host')), \"^www.\", \"\")\\\n",
    "    .filter(\"age != '-'\")\\\n",
    "    .filter(\"gender != '-'\")\\\n",
    "    .drop('visits', 'visit', 'user_json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data.show(2, 200, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = clear_data\\\n",
    "    .groupBy(col(\"gender\"), col(\"age\"), col(\"uid\"))\\\n",
    "    .agg(collect_list(\"host\").alias(\"hosts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data.show(2, 200, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_TF = HashingTF(inputCol=\"hosts\", outputCol=\"rawFeatures\", numFeatures=10000, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_age = StringIndexer(inputCol=\"age\", outputCol=\"ageIndex\").fit(group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_gender = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\").fit(group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_age = RandomForestClassifier(featuresCol=\"rawFeatures\", labelCol=\"ageIndex\", predictionCol=\"age_index_prediction\", \n",
    "        rawPredictionCol=\"age_index_raw_prediction\", probabilityCol=\"age_probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gender = RandomForestClassifier(featuresCol=\"rawFeatures\", labelCol=\"genderIndex\", predictionCol=\"gender_index_prediction\",\n",
    "                rawPredictionCol=\"gender_index_raw_prediction\", probabilityCol=\"gender_probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[hashing_TF, indexer_age, indexer_gender, rfc_age, rfc_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.show(2, 200, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(\"/user/andrey.blednykh/labs/lab04_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": \"spark-master-1.newprolab.com:6667\",\n",
    "    \"subscribe\": \"input_andrey.blednykh\",\n",
    "    \"startingOffsets\": \"earliest\",\n",
    "    \"maxOffsetsPerTrigger\": \"5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": \"spark-master-1.newprolab.com:6667\",\n",
    "    \"topic\": \"andrey.blednykh\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.readStream.format(\"kafka\").options(**input_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type = StructType([\n",
    "    StructField(\"uid\", StringType(), True),\n",
    "    StructField(\"visits\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_type = ArrayType(\n",
    "    StructType([\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"timestamp\", LongType(), True)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreachBatchFunction(batch_df, batch_id) {\n",
    "    \n",
    "    parced_data = batch_df\\\n",
    "        .select(col(\"value\").cast(\"string\").alias(\"value\"))\\\n",
    "        .select(from_json(col(\"value\"), event_type).alias(\"data\"))\\\n",
    "        .select(\"data.*\")\\\n",
    "        .select(\"uid\", from_json(col(\"visits\"), visit_type).alias(\"visits\"))\n",
    "    \n",
    "    proc_df = parced_data\\\n",
    "        .withColumn(\"visit\", explode(\"visits\").alias(\"visits\"))\\\n",
    "        .withColumn(\"host\", \n",
    "                    regexp_replace(expr(\"parse_url(visit.url), 'HOST'\").alias(\"host\")), \"^www.\", \"\")\\\n",
    "        .filter(\"age != '-'\")\\\n",
    "        .filter(\"gender != '-'\")\\    \n",
    "        .drop(\"visits\", \"visit\")\\\n",
    "        .groupBy(\"uid\")\\\n",
    "        .agg(collect_list(\"host\").alias(\"hosts\"))\n",
    "    \n",
    "    predict_df = lab_model\\\n",
    "        .transform(proc_df)\\\n",
    "        .select(\"uid\", \"PredictedGender\", \"PredictedAge\")\\\n",
    "        .withColumnRenamed(\"PredictedAge\", \"age\")\\\n",
    "        .withColumnRenamed(\"PredictedGender\", \"gender\")\n",
    "    \n",
    "    predict_df\n",
    "        .select(to_json(struct(*predict_df.columns)).alias(\"value\"))\n",
    "        .write(\"kafka\")\n",
    "        .options(**write_kafka_params)\\\n",
    "        .mode(\"append\")\n",
    "        .save()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_model = PipelineModel.load(\"/user/andrey.blednykh/labs/lab04_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.writeStream\\\n",
    "    .foreachBatch(foreachBatchFunction)\\\n",
    "    .option('checkpointLocation', 'streaming/chk/chk_andrey_blednykh')\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    for s in streams:\n",
    "        desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "        s.stop()\n",
    "        print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@38a16f45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@38a16f45"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "      .builder\n",
    "      .master(\"local[1]\")\n",
    "      .getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.net.URL\n",
    "import java.net.URLDecoder.decode\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions.udf\n",
    "import org.apache.spark.sql.functions.regexp_replace\n",
    "import scala.util.Try\n",
    "import org.apache.spark.sql.types.{IntegerType, LongType, StructType, DataType, StringType}\n",
    "import java.net.URLDecoder._\n",
    "import org.apache.spark.sql.functions.udf\n",
    "import org.apache.spark.sql.functions.explode\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.util.Try\n",
    "import java.net.URL\n",
    "import java.net.URLDecoder.decode\n",
    "import scala.util.Try\n",
    "import org.apache.spark.sql.functions.{udf, col}\n",
    " import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{CountVectorizer, StringIndexer, IndexToString}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainPath = /labs/slaba04/gender_age_dataset.txt\n",
       "modelPath = /user/sergey.polyakhov/laba04/model/\n",
       "maxIter = 10\n",
       "regParam = 0.001\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val trainPath = \"/labs/slaba04/gender_age_dataset.txt\"\n",
    "    val modelPath = \"/user/sergey.polyakhov/laba04/model/\"\n",
    "    val maxIter = \"10\"\n",
    "    val regParam = \"0.001\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exprGetDomain = regexp_replace(parse_url(visits.url, 'HOST'), '^www.', '')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "regexp_replace(parse_url(visits.url, 'HOST'), '^www.', '')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val exprGetDomain = \"regexp_replace(parse_url(visits.url, 'HOST'), '^www.', '')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = [gender: string, age: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[gender: string, age: string ... 3 more fields]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  val data =spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \"\\t\") \n",
    "    .option(\"mode\", \"failfast\") \n",
    "    .load(trainPath)\n",
    "    .withColumn(\"gender_age\", concat('gender, lit(\"_\"), 'age))\n",
    "    //.select(col(\"uid\"),col(\"gender\"), col(\"age\"), explode(col(\"visits\")).alias(\"visits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(visits,ArrayType(StructType(StructField(timestamp,LongType,true), StructField(url,StringType,true)),true),true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(visits,ArrayType(StructType(StructField(timestamp,LongType,true), StructField(url,StringType,true)),true),true))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = spark.read.json(data.select(\"user_json\").as[String]).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logs = [uid: string, gender_age: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, gender_age: string ... 1 more field]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val logs = data\n",
    ".select($\"uid\", $\"gender_age\", from_json($\"user_json\", schema).as(\"s\"))\n",
    ".select(\"uid\", \"gender_age\", \"s.*\")\n",
    ".select(col(\"uid\"),col(\"gender_age\"), explode(col(\"visits\")).alias(\"visits\"))\n",
    ".withColumn(\"domain\", expr(exprGetDomain))\n",
    ".groupBy(col(\"uid\"), col(\"gender_age\"))\n",
    ".agg(collect_list(\"domain\").alias(\"domains\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- gender_age: string (nullable = true)\n",
      " |-- domains: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l_test = [uid: string, gender_age: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, gender_age: string ... 2 more fields]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val l_test=\n",
    "logs\n",
    ".select(col(\"uid\"),col(\"gender_age\"))\n",
    ".withColumn(\"gender\", substring_index(col(\"gender_age\"), \"_\",1))\n",
    ".withColumn(\"age\", substring_index(col(\"gender_age\"), \"_\",-1))\n",
    ".cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----------+------+-----+\n",
      "|uid                                 |gender_age|gender|age  |\n",
      "+------------------------------------+----------+------+-----+\n",
      "|d52ab244-0a9c-434f-9dd0-34594b2a5993|M_25-34   |M     |25-34|\n",
      "|d60b267c-dab6-46a5-81f8-463d7deb6a60|F_25-34   |F     |25-34|\n",
      "+------------------------------------+----------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l_test.show(2, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv = cntVec_0a683efb0b61\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cntVec_0a683efb0b61"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cv = new CountVectorizer()\n",
    "      .setInputCol(\"domains\")\n",
    "      .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexer = strIdx_9ebce3aaed00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "strIdx_9ebce3aaed00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val indexer = new StringIndexer()\n",
    "      .setInputCol(\"gender_age\")\n",
    "      .setOutputCol(\"label\")\n",
    "      .fit(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr = logreg_6ff5683c007c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_6ff5683c007c"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val lr = new LogisticRegression()\n",
    "      .setMaxIter(maxIter.toInt)\n",
    "      .setRegParam(regParam.toDouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "converter = idxToStr_92c0ef42c7e5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "idxToStr_92c0ef42c7e5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val converter = new IndexToString()\n",
    "      .setInputCol(\"prediction\")\n",
    "      .setOutputCol(\"label_string\")\n",
    "      .setLabels(indexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = pipeline_e28e4ac5f75b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e28e4ac5f75b"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline()\n",
    "      .setStages(Array(cv, indexer, lr, converter)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_e28e4ac5f75b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e28e4ac5f75b"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val model = pipeline.fit(logs)\n",
    "    model.write.overwrite.save(modelPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelPath = /user/sergey.polyakhov/laba04/model/\n",
       "kafkaInputTopic = input_sergey.polyakhov\n",
       "kafkaOutputTopic = sergey.polyakhov\n",
       "kafkaServer = spark-de-master-1.newprolab.com:6667\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spark-de-master-1.newprolab.com:6667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelPath = \"/user/sergey.polyakhov/laba04/model/\"\n",
    "val kafkaInputTopic = \"input_sergey.polyakhov\"\n",
    "val kafkaOutputTopic = \"sergey.polyakhov\"\n",
    "val kafkaServer = \"spark-de-master-1.newprolab.com:6667\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_e28e4ac5f75b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e28e4ac5f75b"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = PipelineModel.load(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(uid,StringType,true), StructField(visits,ArrayType(StructType(StructField(url,StringType,true), StructField(timestamp,StringType,true)),true),true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(uid,StringType,true), StructField(visits,ArrayType(StructType(StructField(url,StringType,true), StructField(timestamp,StringType,true)),true),true))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  val json_schema1 = StructType(Seq(\n",
    "      StructField(\"uid\", StringType, nullable = true),\n",
    "      StructField(\"visits\", StringType, nullable = true) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val json_schema2 = ArrayType(StructType(Seq(StructField(\"url\", StringType), StructField(\"timestamp\", StringType))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exprGetDomain = regexp_replace(parse_url(visits.url, 'HOST'), '^www.', '')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "regexp_replace(parse_url(visits.url, 'HOST'), '^www.', '')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val exprGetDomain = \"regexp_replace(parse_url(visits, 'HOST'), '^www.', '')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logs = [key: binary, value: binary ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[key: binary, value: binary ... 5 more fields]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val logs = spark\n",
    "      .read\n",
    "      .format(\"kafka\")\n",
    "      .option(\"kafka.bootstrap.servers\", kafkaServer)\n",
    "      .option(\"subscribe\", kafkaInputTopic)\n",
    "      .option(\"startingOffsets\", \"earliest\")\n",
    "      .option(\"checkpointLocation\", s\"chk/step2_lab04\")\n",
    "      .load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preparedLogs = [uid: string, domains: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, domains: array<string>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val preparedLogs = logs\n",
    "          .select(col(\"timestamp\"), from_json(col(\"value\").cast(\"string\"), json_schema1).alias(\"valueParsed\"))\n",
    "            .select(col(\"valueParsed.*\"))\n",
    "            .select($\"uid\", from_json($\"visits\", json_schema2).as(\"s\"))\n",
    "            .select(\"uid\", \"s.url\")\n",
    "            .select(col(\"uid\"), explode(col(\"url\")).alias(\"visits\"))\n",
    "            .withColumn(\"domain\", expr(exprGetDomain))\n",
    "            .groupBy(col(\"uid\"))\n",
    "            .agg(collect_list(\"domain\").alias(\"domains\")) \n",
    "            .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = model.transform(preparedLogs).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "          .select( col(\"uid\"),col(\"label_string\").alias(\"gender_age\"))\n",
    "          .withColumn(\"gender\", substring_index(col(\"gender_age\"), \"_\",1))\n",
    "          .withColumn(\"age\", substring_index(col(\"gender_age\"), \"_\",-1))\n",
    "          .select(col(\"uid\"),col(\"gender\"), col(\"age\"))\n",
    "           .toJSON\n",
    "           .write\n",
    "          //  .trigger(Trigger.ProcessingTime(\"5 seconds\"))\n",
    "          .format(\"kafka\")\n",
    "          .option(\"kafka.bootstrap.servers\", kafkaServer)\n",
    "          .option(\"topic\", kafkaOutputTopic)\n",
    "           .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаба 1. Расчет рейтингов фильмов – RDD\n",
    "\n",
    "## Дедлайн\n",
    "\n",
    "Понедельник, 1 марта, 23:59:59\n",
    "\n",
    "## Задача\n",
    "\n",
    "По имеющимся данным о рейтингах фильмов (MovieLens: 100 000 рейтингов) посчитать агрегированную статистику по ним.\n",
    "\n",
    "## Описание данных\n",
    "\n",
    "Имеются следующие входные данные:\n",
    "\n",
    "* Таблица `users x movies` с рейтингами. Архив с датасетом нужно скачать с сайта [GroupLens](http://files.grouplens.org/datasets/movielens/ml-100k.zip). Также, он загружен на HDFS в `/labs/laba01/ml-100k`. Файл u.data содержит все оценки, а файл u.item — список всех фильмов.\n",
    "\n",
    "`!hdfs dfs -ls /labs/laba01/ml-100k`\n",
    "\n",
    "* `id фильма` для расчета индивидуальных характеристик — в Личном кабинете на странице [Лабы 1](https://lk-spark.newprolab.com/lab/slaba01).\n",
    "\n",
    "## Результат\n",
    "\n",
    "Выходной формат файла — json. Пример решения:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"hist_film\": [  \n",
    "      134,\n",
    "      123,\n",
    "      782,\n",
    "      356,\n",
    "      148\n",
    "   ],\n",
    "   \"hist_all\": [  \n",
    "      134,\n",
    "      123,\n",
    "      782,\n",
    "      356,\n",
    "      148\n",
    "   ]\n",
    "}\n",
    "```\n",
    "\n",
    "В поле `“hist_film”` нужно указать для заданного `id` фильма количество поставленных оценок в следующем порядке: `\"1\", \"2\", \"3\", \"4\", \"5\"`. То есть сколько было единичек, двоек, троек и т.д.\n",
    "\n",
    "В поле `“hist_all”` нужно указать то же самое только для всех фильмов общее количество поставленных оценок в том же порядке: `\"1\", \"2\", \"3\", \"4\", \"5\"`.\n",
    "\n",
    "## Проверка\n",
    "\n",
    "Файл необходимо положить в свою домашнюю директорию на кластере под названием: `lab01.json`.\n",
    "\n",
    "Проверка осуществляется автоматическим скриптом на странице лабы в личном кабинете.\n",
    "\n",
    "Обязательное условие зачета лабораторной работы – это выкладка после дедлайна лабы своего решения в репозиторий через pull-request. Как это сделать, можно прочитать [здесь](/git.md). Если будут вопросы – спрашивайте в Slack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"natasha pritykovskaya Spark RDD app\") \n",
    "\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 items\r\n",
      "-rw-r--r--   3 hdfs hdfs       6750 2020-09-05 20:38 /labs/laba01/ml-100k/README\r\n",
      "-rw-r--r--   3 hdfs hdfs        716 2020-09-05 20:38 /labs/laba01/ml-100k/allbut.pl\r\n",
      "-rw-r--r--   3 hdfs hdfs        643 2020-09-05 20:38 /labs/laba01/ml-100k/mku.sh\r\n",
      "-rw-r--r--   3 hdfs hdfs    1979173 2020-09-05 20:38 /labs/laba01/ml-100k/u.data\r\n",
      "-rw-r--r--   3 hdfs hdfs        202 2020-09-05 20:38 /labs/laba01/ml-100k/u.genre\r\n",
      "-rw-r--r--   3 hdfs hdfs         36 2020-09-05 20:38 /labs/laba01/ml-100k/u.info\r\n",
      "-rw-r--r--   3 hdfs hdfs     236344 2020-09-05 20:38 /labs/laba01/ml-100k/u.item\r\n",
      "-rw-r--r--   3 hdfs hdfs        193 2020-09-05 20:38 /labs/laba01/ml-100k/u.occupation\r\n",
      "-rw-r--r--   3 hdfs hdfs      22628 2020-09-05 20:38 /labs/laba01/ml-100k/u.user\r\n",
      "-rw-r--r--   3 hdfs hdfs    1586544 2020-09-05 20:38 /labs/laba01/ml-100k/u1.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     392629 2020-09-05 20:38 /labs/laba01/ml-100k/u1.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1583948 2020-09-05 20:38 /labs/laba01/ml-100k/u2.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     395225 2020-09-05 20:38 /labs/laba01/ml-100k/u2.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1582546 2020-09-05 20:38 /labs/laba01/ml-100k/u3.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     396627 2020-09-05 20:38 /labs/laba01/ml-100k/u3.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1581878 2020-09-05 20:38 /labs/laba01/ml-100k/u4.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     397295 2020-09-05 20:38 /labs/laba01/ml-100k/u4.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1581776 2020-09-05 20:38 /labs/laba01/ml-100k/u5.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     397397 2020-09-05 20:38 /labs/laba01/ml-100k/u5.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1792501 2020-09-05 20:38 /labs/laba01/ml-100k/ua.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     186672 2020-09-05 20:38 /labs/laba01/ml-100k/ua.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1792476 2020-09-05 20:38 /labs/laba01/ml-100k/ub.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     186697 2020-09-05 20:38 /labs/laba01/ml-100k/ub.test\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/laba01/ml-100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"/labs/laba01/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['196\\t242\\t3\\t881250949',\n",
       " '186\\t302\\t3\\t891717742',\n",
       " '22\\t377\\t1\\t878887116',\n",
       " '244\\t51\\t2\\t880606923',\n",
       " '166\\t346\\t1\\t886397596']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "film id for calculations 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В поле “hist_film” нужно указать для заданного id фильма количество поставленных оценок в следующем порядке: \"1\", \"2\", \"3\", \"4\", \"5\". То есть сколько было единичек, двоек, троек и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "   \"hist_film\": None,\n",
    "   \"hist_all\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 20, 43, 123, 103]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = '96'\n",
    "result[\"hist_film\"] = sorted(rdd.map(lambda x: x.split(\"\\t\"))\n",
    "         .filter(lambda x: len(x) ==4 )\n",
    "         .filter(lambda x: x[1] == ID)\n",
    "         .map(lambda x: (x[2], 1))\\\n",
    "         .groupByKey()\n",
    "         .map(lambda x: (x[0], len(x[1])))\n",
    "         .collect())\n",
    "result[\"hist_film\"] = [i[1] for i in result[\"hist_film\"]]\n",
    "result[\"hist_film\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"hist_all\"] = sorted(rdd.map(lambda x: x.split(\"\\t\"))\n",
    "         .filter(lambda x: len(x) ==4 )\n",
    "         .map(lambda x: (x[2], 1))\\\n",
    "         .groupByKey()\n",
    "         .map(lambda x: (x[0], len(x[1])))\n",
    "         .collect())\n",
    "result[\"hist_all\"] = [i[1] for i in result[\"hist_all\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hist_film': [6, 20, 43, 123, 103],\n",
       " 'hist_all': [6110, 11370, 27145, 34174, 21201]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../lab01.json', 'w') as fp:\n",
    "    json.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

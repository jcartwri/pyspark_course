{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF, StopWordsRemover, VectorAssembler, VectorSizeHint\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITIONS = 18\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  74107|       0|\n",
      "|   1654|  89249|       0|\n",
      "|   1654|  99982|       0|\n",
      "|   1654|  89901|       0|\n",
      "|   1654| 100504|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('user_id', StringType()),\n",
    "                    StructField('item_id', StringType()),\n",
    "                    StructField('purchase', IntegerType())])\n",
    "train = spark.read.csv('/labs/slaba03/laba03_train.csv', schema=schema, header=True)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|user_id|item_id|\n",
      "+-------+-------+\n",
      "|   1654|  94814|\n",
      "|   1654|  93629|\n",
      "|   1654|   9980|\n",
      "|   1654|  95099|\n",
      "|   1654|  11265|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('user_id', StringType()),\n",
    "                    StructField('item_id', StringType())])\n",
    "test = spark.read.csv('/labs/slaba03/laba03_test.csv', schema=schema, header=True)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------\n",
      " item_id                     | 65667                                                                                  \n",
      " channel_id                  | null                                                                                   \n",
      " datetime_availability_start | 1970-01-01                                                                             \n",
      " datetime_availability_stop  | 2018-01-01                                                                             \n",
      " datetime_show_start         | null                                                                                   \n",
      " datetime_show_stop          | null                                                                                   \n",
      " content_type                | 1                                                                                      \n",
      " title                       | на пробах только девушки (all girl auditions)                                          \n",
      " year                        | 2013.0                                                                                 \n",
      " genres                      | Эротика                                                                                \n",
      " region_id                   | null                                                                                   \n",
      "-RECORD 1-------------------------------------------------------------------------------------------------------------\n",
      " item_id                     | 65669                                                                                  \n",
      " channel_id                  | null                                                                                   \n",
      " datetime_availability_start | 1970-01-01                                                                             \n",
      " datetime_availability_stop  | 2018-01-01                                                                             \n",
      " datetime_show_start         | null                                                                                   \n",
      " datetime_show_stop          | null                                                                                   \n",
      " content_type                | 1                                                                                      \n",
      " title                       | скуби ду: эротическая пародия (scooby doo: a xxx parody)                               \n",
      " year                        | 2011.0                                                                                 \n",
      " genres                      | Эротика                                                                                \n",
      " region_id                   | null                                                                                   \n",
      "-RECORD 2-------------------------------------------------------------------------------------------------------------\n",
      " item_id                     | 65668                                                                                  \n",
      " channel_id                  | null                                                                                   \n",
      " datetime_availability_start | 1970-01-01                                                                             \n",
      " datetime_availability_stop  | 2018-01-01                                                                             \n",
      " datetime_show_start         | null                                                                                   \n",
      " datetime_show_stop          | null                                                                                   \n",
      " content_type                | 1                                                                                      \n",
      " title                       | горячие девочки для горячих девочек (hot babes 4 hot babes)                            \n",
      " year                        | 2011.0                                                                                 \n",
      " genres                      | Эротика                                                                                \n",
      " region_id                   | null                                                                                   \n",
      "-RECORD 3-------------------------------------------------------------------------------------------------------------\n",
      " item_id                     | 65671                                                                                  \n",
      " channel_id                  | null                                                                                   \n",
      " datetime_availability_start | 1970-01-01                                                                             \n",
      " datetime_availability_stop  | 2018-01-01                                                                             \n",
      " datetime_show_start         | null                                                                                   \n",
      " datetime_show_stop          | null                                                                                   \n",
      " content_type                | 1                                                                                      \n",
      " title                       | соблазнительницы женатых мужчин (top heavy homewreckers)                               \n",
      " year                        | 2011.0                                                                                 \n",
      " genres                      | Эротика                                                                                \n",
      " region_id                   | null                                                                                   \n",
      "-RECORD 4-------------------------------------------------------------------------------------------------------------\n",
      " item_id                     | 65670                                                                                  \n",
      " channel_id                  | null                                                                                   \n",
      " datetime_availability_start | 1970-01-01                                                                             \n",
      " datetime_availability_stop  | 2018-01-01                                                                             \n",
      " datetime_show_start         | null                                                                                   \n",
      " datetime_show_stop          | null                                                                                   \n",
      " content_type                | 1                                                                                      \n",
      " title                       | секретные секс-материалы ii: темная секс пародия (the sex files ii: a dark xxx parody) \n",
      " year                        | 2010.0                                                                                 \n",
      " genres                      | Эротика                                                                                \n",
      " region_id                   | null                                                                                   \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('item_id', StringType()),\n",
    "                    StructField('channel_id', StringType()), \n",
    "                     StructField('datetime_availability_start', DateType()),\n",
    "                    StructField('datetime_availability_stop', DateType()), \n",
    "                    StructField('datetime_show_start', DateType()),\n",
    "                    StructField('datetime_show_stop', DateType()),\n",
    "                    StructField('content_type', IntegerType()),\n",
    "                    StructField('title', StringType()),\n",
    "                    StructField('year', FloatType()),\n",
    "                    StructField('genres', StringType()),\n",
    "                    StructField('region_id', IntegerType())])\n",
    "items = spark.read.csv('/labs/slaba03/laba03_items.csv', header=True, multiLine=True, sep ='\\t', schema=schema)\n",
    "items.show(5, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " user_id   | 0          \n",
      " item_id   | 7101053    \n",
      " ts_start  | 1491409931 \n",
      " ts_end    | 1491411600 \n",
      " item_type | live       \n",
      "-RECORD 1---------------\n",
      " user_id   | 0          \n",
      " item_id   | 7101054    \n",
      " ts_start  | 1491412481 \n",
      " ts_end    | 1491451571 \n",
      " item_type | live       \n",
      "-RECORD 2---------------\n",
      " user_id   | 0          \n",
      " item_id   | 7101054    \n",
      " ts_start  | 1491411640 \n",
      " ts_end    | 1491412481 \n",
      " item_type | live       \n",
      "-RECORD 3---------------\n",
      " user_id   | 0          \n",
      " item_id   | 6184414    \n",
      " ts_start  | 1486191290 \n",
      " ts_end    | 1486191640 \n",
      " item_type | live       \n",
      "-RECORD 4---------------\n",
      " user_id   | 257        \n",
      " item_id   | 4436877    \n",
      " ts_start  | 1490628499 \n",
      " ts_end    | 1490630256 \n",
      " item_type | live       \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('user_id', StringType()),\n",
    "                    StructField('item_id', StringType()), \n",
    "                     StructField('ts_start', LongType()),\n",
    "                    StructField('ts_end', LongType()), \n",
    "                    StructField('item_type', StringType())])\n",
    "views = spark.read.csv('/labs/slaba03/laba03_views_programmes.csv', header=True, schema=schema)\n",
    "views.show(5, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 7, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rdd.getNumPartitions(), test.rdd.getNumPartitions(), views.rdd.getNumPartitions(), items.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Row(purchase=1, count=10904), Row(purchase=0, count=5021720)], 2156840)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('purchase').count().collect(), test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler, CountVectorizer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.select('purchase', f.col('user_id').cast(LongType()), f.col('item_id').cast(LongType()))\n",
    "test = test.select(f.col('user_id').cast(LongType()), f.col('item_id').cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=10, maxIter=10, implicitPrefs=True, alpha=0.01, seed=42, ratingCol='purchase', userCol=\"user_id\", itemCol=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['prediction'],outputCol=\"prediction_vect\")\n",
    "scaler = MinMaxScaler(inputCol=assembler.getOutputCol(), outputCol=\"prediction_scaled\")\n",
    "pipeline = Pipeline(stages = [assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlist = f.udf(lambda x: float(list(x)[0]), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.fit(predictions).transform(predictions) \\\n",
    "                .withColumn(\"purchase\", unlist(\"prediction_scaled\")).drop(*[\"prediction_scaled\", \"prediction_vect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------+-------------------+\n",
      "|user_id|item_id|    prediction|           purchase|\n",
      "+-------+-------+--------------+-------------------+\n",
      "| 632495|    546|   9.780827E-4|0.24061553887636625|\n",
      "| 820048|    546| -1.9151293E-4|0.23944475576633972|\n",
      "| 822223|    546|-1.6651055E-15| 0.2396364631415825|\n",
      "| 829957|    546|           0.0|0.23963646314158416|\n",
      "| 831698|    546|   6.148561E-4|0.24025194350646872|\n",
      "| 841994|    546| -2.8825822E-5|0.23960760805208756|\n",
      "| 848670|    546|  1.857072E-15|0.23963646314158601|\n",
      "| 862829|    546| -1.5989634E-5|0.23962045727317854|\n",
      "| 864002|    546| -2.1148409E-4|0.23942476432400228|\n",
      "| 867939|    546|  1.3248062E-4|0.23976907827574892|\n",
      "| 868176|    546|  -4.857222E-4| 0.2391502477614563|\n",
      "| 872983|    546| -2.5424012E-4| 0.2393819648823526|\n",
      "| 874709|    546|           0.0|0.23963646314158416|\n",
      "| 886192|    546| 1.15136645E-4| 0.2397517166891163|\n",
      "| 886854|    546|           0.0|0.23963646314158416|\n",
      "| 891912|    546| -8.1380174E-5|0.23955500033890278|\n",
      "| 892757|    546|           0.0|0.23963646314158416|\n",
      "| 896100|    546|  6.1873824E-4|0.24025582960811398|\n",
      "| 899454|    546|           0.0|0.23963646314158416|\n",
      "| 902167|    546|  -6.231448E-4|0.23901268564815648|\n",
      "+-------+-------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select('user_id', 'item_id', 'purchase') \\\n",
    "                .orderBy('user_id', 'item_id').coalesce(1).toPandas().to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_purchased = train.groupby('user_id').agg(f.sum('purchase').alias('user_times_purchased'))\n",
    "item_purchased = train.groupby('item_id').agg(f.sum('purchase').alias('item_times_purchased'))                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = train_f.join(user_purchased, ['user_id'], how='left') \\\n",
    "                .join(item_purchased, ['item_id'], how='left')\n",
    "test_f = predictions.select('user_id', 'item_id', 'prediction') \\\n",
    "            .join(user_purchased, ['user_id'], how='left') \\\n",
    "            .join(item_purchased, ['item_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      " |-- prediction: float (nullable = false)\n",
      " |-- user_times_purchased: long (nullable = true)\n",
      " |-- item_times_purchased: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_f.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- prediction: float (nullable = false)\n",
      " |-- user_times_purchased: long (nullable = true)\n",
      " |-- item_times_purchased: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_f.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_assembler = VectorAssembler(inputCols=['prediction', 'user_times_purchased', 'item_times_purchased'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = feat_assembler.transform(train_f.fillna(-1))\n",
    "test_f = feat_assembler.transform(test_f.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol='features', labelCol='purchase', predictionCol='prob', seed=42)\n",
    "gbt_model = gbt.fit(train_f)\n",
    "test_predictions = gbt_model.transform(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.select('user_id', 'item_id', f.col('prob').alias('purchase')) \\\n",
    "                .orderBy('user_id', 'item_id').coalesce(1).toPandas().to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 4 pyspark-shell'\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"nikita.mospan lab4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER = \"gender\"\n",
    "AGE = \"age\"\n",
    "UID = \"uid\"\n",
    "VISITS = \"visits\"\n",
    "GENDER_AGE = \"gender_age\"\n",
    "DOMAIN_COL = \"domains\"\n",
    "LABEL = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"/labs/slaba04/gender_age_dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! hdfs dfs -cat /labs/slaba04/gender_age_dataset.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, expr, udf\n",
    "from pyspark.sql.types import StructType, StringType, ArrayType, StructField, LongType\n",
    "\n",
    "inputSchema = StructType([\n",
    "    StructField(GENDER, StringType(), False),\n",
    "    StructField(AGE, StringType(), False),\n",
    "    StructField(UID, StringType(), False),\n",
    "    StructField(\"user_data\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDf = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .schema(inputSchema)\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"mode\", \"failfast\") \\\n",
    "    .load(inputPath) \\\n",
    "    .where(F.col(GENDER) != '-') \\\n",
    "    .where(F.col(AGE) != '-') \\\n",
    "    .withColumn(GENDER_AGE, F.concat(GENDER, AGE))\\\n",
    "    .withColumn(VISITS, F.from_json(\"user_data\", StructType([StructField(\"dummy\", StringType()),\n",
    "                                                             StructField(\"visits\", StringType())])))\\\n",
    "    .select(UID, GENDER_AGE, F.col(\"visits.visits\").alias(VISITS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer().setInputCol(GENDER_AGE).setOutputCol(LABEL)\n",
    "inputWithLabelDf = stringIndexer.fit(inputDf).transform(inputDf)\n",
    "pathToLabelGenderAgeMapping = \"lab4_label_to_age_gender\"\n",
    "inputWithLabelDf.select(GENDER_AGE, LABEL).distinct()\\\n",
    "    .withColumn(GENDER, F.substring(F.col(GENDER_AGE), 1, 1))\\\n",
    "    .withColumn(AGE, F.substring(F.col(GENDER_AGE), 2, 100))\\\n",
    "    .select(AGE, GENDER, LABEL) \\\n",
    "    .repartition(1).write.format(\"parquet\").mode(\"overwrite\").save(pathToLabelGenderAgeMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'VisitsTransformer.ipynb'\n",
    "m = __import__(\"__main__\")\n",
    "setattr(m, 'VisitsTransformer', VisitsTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+--------------------+\n",
      "|                 uid|gender_age|              visits|label|             domains|\n",
      "+--------------------+----------+--------------------+-----+--------------------+\n",
      "|d50192e5-c44e-4ae...|    F18-24|[{\"url\":\"http://z...|  4.0|[zebra-zoya.ru, n...|\n",
      "+--------------------+----------+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visitsTransformer = VisitsTransformer()\n",
    "# visitsTransformer.transform(inputWithLabelDf).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = inputWithLabelDf.randomSplit([0.8, 0.2], seed = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "visitsTransformer = VisitsTransformer()\n",
    "countVectorizer = CountVectorizer().setVocabSize(1000).setInputCol(DOMAIN_COL).setOutputCol(\"features\")\n",
    "rf = RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\")\n",
    "pipeline = Pipeline().setStages([visitsTransformer, countVectorizer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "trainValidationSplit = TrainValidationSplit()\\\n",
    "    .setTrainRatio(0.85)\\\n",
    "    .setEstimatorParamMaps(params)\\\n",
    "    .setEstimator(pipeline)\\\n",
    "    .setEvaluator(evaluator)\n",
    "\n",
    "fittedTrainValidationSplit = trainValidationSplit.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(fittedTrainValidationSplit.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab4ModelPath = 'lab4_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedTrainValidationSplit.bestModel.write().overwrite().save(lab4ModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

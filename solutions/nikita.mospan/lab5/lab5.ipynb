{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField, LongType}\n",
    "import org.apache.spark.sql.functions.{col, udf}\n",
    "import org.apache.spark.ml.feature.{Imputer, CountVectorizer, VectorAssembler, StandardScaler, OneHotEncoder, StringIndexer}\n",
    "import org.apache.spark.ml.classification.{GBTClassifier, GBTClassificationModel}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.tuning.TrainValidationSplit\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import sys.process._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val TARGET_COL = \"TARGET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " val spark = SparkSession\n",
    "   .builder()\n",
    "   .appName(\"mospan lab5\")\n",
    "   .config(\"spark.executor.instances\", \"16\")\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainDf = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")  \n",
    "  .load(\"lab5/lab05_train.csv\")\n",
    "  .drop(\"_c0\")\n",
    "  .filter(col(TARGET_COL).isNotNull)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf.createOrReplaceTempView(\"train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select count(distinct substr(nvl(upper(CLNT_JOB_POSITION), 'OTHER'), 1, 3)) from train_df\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val stringCols = List(\"CLNT_TRUST_RELATION\", \"APP_MARITAL_STATUS\", \n",
    "                             \"APP_KIND_OF_PROP_HABITATION\", \"CLNT_JOB_POSITION_TYPE\",\n",
    "                              \"APP_DRIVING_LICENSE\", \"APP_EDUCATION\", \"APP_TRAVEL_PASS\",\n",
    "                              \"APP_CAR\", \"APP_POSITION_TYPE\", \"APP_EMP_TYPE\", \"APP_COMP_TYPE\", \"PACK\", \"CLNT_JOB_POSITION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processStringCols(df: DataFrame): DataFrame = {\n",
    "    val numericCols = df.columns.toSeq.filter(col => !stringCols.contains(col)).mkString(\",\")\n",
    "    df.createOrReplaceTempView(\"df\")\n",
    "    spark.sql(s\"\"\"select case \n",
    "                    when CLNT_TRUST_RELATION in ('Мать', 'мама', 'мать') then 'MOTHER'\n",
    "                    when CLNT_TRUST_RELATION = 'Сын' then 'SON'\n",
    "                    when CLNT_TRUST_RELATION = 'Дочь' then 'DAUGHTER'\n",
    "                    when CLNT_TRUST_RELATION = 'Друг' then 'FRIEND'\n",
    "                    when CLNT_TRUST_RELATION = 'Отец' then 'FATHER'\n",
    "                    when CLNT_TRUST_RELATION = 'Брат' then 'BROTHER'\n",
    "                    when CLNT_TRUST_RELATION = 'Сестра' then 'SISTER'\n",
    "                    when CLNT_TRUST_RELATION in ('Близкий ро', 'Дальний ро') then 'RELATIVE'\n",
    "                    else  nvl(CLNT_TRUST_RELATION, 'OTHER') end as CLNT_TRUST_RELATION,\n",
    "                nvl(upper(APP_MARITAL_STATUS), 'OTHER') as APP_MARITAL_STATUS,\n",
    "                nvl(APP_KIND_OF_PROP_HABITATION, 'OTHER') as APP_KIND_OF_PROP_HABITATION,\n",
    "                nvl(CLNT_JOB_POSITION_TYPE, 'OTHER') as CLNT_JOB_POSITION_TYPE,\n",
    "                nvl(APP_DRIVING_LICENSE, 'OTHER') as APP_DRIVING_LICENSE,\n",
    "                nvl(APP_EDUCATION, 'OTHER') as APP_EDUCATION,\n",
    "                nvl(APP_TRAVEL_PASS, 'OTHER') as APP_TRAVEL_PASS,\n",
    "                nvl(APP_CAR, 'OTHER') as APP_CAR,\n",
    "                nvl(APP_POSITION_TYPE, 'OTHER') as APP_POSITION_TYPE,\n",
    "                nvl(APP_EMP_TYPE, 'OTHER') as APP_EMP_TYPE,\n",
    "                nvl(APP_COMP_TYPE, 'OTHER') as APP_COMP_TYPE,\n",
    "                PACK,\n",
    "                substr(nvl(upper(CLNT_JOB_POSITION), 'OTHER'), 1, 3) as CLNT_JOB_POSITION,\n",
    "                $numericCols\n",
    "            from df\"\"\")    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainHandleStringsDf = processStringCols(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// val stringCols = trainProcessStringsDf.schema.fields\n",
    "//     .filter(x => x.dataType == StringType && !processedStringCols.contains(x.name))\n",
    "//     .map(x => x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// val trainNoStringsDf = trainProcessStringsDf.drop(stringCols: _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def castIntColsToDouble(df: DataFrame): DataFrame = {\n",
    "    val colsToExcludeFromCast = df.schema.fields\n",
    "        .filter(x => x.dataType == DoubleType || x.name == \"ID\" || x.name == TARGET_COL \n",
    "                || stringCols.contains(x.name))\n",
    "        .map(x => x.name)\n",
    "    (df.columns.toBuffer --= colsToExcludeFromCast)\n",
    "                .foldLeft(df)((current, c) => current.withColumn(c, col(c).cast(\"double\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainDoubleCastDf = castIntColsToDouble(trainHandleStringsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val doubleFeatureCols = trainDoubleCastDf.schema.fields\n",
    "    .filter(x => !(\"ID\" :: TARGET_COL :: stringCols).contains(x.name))\n",
    "    .map(x => x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val finalTrainDf = trainDoubleCastDf.stat.sampleBy(TARGET_COL, fractions=Map(0 -> 0.98, 1 -> 0.98), seed=41)\n",
    "val valDf = trainDoubleCastDf.join(finalTrainDf, Seq(\"ID\"), \"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// finalTrainDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// valDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubleFeatureCols.contains(\"AGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val imputer = new Imputer().setStrategy(\"mean\").setInputCols(doubleFeatureCols).setOutputCols(doubleFeatureCols)\n",
    "val clntTrustRelIndexer = new StringIndexer().setInputCol(\"CLNT_TRUST_RELATION\")\n",
    "    .setOutputCol(\"CLNT_TRUST_RELATION_IND\")\n",
    "val clntTrustRelOhe = new OneHotEncoder().setInputCol(\"CLNT_TRUST_RELATION_IND\")\n",
    "    .setOutputCol(\"CLNT_TRUST_RELATION_ONE_HOT\")\n",
    "val appMaritalStatusIndexer = new StringIndexer().setInputCol(\"APP_MARITAL_STATUS\")\n",
    "    .setOutputCol(\"APP_MARITAL_STATUS_IND\")\n",
    "val appMaritalStatusOhe = new OneHotEncoder().setInputCol(\"APP_MARITAL_STATUS_IND\")\n",
    "    .setOutputCol(\"APP_MARITAL_STATUS_ONE_HOT\")\n",
    "val appKindHabitIndexer = new StringIndexer().setInputCol(\"APP_KIND_OF_PROP_HABITATION\")\n",
    "    .setOutputCol(\"APP_KIND_OF_PROP_HABITATION_IND\")\n",
    "val appKindHabitOhe = new OneHotEncoder().setInputCol(\"APP_KIND_OF_PROP_HABITATION_IND\")\n",
    "    .setOutputCol(\"APP_KIND_OF_PROP_HABITATION_IND_ONE_HOT\")\n",
    "val clntJobIndexer = new StringIndexer().setInputCol(\"CLNT_JOB_POSITION_TYPE\")\n",
    "    .setOutputCol(\"CLNT_JOB_POSITION_TYPE_IND\")\n",
    "val clntJobOhe = new OneHotEncoder().setInputCol(\"CLNT_JOB_POSITION_TYPE_IND\")\n",
    "    .setOutputCol(\"CLNT_JOB_POSITION_TYPE_ONE_HOT\")\n",
    "val appDriveLicenseIndexer = new StringIndexer().setInputCol(\"APP_DRIVING_LICENSE\")\n",
    "    .setOutputCol(\"APP_DRIVING_LICENSE_IND\")\n",
    "val appDriveLicenseOhe = new OneHotEncoder().setInputCol(\"APP_DRIVING_LICENSE_IND\")\n",
    "    .setOutputCol(\"APP_DRIVING_LICENSE_ONE_HOT\")\n",
    "val appEducationIndexer = new StringIndexer().setInputCol(\"APP_EDUCATION\")\n",
    "    .setOutputCol(\"APP_EDUCATION_IND\")\n",
    "val appEducationOhe = new OneHotEncoder().setInputCol(\"APP_EDUCATION_IND\")\n",
    "    .setOutputCol(\"APP_EDUCATION_ONE_HOT\")\n",
    "val appTravelPassIndexer = new StringIndexer().setInputCol(\"APP_TRAVEL_PASS\")\n",
    "    .setOutputCol(\"APP_TRAVEL_PASS_IND\")\n",
    "val appTravelPassOhe = new OneHotEncoder().setInputCol(\"APP_TRAVEL_PASS_IND\")\n",
    "    .setOutputCol(\"APP_TRAVEL_PASS_IND_ONE_HOT\")\n",
    "val appCarIndexer = new StringIndexer().setInputCol(\"APP_CAR\")\n",
    "    .setOutputCol(\"APP_CAR_IND\")\n",
    "val appCarOhe = new OneHotEncoder().setInputCol(\"APP_CAR_IND\")\n",
    "    .setOutputCol(\"APP_CAR_ONE_HOT\")\n",
    "val appPosTypeIndexer = new StringIndexer().setInputCol(\"APP_POSITION_TYPE\")\n",
    "    .setOutputCol(\"APP_POSITION_TYPE_IND\")\n",
    "val appPosTypeOhe = new OneHotEncoder().setInputCol(\"APP_POSITION_TYPE_IND\")\n",
    "    .setOutputCol(\"APP_POSITION_TYPE_ONE_HOT\")\n",
    "val appEmpTypeIndexer = new StringIndexer().setInputCol(\"APP_EMP_TYPE\")\n",
    "    .setOutputCol(\"APP_EMP_TYPE_IND\")\n",
    "val appEmpTypeOhe = new OneHotEncoder().setInputCol(\"APP_EMP_TYPE_IND\")\n",
    "    .setOutputCol(\"APP_EMP_TYPE_ONE_HOT\")\n",
    "val appCompTypeIndexer = new StringIndexer().setInputCol(\"APP_COMP_TYPE\")\n",
    "    .setOutputCol(\"APP_COMP_TYPE_IND\")\n",
    "val appCompTypeOhe = new OneHotEncoder().setInputCol(\"APP_COMP_TYPE_IND\")\n",
    "    .setOutputCol(\"APP_COMP_TYPE_ONE_HOT\")\n",
    "val packIndexer = new StringIndexer().setInputCol(\"PACK\")\n",
    "    .setOutputCol(\"PACK_IND\")\n",
    "val packOhe = new OneHotEncoder().setInputCol(\"PACK_IND\")\n",
    "    .setOutputCol(\"PACK_ONE_HOT\")\n",
    "val jobPosIndexer = new StringIndexer().setInputCol(\"CLNT_JOB_POSITION\")\n",
    "    .setOutputCol(\"CLNT_JOB_POSITION_IND\")\n",
    "    .setHandleInvalid(\"keep\")\n",
    "val jobPosOhe = new OneHotEncoder().setInputCol(\"CLNT_JOB_POSITION_IND\")\n",
    "            .setOutputCol(\"CLNT_JOB_POSITION_ONE_HOT\")\n",
    "val vectorAssembler = new VectorAssembler().setInputCols(doubleFeatureCols \n",
    "                                                        :+ \"CLNT_TRUST_RELATION_ONE_HOT\" \n",
    "                                                        :+ \"APP_MARITAL_STATUS_ONE_HOT\"\n",
    "                                                        :+ \"APP_KIND_OF_PROP_HABITATION_IND_ONE_HOT\"\n",
    "                                                         :+ \"CLNT_JOB_POSITION_TYPE_ONE_HOT\"\n",
    "                                                         :+ \"APP_DRIVING_LICENSE_ONE_HOT\"\n",
    "                                                         :+ \"APP_EDUCATION_ONE_HOT\"\n",
    "                                                         :+ \"APP_TRAVEL_PASS_IND_ONE_HOT\"\n",
    "                                                         :+ \"APP_CAR_ONE_HOT\"\n",
    "                                                         :+ \"APP_POSITION_TYPE_ONE_HOT\"\n",
    "                                                         :+ \"APP_EMP_TYPE_ONE_HOT\"\n",
    "                                                         :+ \"APP_COMP_TYPE_ONE_HOT\"\n",
    "                                                         :+ \"PACK_ONE_HOT\"\n",
    "                                                         :+ \"CLNT_JOB_POSITION_ONE_HOT\"\n",
    "                                                        )\n",
    "    .setOutputCol(\"features\")\n",
    "// val minMaxScaler = new MinMaxScaler().setMin(0).setMax(1).setInputCol(\"features\").setOutputCol(\"min_max_features\")\n",
    "// val stdScaler = new StandardScaler().setInputCol(\"features\").setOutputCol(\"norm_features\")\n",
    "// val layers = Array[Int](119, 32, 2)\n",
    "// val mlp = new MultilayerPerceptronClassifier().setLabelCol(TARGET_COL).setFeaturesCol(\"norm_features\")\n",
    "//     .setLayers(layers)\n",
    "//     .setBlockSize(32)\n",
    "//     .setSeed(41L)\n",
    "//     .setMaxIter(200)\n",
    "val gbt = new GBTClassifier()\n",
    "  .setLabelCol(TARGET_COL)\n",
    "  .setFeaturesCol(\"features\")\n",
    "//   .setMaxIter(20)\n",
    "  .setFeatureSubsetStrategy(\"auto\")\n",
    "val stages = Array(imputer, clntTrustRelIndexer, clntTrustRelOhe, \n",
    "                   appMaritalStatusIndexer, appMaritalStatusOhe,\n",
    "                   appKindHabitIndexer, appKindHabitOhe,\n",
    "                   clntJobIndexer, clntJobOhe,\n",
    "                   appDriveLicenseIndexer, appDriveLicenseOhe,\n",
    "                   appEducationIndexer, appEducationOhe,\n",
    "                   appTravelPassIndexer, appTravelPassOhe,\n",
    "                   appCarIndexer, appCarOhe,\n",
    "                   appPosTypeIndexer, appPosTypeOhe,\n",
    "                   appEmpTypeIndexer, appEmpTypeOhe,\n",
    "                   appCompTypeIndexer, appCompTypeOhe,\n",
    "                   packIndexer, packOhe,\n",
    "                   jobPosIndexer, jobPosOhe,\n",
    "                   vectorAssembler, \n",
    "//                    minMaxScaler, \n",
    "//                    stdScaler, \n",
    "                   gbt)\n",
    "val pipeline = new Pipeline().setStages(stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// val afterImputeDf = imputer.fit(finalTrainDf).transform(finalTrainDf)\n",
    "// val afterIndexerDf = clntTrustRelIndexer.fit(afterImputeDf).transform(afterImputeDf)\n",
    "// val afterOheDf = clntTrustRelOhe.transform(afterIndexerDf)\n",
    "// val afterIndexer2Df = appMaritalStatusIndexer.fit(afterOheDf).transform(afterOheDf)\n",
    "// val afterOhe2Df = appMaritalStatusOhe.transform(afterIndexer2Df)\n",
    "// val afterIndexer3Df = packIndexer.fit(afterOhe2Df).transform(afterOhe2Df)\n",
    "// val afterOhe3Df = packOhe.transform(afterIndexer3Df)\n",
    "// val afterVecAssemblerDf = vectorAssembler.transform(afterOhe3Df)\n",
    "// afterVecAssemblerDf.select(\"features\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val params = new ParamGridBuilder()\n",
    "        .addGrid(gbt.maxDepth, Array(10))\n",
    "        .addGrid(gbt.maxBins, Array(100))\n",
    "        .addGrid(gbt.maxIter, Array(100))\n",
    "        .addGrid(gbt.stepSize, Array(0.1))\n",
    "        .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val evaluator = new BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\").setLabelCol(TARGET_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tvs = new TrainValidationSplit()\n",
    "    .setTrainRatio(0.95)\n",
    "    .setEstimatorParamMaps(params)\n",
    "    .setEstimator(pipeline)\n",
    "    .setEvaluator(evaluator)\n",
    "\n",
    "val fittedTvs = tvs.fit(finalTrainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(fittedTvs.transform(valDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// maxDepth = 10\n",
    "// maxBins = 120\n",
    "// maxIter = 100\n",
    "\n",
    "val bestPipelineModel = fittedTvs.bestModel.asInstanceOf[PipelineModel]\n",
    "val bestGbtStage = bestPipelineModel.stages(28).asInstanceOf[GBTClassificationModel]\n",
    "println(\"maxDepth = \" + bestGbtStage.getMaxDepth)\n",
    "println(\"maxBins = \" + bestGbtStage.getMaxBins)\n",
    "println(\"maxIter = \" + bestGbtStage.getMaxIter)\n",
    "println(\"stepSize = \" + bestGbtStage.getStepSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val testDf = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"mode\", \"failfast\")  \n",
    "  .load(\"lab5/lab05_test.csv\")\n",
    "  .drop(\"_c0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val testHandleStringsDf = processStringCols(testDf)\n",
    "// val testNoStringsDf = testProcessStringsDf.drop(stringCols: _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val testDoubleCastDf = castIntColsToDouble(testHandleStringsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val submissionPredictions = fittedTvs.transform(testDoubleCastDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val vectorSecondElementUdf = udf((v: Vector) => v.toArray(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val resultDf = submissionPredictions.select(\"id\", \"probability\")\n",
    "    .withColumn(\"target\", vectorSecondElementUdf(col(\"probability\")))\n",
    "    .select(\"id\", \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDf.coalesce(1).write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\")\n",
    "    .option(\"sep\", \"\\t\")\n",
    "    .save(\"lab5/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hdfs dfs -ls lab5/results\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cp lab05_best.csv lab05.csv\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"rm lab05.csv\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hdfs dfs -get lab5/results/part-00000-e5adcd51-b04f-41c8-8db2-d7afb2beb4cf-c000.csv lab05.csv\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

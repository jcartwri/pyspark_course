{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Apache Toree - Scala",
      "language": "scala",
      "name": "apache_toree_scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala",
      "version": "2.11.12"
    },
    "colab": {
      "name": "lab05-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R_W90fSp-5G"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR_Ki_Wtp-5K"
      },
      "source": [
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions._\n",
        "import org.apache.spark.sql.functions.{col}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Qf76fup-5M"
      },
      "source": [
        "val spark = SparkSession.builder.appName(\"Spark ML\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7k83vpYp-5N"
      },
      "source": [
        "val TRAIN_DATA_PATH = \"/user/vladimir.belov/lab05_train.csv\"\n",
        "val TEST_DATA_PATH = \"/user/vladimir.belov/lab05_test.csv\"\n",
        "val SAVE_PATH = \"/user/vladimir.belov/lab05\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f210cKOCp-5O"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD2V-pARp-5P"
      },
      "source": [
        "var trainDf = spark\n",
        "    .read\n",
        "    .format(\"csv\")\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"delimiter\", \",\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .load(TRAIN_DATA_PATH)\n",
        "    .drop(\"_c0\")\n",
        "    .cache\n",
        "\n",
        "trainDf.show(1, 0, true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqUG2xX1p-5P"
      },
      "source": [
        "var testDf = spark\n",
        "    .read\n",
        "    .format(\"csv\")\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"delimiter\", \",\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .load(TEST_DATA_PATH)\n",
        "    .drop(\"_c0\")\n",
        "    .na.fill(0)\n",
        "    .cache\n",
        "trainDf.show(1, 0, true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPDp0L-up-5Q"
      },
      "source": [
        "val categoriesCols = List(\n",
        "    \"CLNT_TRUST_RELATION\", \n",
        "    \"APP_MARITAL_STATUS\",\n",
        "    \"APP_KIND_OF_PROP_HABITATION\", \n",
        "    \"CLNT_JOB_POSITION_TYPE\",\n",
        "    \"CLNT_JOB_POSITION\", \n",
        "    \"APP_DRIVING_LICENSE\", \n",
        "    \"APP_EDUCATION\",\n",
        "    \"APP_TRAVEL_PASS\", \n",
        "    \"APP_CAR\", \n",
        "    \"APP_POSITION_TYPE\", \n",
        "    \"APP_EMP_TYPE\",\n",
        "    \"APP_COMP_TYPE\", \n",
        "    \"PACK\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDPGRzahp-5R"
      },
      "source": [
        "trainDf = trainDf.drop(categoriesCols:_*).na.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7kqmvkTp-5R"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZCjdtLMp-5S"
      },
      "source": [
        "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
        "import org.apache.spark.ml.feature.{VectorAssembler}\n",
        "import org.apache.spark.ml.Pipeline\n",
        "import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}\n",
        "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
        "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17qiIOZWp-5S"
      },
      "source": [
        "val vectorAssembler = new VectorAssembler()\n",
        "    .setInputCols(trainDf.drop(\"TARGET\").columns)\n",
        "    .setOutputCol(\"features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edlk8cYbp-5T"
      },
      "source": [
        "val trainDfCleaned = vectorAssembler.transform(trainDf).cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuC8iVo-ruzE"
      },
      "source": [
        "trainDfCleaned.show(1, 0, true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD93wd6lp-5T"
      },
      "source": [
        "// Train RandomForest\n",
        "val randomForestModel = new RandomForestClassifier()\n",
        "    .setLabelCol(\"TARGET\")\n",
        "    .setFeaturesCol(\"features\")\n",
        "    .setSeed(42)\n",
        "    .fit(trainDfCleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scVZXK-Qp-5U"
      },
      "source": [
        "val gbt = new GBTClassifier()\n",
        "    .setLabelCol(\"TARGET\")\n",
        "    .setFeaturesCol(\"features\")\n",
        "    .setMaxIter(10)\n",
        "    .setFeatureSubsetStrategy(\"auto\")\n",
        "    .fit(trainDfCleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdfxCB0Cp-5U"
      },
      "source": [
        "import org.apache.spark.ml.linalg.{SparseVector, Vector}\n",
        "import org.apache.spark.mllib.linalg.{Vector => OldVector}\n",
        "\n",
        "val vectorToArrayUdf = udf { vec: Any =>\n",
        "    vec match {\n",
        "      case v: Vector => v.toArray\n",
        "      case v: OldVector => v.toArray\n",
        "      case v => throw new IllegalArgumentException(\n",
        "        \"function vector_to_array requires a non-null input argument and input type must be \" +\n",
        "        \"`org.apache.spark.ml.linalg.Vector` or `org.apache.spark.mllib.linalg.Vector`, \" +\n",
        "        s\"but got ${ if (v == null) \"null\" else v.getClass.getName }.\")\n",
        "    }\n",
        "  }.asNonNullable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9-759YTp-5V"
      },
      "source": [
        "val realPredictions = gbt.transform(vectorAssembler.transform(testDf)).cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZQcr5Lap-5V"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwsUUlH9p-5W"
      },
      "source": [
        "realPredictions\n",
        "    .withColumn(\"prediction\", vectorToArrayUdf(col(\"probability\")).getItem(1))\n",
        "    .select(\"ID\", \"prediction\")\n",
        "    .withColumnRenamed(\"prediction\", \"target\")\n",
        "    .coalesce(1)\n",
        "    .write\n",
        "    .option(\"header\",\"true\")\n",
        "    .option(\"sep\" ,\"\\t\")\n",
        "    .mode(\"overwrite\")\n",
        "    .format(\"csv\")\n",
        "    .save(SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYPcZ-hAp-5Y"
      },
      "source": [
        "spark.stop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
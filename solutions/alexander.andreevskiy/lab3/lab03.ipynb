{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f6f4070f7f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, pandas_udf, split, lower, udf\n",
    "from pyspark.sql.types import LongType, StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Spark Lab 3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-4.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   91066524 2021-02-27 22:12 /labs/slaba03/laba03_items.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   29965581 2021-02-27 22:12 /labs/slaba03/laba03_test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   74949368 2021-02-27 22:12 /labs/slaba03/laba03_train.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  871302535 2021-02-27 22:12 /labs/slaba03/laba03_views_programmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = spark.read.csv('/labs/slaba03/laba03_items.csv', header=True, sep='\\t')\n",
    "items.registerTempTable(\"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>datetime_availability_start</th>\n",
       "      <th>datetime_availability_stop</th>\n",
       "      <th>datetime_show_start</th>\n",
       "      <th>datetime_show_stop</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>region_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7006336</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1970-01-01T00:00:00Z</td>\n",
       "      <td>2017-04-04T09:00:00Z</td>\n",
       "      <td>2017-04-01T08:05:00Z</td>\n",
       "      <td>2017-04-01T09:00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>крылатый властелин морей</td>\n",
       "      <td>None</td>\n",
       "      <td>General</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7006349</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1970-01-01T00:00:00Z</td>\n",
       "      <td>2017-04-04T20:55:00Z</td>\n",
       "      <td>2017-04-01T20:00:00Z</td>\n",
       "      <td>2017-04-01T20:55:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>крылатый властелин морей</td>\n",
       "      <td>None</td>\n",
       "      <td>General</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id channel_id datetime_availability_start datetime_availability_stop  \\\n",
       "0  7006336        9.0        1970-01-01T00:00:00Z       2017-04-04T09:00:00Z   \n",
       "1  7006349        9.0        1970-01-01T00:00:00Z       2017-04-04T20:55:00Z   \n",
       "\n",
       "    datetime_show_start    datetime_show_stop content_type  \\\n",
       "0  2017-04-01T08:05:00Z  2017-04-01T09:00:00Z            0   \n",
       "1  2017-04-01T20:00:00Z  2017-04-01T20:55:00Z            0   \n",
       "\n",
       "                      title  year   genres region_id  \n",
       "0  крылатый властелин морей  None  General      41.0  \n",
       "1  крылатый властелин морей  None  General      41.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv('/labs/slaba03/laba03_test.csv', header=True)\n",
    "test.registerTempTable(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654</td>\n",
       "      <td>94814</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654</td>\n",
       "      <td>93629</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id purchase\n",
       "0    1654   94814     None\n",
       "1    1654   93629     None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv('/labs/slaba03/laba03_train.csv', header=True)\n",
    "train.registerTempTable(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>903319</td>\n",
       "      <td>11005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>903319</td>\n",
       "      <td>88884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id purchase\n",
       "0  903319   11005        0\n",
       "1  903319   88884        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = spark.read.csv('/labs/slaba03/laba03_views_programmes.csv', header=True)\n",
    "views.registerTempTable(\"views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ts_start</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>item_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7101053</td>\n",
       "      <td>1491409931</td>\n",
       "      <td>1491411600</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7101054</td>\n",
       "      <td>1491412481</td>\n",
       "      <td>1491451571</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  item_id    ts_start      ts_end item_type\n",
       "0       0  7101053  1491409931  1491411600      live\n",
       "1       0  7101054  1491412481  1491451571      live"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(purchase='0', count=5021720), Row(purchase='1', count=10904)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соотношение 0 и 1\n",
    "train.groupBy(\"purchase\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021666629575346776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10904 / (5021720 + 10904)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем обучающую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: \n",
    "\n",
    "* year (NA = 1970)\n",
    "* genre_id (NA = 'NA')\n",
    "* mean_user_purchase\n",
    "* mean_id_purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_temp = train.join(items, on=\"item_id\", how=\"left\")\n",
    "train_temp.registerTempTable(\"train_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_temp.select('user_id',\n",
    "                 'item_id', 'purchase',\n",
    "                 'year','genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+------+-------+\n",
      "|user_id|item_id|purchase|  year| genres|\n",
      "+-------+-------+--------+------+-------+\n",
      "| 865812| 100140|       0|2014.0|Комедии|\n",
      "| 866037| 100140|       0|2014.0|Комедии|\n",
      "| 866155| 100140|       0|2014.0|Комедии|\n",
      "| 866207| 100140|       0|2014.0|Комедии|\n",
      "| 866320| 100140|       0|2014.0|Комедии|\n",
      "+-------+-------+--------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_temp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+------+--------+\n",
      "|user_id|item_id|purchase|  year|genre_id|\n",
      "+-------+-------+--------+------+--------+\n",
      "|   1654| 100140|       0|2014.0|    12.0|\n",
      "| 510087| 100140|       0|2014.0|    12.0|\n",
      "+-------+-------+--------+------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обрабатываем категориальную переменную genres\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "train_temp = train_temp.na.fill({'genres':'NA'}) # заменяем пропуски\n",
    "indexer = StringIndexer(inputCol=\"genres\", outputCol=\"genre_id\") \n",
    "train_temp = indexer.fit(train_temp).transform(train_temp) \n",
    "train_temp = train_temp.drop(\"genres\").cache()\n",
    "train_temp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+----+--------+\n",
      "|user_id|item_id|purchase|year|genre_id|\n",
      "+-------+-------+--------+----+--------+\n",
      "+-------+-------+--------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# проверяем, что нет пропусков\n",
    "train_temp.where(col(\"genre_id\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|item_id|  mean_item_purchase|\n",
      "+-------+--------------------+\n",
      "|  98725|7.369196757553427E-4|\n",
      "|    691|                 0.0|\n",
      "|   2136| 7.22543352601156E-4|\n",
      "|  88649|0.001454545454545...|\n",
      "|  74605|                 0.0|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_popularity = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        item_id,\n",
    "        sum(purchase) / count(item_id) AS mean_item_purchase\n",
    "    FROM train_temp\n",
    "    GROUP BY item_id\n",
    "\"\"\")\n",
    "\n",
    "item_popularity.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|  mean_user_purchase|\n",
      "+-------+--------------------+\n",
      "| 921852|3.789314134141720...|\n",
      "| 927169|0.003464203233256351|\n",
      "| 929499|0.002714230321830167|\n",
      "| 930508|0.002693343593689...|\n",
      "| 867363|3.892565200467107...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_popularity = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        user_id,\n",
    "        sum(purchase) / count(user_id) AS mean_user_purchase\n",
    "    FROM train_temp\n",
    "    GROUP BY user_id\n",
    "\"\"\")\n",
    "\n",
    "user_popularity.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_temp.join(item_popularity, on=\"item_id\", how=\"left\")\n",
    "train_temp = train_temp.join(user_popularity, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+------------------+-----+----+--------+\n",
      "|item_id|mean_item_purchase|user_id|mean_user_purchase|label|year|genre_id|\n",
      "+-------+------------------+-------+------------------+-----+----+--------+\n",
      "|  11236|      0.0014869889| 867363|      3.8925651E-4|    0|2010|     104|\n",
      "|  66423|       7.199424E-4| 867363|      3.8925651E-4|    0|1957|     121|\n",
      "+-------+------------------+-------+------------------+-----+----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_temp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_temp.select(F.col(\"item_id\").cast(\"int\"),\n",
    "                               F.col(\"mean_item_purchase\").cast(\"float\"),\n",
    "                               F.col(\"user_id\").cast(\"int\"),\n",
    "                               F.col(\"mean_user_purchase\").cast(\"float\"),\n",
    "                               F.col(\"label\").cast(\"int\").alias('label'),\n",
    "                               F.col(\"year\").cast(\"int\"),\n",
    "                               F.col(\"genre_id\").cast(\"int\"))                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- mean_item_purchase: float (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- mean_user_purchase: float (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- genre_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_temp.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обрабатываем пропуски**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_temp.na.fill({'item_id':-1, 'user_id':-1, \n",
    "                                 'year':1970,'label':0,\n",
    "                                 'mean_user_purchase':0, 'mean_item_purchase':0})\n",
    "train_temp = train_temp.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Векторизуем признаки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assemblerInputs = ['mean_item_purchase', 'mean_user_purchase', 'year', 'genre_id',]\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = assembler.transform(train_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Делим на train и test**\n",
    "\n",
    "Сохраняем 20% нулей и единичек в отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=1, count=8727), Row(label=0, count=4017891)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1 = train_temp.sampleBy(\"label\", fractions={0: 0.8, 1: 0.8}, seed=420) \n",
    "train_1.groupby(\"label\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021673275190246507"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8727 / (8727 + 4017891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=1, count=2177), Row(label=0, count=1003829)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = train_temp.join(train_1, on=[\"user_id\",\"item_id\"], how=\"leftanti\") # удаляем train из train_temp\n",
    "test_1.groupby(\"label\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021640029979940476"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2177 / (2177 + 1003829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1.select(\"user_id\",\"item_id\",\"label\", \"features\").cache()\n",
    "train_1 = train_1.select(\"user_id\",\"item_id\", \"label\", \"features\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+--------------------+\n",
      "|user_id|item_id|label|            features|\n",
      "+-------+-------+-----+--------------------+\n",
      "|   1654|   7679|    0|[7.50750768929719...|\n",
      "|   1654|  10976|    0|[0.0,0.0019470405...|\n",
      "+-------+-------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------+-------+-----+--------------------+\n",
      "|user_id|item_id|label|            features|\n",
      "+-------+-------+-----+--------------------+\n",
      "| 867363|   1870|    0|[7.14285706635564...|\n",
      "| 867363|   2696|    0|[7.34753848519176...|\n",
      "+-------+-------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_1.show(2)\n",
    "train_1.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучаем логистическую регрессию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=15, regParam=0.1)\n",
    "lrModel = lr.fit(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_6e196eee0f9f, numClasses = 2, numFeatures = 4"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|user_id|item_id|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-------+-------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|   1654|   7679|    0|[7.50750768929719...|[6.14966692418366...|[0.99787035257797...|       0.0|\n",
      "|   1654|  10976|    0|[0.0,0.0019470405...|[6.15690461731163...|[0.99788567819493...|       0.0|\n",
      "+-------+-------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------\n",
      " user_id       | 1654                                       \n",
      " item_id       | 7679                                       \n",
      " label         | 0                                          \n",
      " prediction    | 0.0                                        \n",
      " probability   | [0.9978703525779781,0.0021296474220219284] \n",
      " rawPrediction | [6.14966692418366,-6.14966692418366]       \n",
      "-RECORD 1---------------------------------------------------\n",
      " user_id       | 1654                                       \n",
      " item_id       | 10976                                      \n",
      " label         | 0                                          \n",
      " prediction    | 0.0                                        \n",
      " probability   | [0.9978856781949366,0.0021143218050634293] \n",
      " rawPrediction | [6.156904617311632,-6.156904617311632]     \n",
      "-RECORD 2---------------------------------------------------\n",
      " user_id       | 1654                                       \n",
      " item_id       | 73179                                      \n",
      " label         | 0                                          \n",
      " prediction    | 0.0                                        \n",
      " probability   | [0.9978357509409913,0.0021642490590087038] \n",
      " rawPrediction | [6.133515238226524,-6.133515238226524]     \n",
      "-RECORD 3---------------------------------------------------\n",
      " user_id       | 1654                                       \n",
      " item_id       | 92392                                      \n",
      " label         | 0                                          \n",
      " prediction    | 0.0                                        \n",
      " probability   | [0.9978713531999328,0.0021286468000672213] \n",
      " rawPrediction | [6.15013789069651,-6.15013789069651]       \n",
      "-RECORD 4---------------------------------------------------\n",
      " user_id       | 1654                                       \n",
      " item_id       | 92533                                      \n",
      " label         | 0                                          \n",
      " prediction    | 0.0                                        \n",
      " probability   | [0.9978704640532923,0.0021295359467077605] \n",
      " rawPrediction | [6.149719381759708,-6.149719381759708]     \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"user_id\", \"item_id\", \"label\", \"prediction\", \"probability\", \"rawPrediction\").show(5, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003829"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = predictions.select(\"label\", F.col(\"prediction\").cast(\"int\")).filter(\"label == prediction\").count()\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006006"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions = predictions.count()\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.997835997002006\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}\".format(correct_predictions / all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUC is 0.927210409092778'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName='areaUnderROC')\n",
    "f\"AUC is {evaluator.evaluate(predictions)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "split1_udf = udf(lambda value: value[0].item(), DoubleType())\n",
    "split2_udf = udf(lambda value: value[1].item(), DoubleType())\n",
    "output2 = predictions.select(split1_udf('probability').alias('c1'), split2_udf('probability').alias('c2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|                c1|                  c2|\n",
      "+------------------+--------------------+\n",
      "|0.9978703525779781|0.002129647422021...|\n",
      "|0.9978856781949366|0.002114321805063...|\n",
      "|0.9978357509409913|0.002164249059008...|\n",
      "|0.9978713531999328|0.002128646800067...|\n",
      "|0.9978704640532923|0.002129535946707...|\n",
      "|0.9978133028391204|0.002186697160879...|\n",
      "|0.9978750668593972|0.002124933140602...|\n",
      "|0.9978765004872276|0.002123499512772252|\n",
      "|0.9978753510085504|0.002124648991449...|\n",
      "|0.9979187729598386|0.002081227040161...|\n",
      "|0.9979188325441605|0.002081167455839518|\n",
      "|0.9979021097204755|0.002097890279524491|\n",
      "| 0.997903704141627|0.002096295858372...|\n",
      "|0.9977551595296489|0.002244840470350993|\n",
      "|0.9977856537752533|0.002214346224746...|\n",
      "| 0.997833713498837|0.002166286501163053|\n",
      "|  0.99790306682705|0.002096933172949...|\n",
      "|0.9978781800077882|0.002121819992211...|\n",
      "|0.9976421530688276|0.002357846931172201|\n",
      "|0.9979033017518185|0.002096698248181...|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|            purchase|\n",
      "+-------+-------+--------------------+\n",
      "|   1654|    326|0.002129589647197...|\n",
      "|   1654|    546|0.002131562821532711|\n",
      "|   1654|    578|0.002128008501577888|\n",
      "|   1654|   1129| 0.00211705904692094|\n",
      "|   1654|   1151|0.002128412907188269|\n",
      "|   1654|   1222|0.002112812656592212|\n",
      "|   1654|   1320|0.002113101592667...|\n",
      "|   1654|   1599|0.002118676603218...|\n",
      "|   1654|   2304|0.002178204159580919|\n",
      "|   1654|   2327|0.002144677004588...|\n",
      "|   1654|   2562|0.002129773887399...|\n",
      "|   1654|   2736|0.002128469120898...|\n",
      "|   1654|   2785|0.002129390677483448|\n",
      "|   1654|   3099|0.002113431679722631|\n",
      "|   1654|   3159|0.002114995337311...|\n",
      "|   1654|   3408|0.002128377125996152|\n",
      "|   1654|   3686|0.002134608744897...|\n",
      "|   1654|   3692|0.002128329362527...|\n",
      "|   1654|   3764|0.002159065111895...|\n",
      "|   1654|   4255|0.002303861680495...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output3 = predictions.select('user_id', 'item_id', split2_udf('probability').alias('purchase')).sort(col(\"user_id\").asc(), col(\"item_id\").asc())\n",
    "\n",
    "output3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получаем предсказания для тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  94814|    null|\n",
      "|   1654|  93629|    null|\n",
      "|   1654|   9980|    null|\n",
      "|   1654|  95099|    null|\n",
      "|   1654|  11265|    null|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = test.join(items, on=\"item_id\", how=\"left\")\n",
    "test_temp.registerTempTable(\"test_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = test_temp.join(item_popularity, on=\"item_id\", how=\"left\")\n",
    "test_temp = test_temp.join(user_popularity, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+----------+---------------------------+--------------------------+-------------------+------------------+------------+--------------------+------+--------------------+---------+--------------------+--------------------+\n",
      "|user_id|item_id|purchase|channel_id|datetime_availability_start|datetime_availability_stop|datetime_show_start|datetime_show_stop|content_type|               title|  year|              genres|region_id|  mean_item_purchase|  mean_user_purchase|\n",
      "+-------+-------+--------+----------+---------------------------+--------------------------+-------------------+------------------+------------+--------------------+------+--------------------+---------+--------------------+--------------------+\n",
      "| 867363| 100263|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|           фортитьюд|2015.0|Ужасы,Детективы,Т...|     null|7.137758743754461E-4|3.892565200467107...|\n",
      "| 867363| 100735|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|сен-лоран. стиль ...|2014.0|Артхаус,Драмы,Мел...|     null|7.513148009015778E-4|3.892565200467107...|\n",
      "| 867363|   1159|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|               залив|2012.0|Ужасы,Триллеры,Фа...|     null|0.001470588235294...|3.892565200467107...|\n",
      "| 867363|  74605|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|   мой парень – псих|2012.0|Комедии,Драмы,Мел...|     null|                 0.0|3.892565200467107...|\n",
      "| 867363|  81824|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|      дети шпионов 4|2011.0|Приключения,Комед...|     null|0.002212389380530...|3.892565200467107...|\n",
      "+-------+-------+--------+----------+---------------------------+--------------------------+-------------------+------------------+------------+--------------------+------+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_temp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+----------+---------------------------+--------------------------+-------------------+------------------+------------+--------------------+------+---------+--------------------+--------------------+--------+\n",
      "|user_id|item_id|purchase|channel_id|datetime_availability_start|datetime_availability_stop|datetime_show_start|datetime_show_stop|content_type|               title|  year|region_id|  mean_item_purchase|  mean_user_purchase|genre_id|\n",
      "+-------+-------+--------+----------+---------------------------+--------------------------+-------------------+------------------+------------+--------------------+------+---------+--------------------+--------------------+--------+\n",
      "| 867363| 100263|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|           фортитьюд|2015.0|     null|7.137758743754461E-4|3.892565200467107...|   211.0|\n",
      "| 867363| 100735|    null|      null|       1970-01-01T00:00:00Z|      2099-12-31T21:00:00Z|               null|              null|           1|сен-лоран. стиль ...|2014.0|     null|7.513148009015778E-4|3.892565200467107...|   525.0|\n",
      "+-------+-------+--------+----------+---------------------------+--------------------------+-------------------+------------------+------------+--------------------+------+---------+--------------------+--------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обрабатываем genres\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "test_temp = test_temp.na.fill({'genres':'NA'})\n",
    "indexer = StringIndexer(inputCol=\"genres\", outputCol=\"genre_id\") \n",
    "test_temp = indexer.fit(test_temp).transform(test_temp) \n",
    "test_temp = test_temp.drop(\"genres\").cache()\n",
    "test_temp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = test_temp.select(F.col(\"item_id\").cast(\"int\"),\n",
    "                               F.col(\"mean_item_purchase\").cast(\"float\"),\n",
    "                               F.col(\"user_id\").cast(\"int\"),\n",
    "                               F.col(\"mean_user_purchase\").cast(\"float\"),\n",
    "                               F.col(\"purchase\").alias(\"label\").cast(\"int\"),\n",
    "                               F.col(\"year\").cast(\"int\"),\n",
    "                               F.col(\"genre_id\").cast(\"int\"))                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- mean_item_purchase: float (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- mean_user_purchase: float (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- genre_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = test_temp.na.fill({'item_id':-1, 'user_id':-1, \n",
    "                                 'year':1970,'label':0,\n",
    "                                 'mean_user_purchase':0, 'mean_item_purchase':0})\n",
    "test_temp = test_temp.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = ['mean_item_purchase', 'mean_user_purchase', 'year', 'genre_id',]\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = assembler.transform(test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+--------------------+\n",
      "|user_id|item_id|label|            features|\n",
      "+-------+-------+-----+--------------------+\n",
      "| 867363| 100263|    0|[7.13775865733623...|\n",
      "| 867363| 100735|    0|[7.51314801163971...|\n",
      "+-------+-------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_2 = test_temp.select(\"user_id\",\"item_id\",\"label\", \"features\").cache()\n",
    "test_2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lrModel.transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|            purchase|\n",
      "+-------+-------+--------------------+\n",
      "|   1654|    336|0.002119602484666343|\n",
      "|   1654|    678|0.002113261943042748|\n",
      "|   1654|    691|0.002115212340866...|\n",
      "|   1654|    696|0.002144055122632...|\n",
      "|   1654|    763|0.002128888764552467|\n",
      "|   1654|    795|0.002253850565441...|\n",
      "|   1654|    861|0.002128437574394...|\n",
      "|   1654|   1137|0.002176917673465034|\n",
      "|   1654|   1159|0.002143780491118...|\n",
      "|   1654|   1428|0.002129223734127575|\n",
      "|   1654|   1685|0.002150379840219...|\n",
      "|   1654|   1686|0.002128689955180...|\n",
      "|   1654|   1704|0.002159207567787...|\n",
      "|   1654|   2093|0.002114690855248161|\n",
      "|   1654|   2343|0.002128177669228...|\n",
      "|   1654|   2451|0.002116602505044414|\n",
      "|   1654|   2469|0.002338780263039...|\n",
      "|   1654|   2603|0.002132505102742692|\n",
      "|   1654|   2609|0.002120341450096642|\n",
      "|   1654|   2621|0.002143659616926...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = predictions_test.select('user_id', 'item_id', split2_udf('probability').alias('purchase')).sort(col(\"user_id\").asc(), col(\"item_id\").asc())\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.toPandas().to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.write.csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654</td>\n",
       "      <td>336</td>\n",
       "      <td>0.002120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654</td>\n",
       "      <td>678</td>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654</td>\n",
       "      <td>691</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1654</td>\n",
       "      <td>696</td>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1654</td>\n",
       "      <td>763</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  purchase\n",
       "0     1654      336  0.002120\n",
       "1     1654      678  0.002113\n",
       "2     1654      691  0.002115\n",
       "3     1654      696  0.002144\n",
       "4     1654      763  0.002129"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = output.toPandas()\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-e3826cbd1782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "preds = preds.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Записываем предсказания в файл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('lab03.json', 'w', encoding='utf-8') as w:\n",
    "    json.dump(preds, w, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"200\" height=\"200\" src=\"https://static.tildacdn.com/tild6236-6337-4339-b337-313363643735/new_logo.png\">\n",
    "\n",
    "# Spark Structured Streaming I\n",
    "**Андрей Титов**  \n",
    "tenke.iu8@gmail.com  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На этом занятии\n",
    "+ Общие сведения\n",
    "+ Rate streaming\n",
    "+ File streaming\n",
    "+ Kafka streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие сведения\n",
    "\n",
    "Системы поточной обработки данных:\n",
    "- работают с непрерывным потоком данных\n",
    "- нужно хранить состояние стрима\n",
    "- результат обработки быстро появляется в целевой системе\n",
    "- должны проектироваться с учетом требований к высокой доступности\n",
    "- важная скорость обработки данных и время зажержки (лаг)\n",
    "\n",
    "### Примеры систем поточной обработки данных\n",
    "\n",
    "#### Карточный процессинг\n",
    "- нельзя терять платежи\n",
    "- нельзя дублировать платежи\n",
    "- простой сервиса недопустим\n",
    "- максимальное время задержки ~ 1 сек\n",
    "- небольшой поток событий\n",
    "- OLTP\n",
    "\n",
    "#### Обработка логов безопасности\n",
    "- потеря единичных событий допустима\n",
    "- дублирование единичных событий допустимо\n",
    "- простой сервиса допустим\n",
    "- максимальное время задержки ~ 1 час\n",
    "- большой поток событий\n",
    "- OLAP\n",
    "\n",
    "### Виды стриминг систем\n",
    "\n",
    "#### Real-time streaming\n",
    "- низкие задержки на обработку\n",
    "- низкая пропускная способность\n",
    "- подходят для критичных систем\n",
    "- пособытийная обработка\n",
    "- OLTP\n",
    "- exactly once consistency (нет потери данных и нет дубликатов)\n",
    "\n",
    "#### Micro batch streaming\n",
    "- высокие задержки\n",
    "- высокая пропускная способность\n",
    "- не подходят для критичных систем\n",
    "- обработка батчами\n",
    "- OLAP\n",
    "- at least once consistency (во время сбоев могут возникать дубликаты)\n",
    "\n",
    "### Выводы:\n",
    "+ Существуют два типа систем поточной обработки данных - real-time и micro-batch\n",
    "+ Spark Structured Streaming является micro-batch системой\n",
    "+ При работе с большими данными обычно пропускная способность важнее, чем время задержки\n",
    "\n",
    "\n",
    "## Rate streaming\n",
    "\n",
    "Самый простой способ создать стрим - использовать `rate` источник. Созданный DF является streaming, о чем нам говорит метод создания `readStream` и атрибут `isStreaming`. `rate` хорошо подходит для тестирования приложений, когда нет возможности подключится к потоку реальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 8 pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"lab3 lr ALS app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-3.newprolab.com:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab3 lr ALS app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4b97951d68>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType , StringType , ArrayType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs  655090069 2021-02-27 22:13 /labs/slaba04/gender_age_dataset.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /labs/slaba04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('gender', StringType()), \n",
    "                     StructField('age', StringType()),\n",
    "                     StructField('uid', StringType()),\n",
    "                     StructField('user_json', StringType())\n",
    "                    ]\n",
    "                   )\n",
    "train_data = spark.read.format(\"csv\")\\\n",
    "                       .option(\"inferSchema\", \"true\")\\\n",
    "                       .schema(schema)\\\n",
    "                       .option(\"header\", \"true\")\\\n",
    "                       .option(\"delimiter\", \"\\\\t\")\\\n",
    "                       .load(\"/labs/slaba04/gender_age_dataset.txt\")\n",
    "visits_schema = StructType([\n",
    "    StructField(\"visits\", ArrayType(\n",
    "      StructType([\n",
    "          StructField(\"url\", StringType()),\n",
    "          StructField(\"timestamp\", LongType())\n",
    "      ])\n",
    "   ))\n",
    "]) \n",
    "train_data = train_data.withColumn('visits', \n",
    "                                   F.from_json(F.col('user_json'),\n",
    "                                               schema=visits_schema)\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     F|17440|\n",
      "|     M|18698|\n",
      "|     -| 5000|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupby('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|  age|count|\n",
      "+-----+-----+\n",
      "| >=55| 1679|\n",
      "|45-54| 4744|\n",
      "|    -| 5000|\n",
      "|35-44| 9360|\n",
      "|25-34|15457|\n",
      "|18-24| 4898|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupby('age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.withColumn('urls' , train_data['visits']['visits']['url'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.withColumn(\"urls_hosts\", F.expr(\"transform(urls, x -> parse_url(x, 'HOST' ))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.show()\n",
    "\n",
    "# train_data.limit(100).toPandas()['urls_hosts'][0]\n",
    "\n",
    "# train_data.limit(100).toPandas()['urls'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py:2111: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n",
      "  Unsupported type in conversion to Arrow: StructType(List(StructField(visits,ArrayType(StructType(List(StructField(url,StringType,true),StructField(timestamp,LongType,true))),true),true)))\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['zebra-zoya.ru',\n",
       " 'news.yandex.ru',\n",
       " 'www.sotovik.ru',\n",
       " 'news.yandex.ru',\n",
       " 'www.sotovik.ru']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.limit(100).toPandas()['urls_hosts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- user_json: string (nullable = true)\n",
      " |-- visits: struct (nullable = true)\n",
      " |    |-- visits: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- timestamp: long (nullable = true)\n",
      " |-- urls: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- urls_hosts: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБучаем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[gender: string, age: string, uid: string, user_json: string, visits: struct<visits:array<struct<url:string,timestamp:bigint>>>, urls: array<string>, urls_hosts: array<string>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.withColumn(\"gender_label\", F.when(F.col(\"gender\")=='F', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.withColumn(\"age_label\", F.when(F.col(\"age\")=='18-24', 0) \\\n",
    "                                   .when(F.col(\"age\")=='25-34', 1).when(F.col(\"age\")=='35-44', 2) \\\n",
    "                                   .when(F.col(\"age\")=='45-54', 3).otherwise(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119009\n"
     ]
    }
   ],
   "source": [
    "urls = train_data.rdd.flatMap(lambda x: x[6])\n",
    "num_urls = urls.groupBy(lambda x: x).count()\n",
    "\n",
    "print(num_urls)\n",
    "print(urls.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем поменьше num_urls = 10000\n",
    "\n",
    "num_urls = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"urls_hosts\", outputCol=\"rawFeatures\", numFeatures=num_urls)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[gender: string, age: string, uid: string, user_json: string, visits: struct<visits:array<struct<url:string,timestamp:bigint>>>, urls: array<string>, urls_hosts: array<string>, gender_label: int, age_label: int]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гендер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gender = LogisticRegression(featuresCol=\"features\",\n",
    "                            rawPredictionCol='rawPred_gender',\n",
    "                            predictionCol='pred_gender',\n",
    "                            labelCol=\"gender_label\",\n",
    "                            maxIter=100, regParam=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gender = Pipeline(stages=[hashingTF, idf, lr_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.sampleBy(\"gender_label\", fractions={0: 0.8, 1: 0.8}, seed=42)\n",
    "test = train_data.join(train, on=\"uid\", how=\"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gender = pipe_gender.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid', 'gender', 'age', 'user_json', 'visits', 'urls', 'urls_hosts', 'gender_label', 'age_label', 'rawFeatures', 'features', 'rawPred_gender', 'probability', 'pred_gender']\n"
     ]
    }
   ],
   "source": [
    "pred_gender = pipeline_gender.transform(test)\n",
    "print(pred_gender.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_gender = BinaryClassificationEvaluator(rawPredictionCol=\"probability\",\n",
    "                                          labelCol=\"gender_label\", metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6395395682104358"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_gender.evaluate(pred_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_age = LogisticRegression(featuresCol=\"features\",\n",
    "                            rawPredictionCol='rawPred_age',\n",
    "                            predictionCol='pred_age',\n",
    "                            labelCol=\"age_label\",\n",
    "                            maxIter=100, regParam=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_age = Pipeline(stages=[hashingTF, idf, lr_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.sampleBy(\"age_label\", fractions={0: 0.8, 1: 0.8, 2:0.8, 3:0.8, 4:0.8}, seed=42)\n",
    "test = train_data.join(train, on=\"uid\", how=\"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_age = pipe_age.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid', 'gender', 'age', 'user_json', 'visits', 'urls', 'urls_hosts', 'gender_label', 'age_label', 'rawFeatures', 'features', 'rawPred_age', 'probability', 'pred_age']\n"
     ]
    }
   ],
   "source": [
    "pred_age = pipeline_age.transform(test)\n",
    "print(pred_age.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_age = MulticlassClassificationEvaluator(labelCol=\"age_label\",\n",
    "                                                  predictionCol=\"pred_age\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2411948580754272"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_age.evaluate(pred_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Стримингоыфй вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kafka_params = {\n",
    "#     \"kafka.bootstrap.servers\": \"localhost:9092\",\n",
    "#     \"subscribe\": \"test_topic0\",\n",
    "#     \"startingOffsets\": \"\"\"earliest\"\"\",\n",
    "#     \"maxOffsetsPerTrigger\": \"5\"\n",
    "# }\n",
    "\n",
    "# sdf = spark.readStream.format(\"kafka\").options(**kafka_params).load()\n",
    "# parsed_sdf = sdf.select(col(\"value\").cast(\"string\"), col(\"topic\"), col(\"partition\"), col(\"offset\"))\n",
    "\n",
    "# sink = create_console_sink(parsed_sdf)\n",
    "\n",
    "# sq = sink.start()\n",
    "\n",
    "# def create_console_sink_with_checkpoint(chk_name, df): \n",
    "#     return df \\\n",
    "#         .writeStream \\\n",
    "#         .format(\"console\") \\\n",
    "#         .trigger(processingTime=\"10 seconds\") \\\n",
    "#         .option(\"checkpointLocation\", \"chk/{n}\".format(n=chk_name)) \\\n",
    "#         .option(\"truncate\", \"false\") \\\n",
    "#         .option(\"numRows\", \"20\")\n",
    "\n",
    "# sink = create_console_sink_with_checkpoint(\"test0\", parsed_sdf)\n",
    "# sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"lab3 lr ALS app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-3.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab3 lr ALS app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6f24f77128>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-node-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_alexander.okhilkov\",\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "\n",
    "# read readStream\n",
    "kafka_sdf_sh = spark.readStream.format(\"kafka\").options(**read_kafka_params).option(\"failOnDataLoss\", 'False').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.withColumn(\"value\", kafka_sdf_sh[\"value\"].cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('gender', StringType()), \n",
    "                     StructField('age', StringType()),\n",
    "                     StructField('uid', StringType()),\n",
    "                     StructField('user_json', StringType())\n",
    "                    ]\n",
    "                   )\n",
    "\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('value_parsed', \n",
    "                                   F.from_json(F.col('value'),\n",
    "                                               schema=schema)\n",
    "                                      )\n",
    "\n",
    "\n",
    "# kafka_sdf_sh=kafka_sdf_sh.withColumn('gender', kafka_sdf_sh['value_parsed']['gender'])\n",
    "# kafka_sdf_sh=kafka_sdf_sh.withColumn('age', kafka_sdf_sh['value_parsed']['age'])\n",
    "kafka_sdf_sh=kafka_sdf_sh.withColumn('uid', kafka_sdf_sh['value_parsed']['uid'])\n",
    "kafka_sdf_sh=kafka_sdf_sh.withColumn('user_json', kafka_sdf_sh['value_parsed']['user_json'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "visits_schema = StructType([\n",
    "    StructField(\"visits\", ArrayType(\n",
    "      StructType([\n",
    "          StructField(\"url\", StringType()),\n",
    "          StructField(\"timestamp\", LongType())\n",
    "      ])\n",
    "   ))\n",
    "]) \n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('visits', \n",
    "                                   F.from_json(F.col('user_json'),\n",
    "                                               schema=visits_schema)\n",
    "                                              )\n",
    "\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('urls' , kafka_sdf_sh['visits']['visits']['url'] )\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn(\"urls_hosts\", F.expr(\"transform(urls, x -> parse_url(x, 'HOST' ))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: string, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int, value_parsed: struct<gender:string,age:string,uid:string,user_json:string>, uid: string, user_json: string, visits: struct<visits:array<struct<url:string,timestamp:bigint>>>, urls: array<string>, urls_hosts: array<string>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.select(['uid']).withColumn('gender', F.lit('M'))\\\n",
    "                            .withColumn('age', F.lit('25-34'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('key',  F.lit(None) )\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('value',  F.to_json(F.struct(\"uid\",\"gender\",\"age\")) )                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.select('key' , 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: null, value: string]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = kafka_sdf_sh \\\n",
    "        .select('key' , 'value').selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "        .writeStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", 'spark-node-1.newprolab.com:6667') \\\n",
    "        .option(\"topic\", 'alexander.okhilkov') \\\n",
    "        .option(\"checkpointLocation\", \"streaming/chk/chk_kafka/rr\" ) \\\n",
    "        .outputMode(\"append\")\n",
    "\n",
    "# .trigger(processingTime=\"10 seconds\") \\\n",
    "#         .option(\"checkpointLocation\", \"streaming/chk/chk_kafka\" ) \\\n",
    "#         .option(\"truncate\", \"false\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       " 'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       " 'name': None,\n",
       " 'timestamp': '2021-03-22T20:28:44.196Z',\n",
       " 'batchId': 41,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'getEndOffset': 0, 'setOffsetRange': 2, 'triggerExecution': 2},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "   'startOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "   'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:27:50.485Z',\n",
       "  'batchId': 1,\n",
       "  'numInputRows': 1,\n",
       "  'processedRowsPerSecond': 0.0759589821496392,\n",
       "  'durationMs': {'addBatch': 12620,\n",
       "   'getBatch': 10,\n",
       "   'queryPlanning': 64,\n",
       "   'triggerExecution': 13165},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5001}},\n",
       "    'numInputRows': 1,\n",
       "    'processedRowsPerSecond': 0.0759589821496392}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:03.711Z',\n",
       "  'batchId': 2,\n",
       "  'numInputRows': 405,\n",
       "  'inputRowsPerSecond': 30.621503099954634,\n",
       "  'processedRowsPerSecond': 76.96693272519956,\n",
       "  'durationMs': {'addBatch': 807,\n",
       "   'getBatch': 11,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 175,\n",
       "   'setOffsetRange': 3337,\n",
       "   'triggerExecution': 5262,\n",
       "   'walCommit': 672},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5001}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5406}},\n",
       "    'numInputRows': 405,\n",
       "    'inputRowsPerSecond': 30.621503099954634,\n",
       "    'processedRowsPerSecond': 76.96693272519956}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:08.974Z',\n",
       "  'batchId': 3,\n",
       "  'numInputRows': 190,\n",
       "  'inputRowsPerSecond': 36.101083032490976,\n",
       "  'processedRowsPerSecond': 231.990231990232,\n",
       "  'durationMs': {'addBatch': 466,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 88,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 819,\n",
       "   'walCommit': 136},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5406}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5596}},\n",
       "    'numInputRows': 190,\n",
       "    'inputRowsPerSecond': 36.101083032490976,\n",
       "    'processedRowsPerSecond': 231.990231990232}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:09.793Z',\n",
       "  'batchId': 4,\n",
       "  'numInputRows': 74,\n",
       "  'inputRowsPerSecond': 90.35409035409036,\n",
       "  'processedRowsPerSecond': 147.70459081836327,\n",
       "  'durationMs': {'addBatch': 194,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 106,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 501,\n",
       "   'walCommit': 101},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5596}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5670}},\n",
       "    'numInputRows': 74,\n",
       "    'inputRowsPerSecond': 90.35409035409036,\n",
       "    'processedRowsPerSecond': 147.70459081836327}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:10.295Z',\n",
       "  'batchId': 5,\n",
       "  'numInputRows': 32,\n",
       "  'inputRowsPerSecond': 63.745019920318725,\n",
       "  'processedRowsPerSecond': 61.65703275529865,\n",
       "  'durationMs': {'addBatch': 161,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 59,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 519,\n",
       "   'walCommit': 143},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5670}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5702}},\n",
       "    'numInputRows': 32,\n",
       "    'inputRowsPerSecond': 63.745019920318725,\n",
       "    'processedRowsPerSecond': 61.65703275529865}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:10.815Z',\n",
       "  'batchId': 6,\n",
       "  'numInputRows': 30,\n",
       "  'inputRowsPerSecond': 57.69230769230769,\n",
       "  'processedRowsPerSecond': 53.28596802841919,\n",
       "  'durationMs': {'addBatch': 183,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 162,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 563,\n",
       "   'walCommit': 74},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5702}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5732}},\n",
       "    'numInputRows': 30,\n",
       "    'inputRowsPerSecond': 57.69230769230769,\n",
       "    'processedRowsPerSecond': 53.28596802841919}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:11.378Z',\n",
       "  'batchId': 7,\n",
       "  'numInputRows': 85,\n",
       "  'inputRowsPerSecond': 150.97690941385437,\n",
       "  'processedRowsPerSecond': 174.53798767967146,\n",
       "  'durationMs': {'addBatch': 166,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 57,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 487,\n",
       "   'walCommit': 60},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5732}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5817}},\n",
       "    'numInputRows': 85,\n",
       "    'inputRowsPerSecond': 150.97690941385437,\n",
       "    'processedRowsPerSecond': 174.53798767967146}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:11.884Z',\n",
       "  'batchId': 8,\n",
       "  'numInputRows': 77,\n",
       "  'inputRowsPerSecond': 152.17391304347825,\n",
       "  'processedRowsPerSecond': 140.51094890510947,\n",
       "  'durationMs': {'addBatch': 204,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 170,\n",
       "   'setOffsetRange': 11,\n",
       "   'triggerExecution': 548,\n",
       "   'walCommit': 116},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5817}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5894}},\n",
       "    'numInputRows': 77,\n",
       "    'inputRowsPerSecond': 152.17391304347825,\n",
       "    'processedRowsPerSecond': 140.51094890510947}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:12.432Z',\n",
       "  'batchId': 9,\n",
       "  'numInputRows': 73,\n",
       "  'inputRowsPerSecond': 133.21167883211677,\n",
       "  'processedRowsPerSecond': 114.77987421383648,\n",
       "  'durationMs': {'addBatch': 181,\n",
       "   'getBatch': 2,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 81,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 612,\n",
       "   'walCommit': 171},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5894}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5967}},\n",
       "    'numInputRows': 73,\n",
       "    'inputRowsPerSecond': 133.21167883211677,\n",
       "    'processedRowsPerSecond': 114.77987421383648}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:13.068Z',\n",
       "  'batchId': 10,\n",
       "  'numInputRows': 91,\n",
       "  'inputRowsPerSecond': 143.0817610062893,\n",
       "  'processedRowsPerSecond': 166.05839416058393,\n",
       "  'durationMs': {'addBatch': 162,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 72,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 548,\n",
       "   'walCommit': 115},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5967}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6058}},\n",
       "    'numInputRows': 91,\n",
       "    'inputRowsPerSecond': 143.0817610062893,\n",
       "    'processedRowsPerSecond': 166.05839416058393}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:13.616Z',\n",
       "  'batchId': 11,\n",
       "  'numInputRows': 104,\n",
       "  'inputRowsPerSecond': 189.7810218978102,\n",
       "  'processedRowsPerSecond': 190.82568807339447,\n",
       "  'durationMs': {'addBatch': 280,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 46,\n",
       "   'setOffsetRange': 4,\n",
       "   'triggerExecution': 545,\n",
       "   'walCommit': 104},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6058}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6162}},\n",
       "    'numInputRows': 104,\n",
       "    'inputRowsPerSecond': 189.7810218978102,\n",
       "    'processedRowsPerSecond': 190.82568807339447}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:14.161Z',\n",
       "  'batchId': 12,\n",
       "  'numInputRows': 75,\n",
       "  'inputRowsPerSecond': 137.61467889908255,\n",
       "  'processedRowsPerSecond': 175.2336448598131,\n",
       "  'durationMs': {'addBatch': 175,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 98,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 428,\n",
       "   'walCommit': 67},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6162}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6237}},\n",
       "    'numInputRows': 75,\n",
       "    'inputRowsPerSecond': 137.61467889908255,\n",
       "    'processedRowsPerSecond': 175.2336448598131}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:14.590Z',\n",
       "  'batchId': 13,\n",
       "  'numInputRows': 87,\n",
       "  'inputRowsPerSecond': 202.7972027972028,\n",
       "  'processedRowsPerSecond': 159.04936014625227,\n",
       "  'durationMs': {'addBatch': 173,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 43,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 547,\n",
       "   'walCommit': 41},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6237}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6324}},\n",
       "    'numInputRows': 87,\n",
       "    'inputRowsPerSecond': 202.7972027972028,\n",
       "    'processedRowsPerSecond': 159.04936014625227}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:15.196Z',\n",
       "  'batchId': 14,\n",
       "  'numInputRows': 90,\n",
       "  'inputRowsPerSecond': 148.5148514851485,\n",
       "  'processedRowsPerSecond': 94.83667017913594,\n",
       "  'durationMs': {'addBatch': 268,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 184,\n",
       "   'setOffsetRange': 81,\n",
       "   'triggerExecution': 949,\n",
       "   'walCommit': 309},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6324}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6414}},\n",
       "    'numInputRows': 90,\n",
       "    'inputRowsPerSecond': 148.5148514851485,\n",
       "    'processedRowsPerSecond': 94.83667017913594}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:16.146Z',\n",
       "  'batchId': 15,\n",
       "  'numInputRows': 142,\n",
       "  'inputRowsPerSecond': 149.47368421052633,\n",
       "  'processedRowsPerSecond': 272.55278310940497,\n",
       "  'durationMs': {'addBatch': 238,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 71,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 521,\n",
       "   'walCommit': 135},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6414}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6556}},\n",
       "    'numInputRows': 142,\n",
       "    'inputRowsPerSecond': 149.47368421052633,\n",
       "    'processedRowsPerSecond': 272.55278310940497}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:16.668Z',\n",
       "  'batchId': 16,\n",
       "  'numInputRows': 70,\n",
       "  'inputRowsPerSecond': 134.09961685823754,\n",
       "  'processedRowsPerSecond': 48.40940525587828,\n",
       "  'durationMs': {'addBatch': 376,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 921,\n",
       "   'setOffsetRange': 20,\n",
       "   'triggerExecution': 1446,\n",
       "   'walCommit': 58},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6556}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6626}},\n",
       "    'numInputRows': 70,\n",
       "    'inputRowsPerSecond': 134.09961685823754,\n",
       "    'processedRowsPerSecond': 48.40940525587828}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:18.114Z',\n",
       "  'batchId': 17,\n",
       "  'numInputRows': 134,\n",
       "  'inputRowsPerSecond': 92.66943291839557,\n",
       "  'processedRowsPerSecond': 222.96173044925126,\n",
       "  'durationMs': {'addBatch': 214,\n",
       "   'getBatch': 5,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 123,\n",
       "   'setOffsetRange': 12,\n",
       "   'triggerExecution': 601,\n",
       "   'walCommit': 189},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6626}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6760}},\n",
       "    'numInputRows': 134,\n",
       "    'inputRowsPerSecond': 92.66943291839557,\n",
       "    'processedRowsPerSecond': 222.96173044925126}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:18.716Z',\n",
       "  'batchId': 18,\n",
       "  'numInputRows': 122,\n",
       "  'inputRowsPerSecond': 202.65780730897012,\n",
       "  'processedRowsPerSecond': 232.38095238095238,\n",
       "  'durationMs': {'addBatch': 302,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 45,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 525,\n",
       "   'walCommit': 78},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6760}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6882}},\n",
       "    'numInputRows': 122,\n",
       "    'inputRowsPerSecond': 202.65780730897012,\n",
       "    'processedRowsPerSecond': 232.38095238095238}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:19.242Z',\n",
       "  'batchId': 19,\n",
       "  'numInputRows': 80,\n",
       "  'inputRowsPerSecond': 152.0912547528517,\n",
       "  'processedRowsPerSecond': 134.0033500837521,\n",
       "  'durationMs': {'addBatch': 170,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 48,\n",
       "   'setOffsetRange': 13,\n",
       "   'triggerExecution': 597,\n",
       "   'walCommit': 83},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6882}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6962}},\n",
       "    'numInputRows': 80,\n",
       "    'inputRowsPerSecond': 152.0912547528517,\n",
       "    'processedRowsPerSecond': 134.0033500837521}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:19.848Z',\n",
       "  'batchId': 20,\n",
       "  'numInputRows': 99,\n",
       "  'inputRowsPerSecond': 163.36633663366337,\n",
       "  'processedRowsPerSecond': 56.25,\n",
       "  'durationMs': {'addBatch': 484,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 49,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1760,\n",
       "   'walCommit': 66},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6962}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7061}},\n",
       "    'numInputRows': 99,\n",
       "    'inputRowsPerSecond': 163.36633663366337,\n",
       "    'processedRowsPerSecond': 56.25}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:21.614Z',\n",
       "  'batchId': 21,\n",
       "  'numInputRows': 326,\n",
       "  'inputRowsPerSecond': 184.59796149490373,\n",
       "  'processedRowsPerSecond': 346.8085106382979,\n",
       "  'durationMs': {'addBatch': 459,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 157,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 940,\n",
       "   'walCommit': 213},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7061}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7387}},\n",
       "    'numInputRows': 326,\n",
       "    'inputRowsPerSecond': 184.59796149490373,\n",
       "    'processedRowsPerSecond': 346.8085106382979}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:22.554Z',\n",
       "  'batchId': 22,\n",
       "  'numInputRows': 158,\n",
       "  'inputRowsPerSecond': 168.08510638297872,\n",
       "  'processedRowsPerSecond': 149.33837429111531,\n",
       "  'durationMs': {'addBatch': 234,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 65,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1058,\n",
       "   'walCommit': 655},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7387}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7545}},\n",
       "    'numInputRows': 158,\n",
       "    'inputRowsPerSecond': 168.08510638297872,\n",
       "    'processedRowsPerSecond': 149.33837429111531}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:23.613Z',\n",
       "  'batchId': 23,\n",
       "  'numInputRows': 157,\n",
       "  'inputRowsPerSecond': 148.2530689329556,\n",
       "  'processedRowsPerSecond': 296.2264150943396,\n",
       "  'durationMs': {'addBatch': 246,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 105,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 530,\n",
       "   'walCommit': 117},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7545}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7702}},\n",
       "    'numInputRows': 157,\n",
       "    'inputRowsPerSecond': 148.2530689329556,\n",
       "    'processedRowsPerSecond': 296.2264150943396}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:24.144Z',\n",
       "  'batchId': 24,\n",
       "  'numInputRows': 85,\n",
       "  'inputRowsPerSecond': 160.07532956685498,\n",
       "  'processedRowsPerSecond': 137.76337115072934,\n",
       "  'durationMs': {'addBatch': 248,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 57,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 617,\n",
       "   'walCommit': 72},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7702}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7787}},\n",
       "    'numInputRows': 85,\n",
       "    'inputRowsPerSecond': 160.07532956685498,\n",
       "    'processedRowsPerSecond': 137.76337115072934}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:24.761Z',\n",
       "  'batchId': 25,\n",
       "  'numInputRows': 91,\n",
       "  'inputRowsPerSecond': 147.4878444084279,\n",
       "  'processedRowsPerSecond': 46.09929078014184,\n",
       "  'durationMs': {'addBatch': 224,\n",
       "   'getBatch': 8,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 178,\n",
       "   'setOffsetRange': 33,\n",
       "   'triggerExecution': 1974,\n",
       "   'walCommit': 1377},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7787}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7878}},\n",
       "    'numInputRows': 91,\n",
       "    'inputRowsPerSecond': 147.4878444084279,\n",
       "    'processedRowsPerSecond': 46.09929078014184}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:26.736Z',\n",
       "  'batchId': 26,\n",
       "  'numInputRows': 299,\n",
       "  'inputRowsPerSecond': 151.39240506329114,\n",
       "  'processedRowsPerSecond': 644.3965517241379,\n",
       "  'durationMs': {'addBatch': 229,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 46,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 464,\n",
       "   'walCommit': 121},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7878}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8177}},\n",
       "    'numInputRows': 299,\n",
       "    'inputRowsPerSecond': 151.39240506329114,\n",
       "    'processedRowsPerSecond': 644.3965517241379}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:27.200Z',\n",
       "  'batchId': 27,\n",
       "  'numInputRows': 168,\n",
       "  'inputRowsPerSecond': 362.06896551724134,\n",
       "  'processedRowsPerSecond': 685.7142857142858,\n",
       "  'durationMs': {'addBatch': 122,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 44,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 245,\n",
       "   'walCommit': 34},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8177}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8345}},\n",
       "    'numInputRows': 168,\n",
       "    'inputRowsPerSecond': 362.06896551724134,\n",
       "    'processedRowsPerSecond': 685.7142857142858}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:27.446Z',\n",
       "  'batchId': 28,\n",
       "  'numInputRows': 46,\n",
       "  'inputRowsPerSecond': 186.9918699186992,\n",
       "  'processedRowsPerSecond': 32.07810320781032,\n",
       "  'durationMs': {'addBatch': 700,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 38,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1434,\n",
       "   'walCommit': 39},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8345}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8391}},\n",
       "    'numInputRows': 46,\n",
       "    'inputRowsPerSecond': 186.9918699186992,\n",
       "    'processedRowsPerSecond': 32.07810320781032}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:28.880Z',\n",
       "  'batchId': 29,\n",
       "  'numInputRows': 258,\n",
       "  'inputRowsPerSecond': 179.91631799163181,\n",
       "  'processedRowsPerSecond': 602.803738317757,\n",
       "  'durationMs': {'addBatch': 250,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 32,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 428,\n",
       "   'walCommit': 84},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8391}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8649}},\n",
       "    'numInputRows': 258,\n",
       "    'inputRowsPerSecond': 179.91631799163181,\n",
       "    'processedRowsPerSecond': 602.803738317757}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:29.309Z',\n",
       "  'batchId': 30,\n",
       "  'numInputRows': 152,\n",
       "  'inputRowsPerSecond': 354.31235431235433,\n",
       "  'processedRowsPerSecond': 183.13253012048193,\n",
       "  'durationMs': {'addBatch': 126,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 61,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 830,\n",
       "   'walCommit': 90},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8649}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8801}},\n",
       "    'numInputRows': 152,\n",
       "    'inputRowsPerSecond': 354.31235431235433,\n",
       "    'processedRowsPerSecond': 183.13253012048193}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:30.139Z',\n",
       "  'batchId': 31,\n",
       "  'numInputRows': 222,\n",
       "  'inputRowsPerSecond': 267.4698795180723,\n",
       "  'processedRowsPerSecond': 497.7578475336323,\n",
       "  'durationMs': {'addBatch': 188,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 36,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 446,\n",
       "   'walCommit': 139},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8801}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9023}},\n",
       "    'numInputRows': 222,\n",
       "    'inputRowsPerSecond': 267.4698795180723,\n",
       "    'processedRowsPerSecond': 497.7578475336323}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:30.586Z',\n",
       "  'batchId': 32,\n",
       "  'numInputRows': 88,\n",
       "  'inputRowsPerSecond': 196.86800894854585,\n",
       "  'processedRowsPerSecond': 341.08527131782944,\n",
       "  'durationMs': {'addBatch': 104,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 26,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 258,\n",
       "   'walCommit': 79},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9023}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9111}},\n",
       "    'numInputRows': 88,\n",
       "    'inputRowsPerSecond': 196.86800894854585,\n",
       "    'processedRowsPerSecond': 341.08527131782944}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:30.844Z',\n",
       "  'batchId': 33,\n",
       "  'numInputRows': 96,\n",
       "  'inputRowsPerSecond': 372.09302325581393,\n",
       "  'processedRowsPerSecond': 111.49825783972126,\n",
       "  'durationMs': {'addBatch': 106,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 34,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 861,\n",
       "   'walCommit': 248},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9111}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9207}},\n",
       "    'numInputRows': 96,\n",
       "    'inputRowsPerSecond': 372.09302325581393,\n",
       "    'processedRowsPerSecond': 111.49825783972126}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:31.705Z',\n",
       "  'batchId': 34,\n",
       "  'numInputRows': 253,\n",
       "  'inputRowsPerSecond': 293.8443670150987,\n",
       "  'processedRowsPerSecond': 615.5717761557178,\n",
       "  'durationMs': {'addBatch': 203,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 38,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 411,\n",
       "   'walCommit': 94},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9207}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9460}},\n",
       "    'numInputRows': 253,\n",
       "    'inputRowsPerSecond': 293.8443670150987,\n",
       "    'processedRowsPerSecond': 615.5717761557178}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.117Z',\n",
       "  'batchId': 35,\n",
       "  'numInputRows': 112,\n",
       "  'inputRowsPerSecond': 271.84466019417476,\n",
       "  'processedRowsPerSecond': 346.7492260061919,\n",
       "  'durationMs': {'addBatch': 150,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 58,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 323,\n",
       "   'walCommit': 64},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9460}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9572}},\n",
       "    'numInputRows': 112,\n",
       "    'inputRowsPerSecond': 271.84466019417476,\n",
       "    'processedRowsPerSecond': 346.7492260061919}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.441Z',\n",
       "  'batchId': 36,\n",
       "  'numInputRows': 107,\n",
       "  'inputRowsPerSecond': 330.2469135802469,\n",
       "  'processedRowsPerSecond': 502.3474178403756,\n",
       "  'durationMs': {'addBatch': 87,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 24,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 213,\n",
       "   'walCommit': 51},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9572}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9679}},\n",
       "    'numInputRows': 107,\n",
       "    'inputRowsPerSecond': 330.2469135802469,\n",
       "    'processedRowsPerSecond': 502.3474178403756}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.655Z',\n",
       "  'batchId': 37,\n",
       "  'numInputRows': 61,\n",
       "  'inputRowsPerSecond': 285.04672897196264,\n",
       "  'processedRowsPerSecond': 253.11203319502076,\n",
       "  'durationMs': {'addBatch': 93,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 39,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 241,\n",
       "   'walCommit': 66},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9679}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9740}},\n",
       "    'numInputRows': 61,\n",
       "    'inputRowsPerSecond': 285.04672897196264,\n",
       "    'processedRowsPerSecond': 253.11203319502076}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.897Z',\n",
       "  'batchId': 38,\n",
       "  'numInputRows': 46,\n",
       "  'inputRowsPerSecond': 190.0826446280992,\n",
       "  'processedRowsPerSecond': 174.90494296577947,\n",
       "  'durationMs': {'addBatch': 85,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 22,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 263,\n",
       "   'walCommit': 46},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9740}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9786}},\n",
       "    'numInputRows': 46,\n",
       "    'inputRowsPerSecond': 190.0826446280992,\n",
       "    'processedRowsPerSecond': 174.90494296577947}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:33.160Z',\n",
       "  'batchId': 39,\n",
       "  'numInputRows': 62,\n",
       "  'inputRowsPerSecond': 235.74144486692015,\n",
       "  'processedRowsPerSecond': 89.72503617945009,\n",
       "  'durationMs': {'addBatch': 101,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 26,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 690,\n",
       "   'walCommit': 475},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9786}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9848}},\n",
       "    'numInputRows': 62,\n",
       "    'inputRowsPerSecond': 235.74144486692015,\n",
       "    'processedRowsPerSecond': 89.72503617945009}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:33.851Z',\n",
       "  'batchId': 40,\n",
       "  'numInputRows': 152,\n",
       "  'inputRowsPerSecond': 219.97105643994212,\n",
       "  'processedRowsPerSecond': 445.7478005865102,\n",
       "  'durationMs': {'addBatch': 100,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 1,\n",
       "   'queryPlanning': 29,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 341,\n",
       "   'walCommit': 44},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9848}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'numInputRows': 152,\n",
       "    'inputRowsPerSecond': 219.97105643994212,\n",
       "    'processedRowsPerSecond': 445.7478005865102}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:34.192Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:44.196Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 2},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    for s in streams:\n",
    "        desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "        s.stop()\n",
    "        print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"lab3 lr ALS app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-3.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab3 lr ALS app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6f25ad9dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_kafka_params = {\n",
    "#     \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "#     \"subscribe\": \"input_alexander.okhilkov\",\n",
    "#     \"startingOffsets\": \"latest\"\n",
    "# }\n",
    "\n",
    "\n",
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-node-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_alexander.okhilkov\",\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "\n",
    "# read readStream\n",
    "kafka_sdf_sh = spark.readStream.format(\"kafka\").options(**read_kafka_params).option(\"failOnDataLoss\", 'False').load()\n",
    "\n",
    "\n",
    "# \"maxOffsetsPerTrigger\": \"100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('gender', StringType()), \n",
    "                     StructField('age', StringType()),\n",
    "                     StructField('uid', StringType()),\n",
    "                     StructField('user_json', StringType())\n",
    "                    ])\n",
    "\n",
    "visits_schema = StructType([\n",
    "    StructField(\"visits\", ArrayType(\n",
    "      StructType([\n",
    "          StructField(\"url\", StringType()),\n",
    "          StructField(\"timestamp\", LongType())\n",
    "      ])\n",
    "   ))\n",
    "]) \n",
    "\n",
    "\n",
    "def create_predictions(df, epoch_id): # epoch_id batch_id\n",
    "    df = df.withColumn(\"value\", df[\"value\"].cast(\"string\"))\n",
    "    df = df.withColumn('value_parsed', F.from_json(F.col('value'), schema=schema))\n",
    "    \n",
    "    df=df.withColumn('uid', df['value_parsed']['uid'])\n",
    "#     df=df.withColumn('user_json', df['value_parsed']['user_json'])\n",
    "    \n",
    "#     df = df.withColumn('visits', F.from_json(F.col('user_json'), schema=visits_schema))\n",
    "    \n",
    "#     df = df.withColumn('urls' , df['visits']['visits']['url'] )\n",
    "#     df = df.withColumn(\"urls_hosts\", F.expr(\"transform(urls, x -> parse_url(x, 'HOST' ))\"))\n",
    "\n",
    "    df = df.select(['uid']).withColumn('gender', F.lit('M'))\\\n",
    "                            .withColumn('age', F.lit('25-34'))\n",
    "    print(df)\n",
    "    \n",
    "    df = df.withColumn('key',  F.lit(None) )\n",
    "    df = df.withColumn('value',  F.to_json(F.struct(\"uid\",\"gender\",\"age\")) )  \n",
    "    print(df)\n",
    "    \n",
    "    df = df.select('key' , 'value')\n",
    "    \n",
    "    print(df)\n",
    "    df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = kafka_sdf_sh \\\n",
    "        .writeStream \\\n",
    "        .foreachBatch(create_predictions) \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", 'spark-node-1.newprolab.com:6667') \\\n",
    "        .option(\"topic\", 'alexander.okhilkov') \\\n",
    "        .option(\"checkpointLocation\", \"streaming/chk/chk_kafka/oooou\" ) \\\n",
    "        .outputMode(\"append\")\n",
    "\n",
    "# .trigger(processingTime=\"10 seconds\") \\\n",
    "#         .option(\"checkpointLocation\", \"streaming/chk/chk_kafka\" ) \\\n",
    "#         .option(\"truncate\", \"false\") \\\n",
    "# .select('key' , 'value').selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "\n",
    "# spark-node-1.newprolab.com\n",
    "#         .option(\"kafka.bootstrap.servers\", 'spark-master-1.newprolab.com:6667') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       " 'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       " 'name': None,\n",
       " 'timestamp': '2021-03-22T20:09:32.414Z',\n",
       " 'batchId': 41,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'getEndOffset': 0, 'setOffsetRange': 1, 'triggerExecution': 2},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "   'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "   'endOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:06.641Z',\n",
       "  'batchId': 0,\n",
       "  'numInputRows': 0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'addBatch': 1710,\n",
       "   'getBatch': 16,\n",
       "   'getEndOffset': 4,\n",
       "   'queryPlanning': 1611,\n",
       "   'setOffsetRange': 4717,\n",
       "   'triggerExecution': 8704,\n",
       "   'walCommit': 299},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': None,\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 0}},\n",
       "    'numInputRows': 0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:15.413Z',\n",
       "  'batchId': 1,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 26,\n",
       "   'triggerExecution': 31},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 0}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 0}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:19.839Z',\n",
       "  'batchId': 1,\n",
       "  'numInputRows': 2,\n",
       "  'inputRowsPerSecond': 153.84615384615384,\n",
       "  'processedRowsPerSecond': 0.33444816053511706,\n",
       "  'durationMs': {'addBatch': 4813,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 38,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 5980,\n",
       "   'walCommit': 276},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 0}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 2}},\n",
       "    'numInputRows': 2,\n",
       "    'inputRowsPerSecond': 153.84615384615384,\n",
       "    'processedRowsPerSecond': 0.33444816053511706}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:25.819Z',\n",
       "  'batchId': 2,\n",
       "  'numInputRows': 198,\n",
       "  'inputRowsPerSecond': 33.11036789297658,\n",
       "  'processedRowsPerSecond': 128.9902280130293,\n",
       "  'durationMs': {'addBatch': 947,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 1,\n",
       "   'queryPlanning': 300,\n",
       "   'setOffsetRange': 31,\n",
       "   'triggerExecution': 1535,\n",
       "   'walCommit': 73},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 2}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 200}},\n",
       "    'numInputRows': 198,\n",
       "    'inputRowsPerSecond': 33.11036789297658,\n",
       "    'processedRowsPerSecond': 128.9902280130293}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:27.355Z',\n",
       "  'batchId': 3,\n",
       "  'numInputRows': 125,\n",
       "  'inputRowsPerSecond': 81.38020833333333,\n",
       "  'processedRowsPerSecond': 247.5247524752475,\n",
       "  'durationMs': {'addBatch': 235,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 32,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 505,\n",
       "   'walCommit': 101},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 200}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 325}},\n",
       "    'numInputRows': 125,\n",
       "    'inputRowsPerSecond': 81.38020833333333,\n",
       "    'processedRowsPerSecond': 247.5247524752475}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:27.861Z',\n",
       "  'batchId': 4,\n",
       "  'numInputRows': 96,\n",
       "  'inputRowsPerSecond': 189.72332015810275,\n",
       "  'processedRowsPerSecond': 113.87900355871886,\n",
       "  'durationMs': {'addBatch': 311,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 153,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 843,\n",
       "   'walCommit': 212},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 325}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 421}},\n",
       "    'numInputRows': 96,\n",
       "    'inputRowsPerSecond': 189.72332015810275,\n",
       "    'processedRowsPerSecond': 113.87900355871886}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:28.704Z',\n",
       "  'batchId': 5,\n",
       "  'numInputRows': 116,\n",
       "  'inputRowsPerSecond': 137.6037959667853,\n",
       "  'processedRowsPerSecond': 69.9216395418927,\n",
       "  'durationMs': {'addBatch': 675,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 509,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 1659,\n",
       "   'walCommit': 54},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 421}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 537}},\n",
       "    'numInputRows': 116,\n",
       "    'inputRowsPerSecond': 137.6037959667853,\n",
       "    'processedRowsPerSecond': 69.9216395418927}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:30.364Z',\n",
       "  'batchId': 6,\n",
       "  'numInputRows': 68,\n",
       "  'inputRowsPerSecond': 40.96385542168675,\n",
       "  'processedRowsPerSecond': 83.6408364083641,\n",
       "  'durationMs': {'addBatch': 319,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 216,\n",
       "   'setOffsetRange': 9,\n",
       "   'triggerExecution': 813,\n",
       "   'walCommit': 151},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 537}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 605}},\n",
       "    'numInputRows': 68,\n",
       "    'inputRowsPerSecond': 40.96385542168675,\n",
       "    'processedRowsPerSecond': 83.6408364083641}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:31.178Z',\n",
       "  'batchId': 7,\n",
       "  'numInputRows': 66,\n",
       "  'inputRowsPerSecond': 81.08108108108108,\n",
       "  'processedRowsPerSecond': 171.42857142857142,\n",
       "  'durationMs': {'addBatch': 175,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 28,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 385,\n",
       "   'walCommit': 110},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 605}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 671}},\n",
       "    'numInputRows': 66,\n",
       "    'inputRowsPerSecond': 81.08108108108108,\n",
       "    'processedRowsPerSecond': 171.42857142857142}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:31.564Z',\n",
       "  'batchId': 8,\n",
       "  'numInputRows': 29,\n",
       "  'inputRowsPerSecond': 75.12953367875647,\n",
       "  'processedRowsPerSecond': 38.35978835978836,\n",
       "  'durationMs': {'addBatch': 167,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 31,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 756,\n",
       "   'walCommit': 55},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 671}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 700}},\n",
       "    'numInputRows': 29,\n",
       "    'inputRowsPerSecond': 75.12953367875647,\n",
       "    'processedRowsPerSecond': 38.35978835978836}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:32.321Z',\n",
       "  'batchId': 9,\n",
       "  'numInputRows': 39,\n",
       "  'inputRowsPerSecond': 51.51915455746367,\n",
       "  'processedRowsPerSecond': 126.2135922330097,\n",
       "  'durationMs': {'addBatch': 135,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 33,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 309,\n",
       "   'walCommit': 59},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 700}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 739}},\n",
       "    'numInputRows': 39,\n",
       "    'inputRowsPerSecond': 51.51915455746367,\n",
       "    'processedRowsPerSecond': 126.2135922330097}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:32.631Z',\n",
       "  'batchId': 10,\n",
       "  'numInputRows': 46,\n",
       "  'inputRowsPerSecond': 148.38709677419354,\n",
       "  'processedRowsPerSecond': 38.59060402684564,\n",
       "  'durationMs': {'addBatch': 595,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 329,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 1192,\n",
       "   'walCommit': 93},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 739}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 785}},\n",
       "    'numInputRows': 46,\n",
       "    'inputRowsPerSecond': 148.38709677419354,\n",
       "    'processedRowsPerSecond': 38.59060402684564}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:33.826Z',\n",
       "  'batchId': 11,\n",
       "  'numInputRows': 159,\n",
       "  'inputRowsPerSecond': 133.05439330543933,\n",
       "  'processedRowsPerSecond': 137.3056994818653,\n",
       "  'durationMs': {'addBatch': 259,\n",
       "   'getBatch': 12,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 657,\n",
       "   'setOffsetRange': 14,\n",
       "   'triggerExecution': 1158,\n",
       "   'walCommit': 121},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 785}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 944}},\n",
       "    'numInputRows': 159,\n",
       "    'inputRowsPerSecond': 133.05439330543933,\n",
       "    'processedRowsPerSecond': 137.3056994818653}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:34.985Z',\n",
       "  'batchId': 12,\n",
       "  'numInputRows': 145,\n",
       "  'inputRowsPerSecond': 125.10785159620362,\n",
       "  'processedRowsPerSecond': 353.6585365853659,\n",
       "  'durationMs': {'addBatch': 194,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 33,\n",
       "   'setOffsetRange': 7,\n",
       "   'triggerExecution': 410,\n",
       "   'walCommit': 97},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 944}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1089}},\n",
       "    'numInputRows': 145,\n",
       "    'inputRowsPerSecond': 125.10785159620362,\n",
       "    'processedRowsPerSecond': 353.6585365853659}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:35.396Z',\n",
       "  'batchId': 13,\n",
       "  'numInputRows': 82,\n",
       "  'inputRowsPerSecond': 199.51338199513384,\n",
       "  'processedRowsPerSecond': 282.7586206896552,\n",
       "  'durationMs': {'addBatch': 112,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 22,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 290,\n",
       "   'walCommit': 71},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1089}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1171}},\n",
       "    'numInputRows': 82,\n",
       "    'inputRowsPerSecond': 199.51338199513384,\n",
       "    'processedRowsPerSecond': 282.7586206896552}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:35.687Z',\n",
       "  'batchId': 14,\n",
       "  'numInputRows': 46,\n",
       "  'inputRowsPerSecond': 158.07560137457045,\n",
       "  'processedRowsPerSecond': 49.409237379162185,\n",
       "  'durationMs': {'addBatch': 403,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 73,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 931,\n",
       "   'walCommit': 373},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1171}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1217}},\n",
       "    'numInputRows': 46,\n",
       "    'inputRowsPerSecond': 158.07560137457045,\n",
       "    'processedRowsPerSecond': 49.409237379162185}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:36.619Z',\n",
       "  'batchId': 15,\n",
       "  'numInputRows': 57,\n",
       "  'inputRowsPerSecond': 61.1587982832618,\n",
       "  'processedRowsPerSecond': 177.01863354037266,\n",
       "  'durationMs': {'addBatch': 125,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 32,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 321,\n",
       "   'walCommit': 93},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1217}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1274}},\n",
       "    'numInputRows': 57,\n",
       "    'inputRowsPerSecond': 61.1587982832618,\n",
       "    'processedRowsPerSecond': 177.01863354037266}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:36.941Z',\n",
       "  'batchId': 16,\n",
       "  'numInputRows': 76,\n",
       "  'inputRowsPerSecond': 236.0248447204969,\n",
       "  'processedRowsPerSecond': 102.42587601078168,\n",
       "  'durationMs': {'addBatch': 332,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 22,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 742,\n",
       "   'walCommit': 75},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1274}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1350}},\n",
       "    'numInputRows': 76,\n",
       "    'inputRowsPerSecond': 236.0248447204969,\n",
       "    'processedRowsPerSecond': 102.42587601078168}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:37.705Z',\n",
       "  'batchId': 17,\n",
       "  'numInputRows': 64,\n",
       "  'inputRowsPerSecond': 83.7696335078534,\n",
       "  'processedRowsPerSecond': 101.91082802547771,\n",
       "  'durationMs': {'addBatch': 255,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 15,\n",
       "   'setOffsetRange': 11,\n",
       "   'triggerExecution': 623,\n",
       "   'walCommit': 133},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1350}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1414}},\n",
       "    'numInputRows': 64,\n",
       "    'inputRowsPerSecond': 83.7696335078534,\n",
       "    'processedRowsPerSecond': 101.91082802547771}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:38.334Z',\n",
       "  'batchId': 18,\n",
       "  'numInputRows': 102,\n",
       "  'inputRowsPerSecond': 162.16216216216216,\n",
       "  'processedRowsPerSecond': 196.53179190751445,\n",
       "  'durationMs': {'addBatch': 210,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 5,\n",
       "   'queryPlanning': 85,\n",
       "   'setOffsetRange': 6,\n",
       "   'triggerExecution': 519,\n",
       "   'walCommit': 87},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1414}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1516}},\n",
       "    'numInputRows': 102,\n",
       "    'inputRowsPerSecond': 162.16216216216216,\n",
       "    'processedRowsPerSecond': 196.53179190751445}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:38.854Z',\n",
       "  'batchId': 19,\n",
       "  'numInputRows': 71,\n",
       "  'inputRowsPerSecond': 136.53846153846155,\n",
       "  'processedRowsPerSecond': 181.12244897959184,\n",
       "  'durationMs': {'addBatch': 178,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 20,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 392,\n",
       "   'walCommit': 69},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1516}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1587}},\n",
       "    'numInputRows': 71,\n",
       "    'inputRowsPerSecond': 136.53846153846155,\n",
       "    'processedRowsPerSecond': 181.12244897959184}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:39.250Z',\n",
       "  'batchId': 20,\n",
       "  'numInputRows': 41,\n",
       "  'inputRowsPerSecond': 103.53535353535354,\n",
       "  'processedRowsPerSecond': 72.05623901581723,\n",
       "  'durationMs': {'addBatch': 197,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 72,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 569,\n",
       "   'walCommit': 167},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1587}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1628}},\n",
       "    'numInputRows': 41,\n",
       "    'inputRowsPerSecond': 103.53535353535354,\n",
       "    'processedRowsPerSecond': 72.05623901581723}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:39.820Z',\n",
       "  'batchId': 21,\n",
       "  'numInputRows': 65,\n",
       "  'inputRowsPerSecond': 114.03508771929826,\n",
       "  'processedRowsPerSecond': 115.65836298932383,\n",
       "  'durationMs': {'addBatch': 185,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 47,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 562,\n",
       "   'walCommit': 113},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1628}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1693}},\n",
       "    'numInputRows': 65,\n",
       "    'inputRowsPerSecond': 114.03508771929826,\n",
       "    'processedRowsPerSecond': 115.65836298932383}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:40.383Z',\n",
       "  'batchId': 22,\n",
       "  'numInputRows': 67,\n",
       "  'inputRowsPerSecond': 119.00532859680285,\n",
       "  'processedRowsPerSecond': 68.78850102669405,\n",
       "  'durationMs': {'addBatch': 372,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 1,\n",
       "   'queryPlanning': 24,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 974,\n",
       "   'walCommit': 109},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1693}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1760}},\n",
       "    'numInputRows': 67,\n",
       "    'inputRowsPerSecond': 119.00532859680285,\n",
       "    'processedRowsPerSecond': 68.78850102669405}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:41.362Z',\n",
       "  'batchId': 23,\n",
       "  'numInputRows': 108,\n",
       "  'inputRowsPerSecond': 110.31664964249234,\n",
       "  'processedRowsPerSecond': 143.04635761589404,\n",
       "  'durationMs': {'addBatch': 276,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 33,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 755,\n",
       "   'walCommit': 119},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1760}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1868}},\n",
       "    'numInputRows': 108,\n",
       "    'inputRowsPerSecond': 110.31664964249234,\n",
       "    'processedRowsPerSecond': 143.04635761589404}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:42.123Z',\n",
       "  'batchId': 24,\n",
       "  'numInputRows': 95,\n",
       "  'inputRowsPerSecond': 124.83574244415243,\n",
       "  'processedRowsPerSecond': 26.768103691180613,\n",
       "  'durationMs': {'addBatch': 1437,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 437,\n",
       "   'setOffsetRange': 54,\n",
       "   'triggerExecution': 3549,\n",
       "   'walCommit': 227},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1868}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 1963}},\n",
       "    'numInputRows': 95,\n",
       "    'inputRowsPerSecond': 124.83574244415243,\n",
       "    'processedRowsPerSecond': 26.768103691180613}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:45.673Z',\n",
       "  'batchId': 25,\n",
       "  'numInputRows': 424,\n",
       "  'inputRowsPerSecond': 119.43661971830987,\n",
       "  'processedRowsPerSecond': 384.7549909255898,\n",
       "  'durationMs': {'addBatch': 786,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 50,\n",
       "   'setOffsetRange': 73,\n",
       "   'triggerExecution': 1102,\n",
       "   'walCommit': 119},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 1963}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 2387}},\n",
       "    'numInputRows': 424,\n",
       "    'inputRowsPerSecond': 119.43661971830987,\n",
       "    'processedRowsPerSecond': 384.7549909255898}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:46.781Z',\n",
       "  'batchId': 26,\n",
       "  'numInputRows': 255,\n",
       "  'inputRowsPerSecond': 230.14440433212994,\n",
       "  'processedRowsPerSecond': 255.51102204408818,\n",
       "  'durationMs': {'addBatch': 338,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 19,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 998,\n",
       "   'walCommit': 57},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 2387}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 2642}},\n",
       "    'numInputRows': 255,\n",
       "    'inputRowsPerSecond': 230.14440433212994,\n",
       "    'processedRowsPerSecond': 255.51102204408818}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:47.791Z',\n",
       "  'batchId': 27,\n",
       "  'numInputRows': 159,\n",
       "  'inputRowsPerSecond': 157.4257425742574,\n",
       "  'processedRowsPerSecond': 110.03460207612456,\n",
       "  'durationMs': {'addBatch': 684,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 58,\n",
       "   'setOffsetRange': 18,\n",
       "   'triggerExecution': 1445,\n",
       "   'walCommit': 488},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 2642}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 2801}},\n",
       "    'numInputRows': 159,\n",
       "    'inputRowsPerSecond': 157.4257425742574,\n",
       "    'processedRowsPerSecond': 110.03460207612456}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:49.237Z',\n",
       "  'batchId': 28,\n",
       "  'numInputRows': 302,\n",
       "  'inputRowsPerSecond': 208.85200553250345,\n",
       "  'processedRowsPerSecond': 245.72823433685923,\n",
       "  'durationMs': {'addBatch': 441,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 1,\n",
       "   'queryPlanning': 50,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1229,\n",
       "   'walCommit': 116},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 2801}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 3103}},\n",
       "    'numInputRows': 302,\n",
       "    'inputRowsPerSecond': 208.85200553250345,\n",
       "    'processedRowsPerSecond': 245.72823433685923}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:50.467Z',\n",
       "  'batchId': 29,\n",
       "  'numInputRows': 242,\n",
       "  'inputRowsPerSecond': 196.7479674796748,\n",
       "  'processedRowsPerSecond': 108.22898032200357,\n",
       "  'durationMs': {'addBatch': 1296,\n",
       "   'getBatch': 28,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 95,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 2236,\n",
       "   'walCommit': 488},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 3103}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 3345}},\n",
       "    'numInputRows': 242,\n",
       "    'inputRowsPerSecond': 196.7479674796748,\n",
       "    'processedRowsPerSecond': 108.22898032200357}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:52.704Z',\n",
       "  'batchId': 30,\n",
       "  'numInputRows': 349,\n",
       "  'inputRowsPerSecond': 156.01251676352257,\n",
       "  'processedRowsPerSecond': 95.30311305297651,\n",
       "  'durationMs': {'addBatch': 268,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 2488,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 3662,\n",
       "   'walCommit': 384},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 3345}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 3694}},\n",
       "    'numInputRows': 349,\n",
       "    'inputRowsPerSecond': 156.01251676352257,\n",
       "    'processedRowsPerSecond': 95.30311305297651}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:56.367Z',\n",
       "  'batchId': 31,\n",
       "  'numInputRows': 346,\n",
       "  'inputRowsPerSecond': 94.45809445809446,\n",
       "  'processedRowsPerSecond': 469.47082767978293,\n",
       "  'durationMs': {'addBatch': 530,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 12,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 737,\n",
       "   'walCommit': 56},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 3694}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4040}},\n",
       "    'numInputRows': 346,\n",
       "    'inputRowsPerSecond': 94.45809445809446,\n",
       "    'processedRowsPerSecond': 469.47082767978293}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:57.104Z',\n",
       "  'batchId': 32,\n",
       "  'numInputRows': 117,\n",
       "  'inputRowsPerSecond': 158.7516960651289,\n",
       "  'processedRowsPerSecond': 373.8019169329074,\n",
       "  'durationMs': {'addBatch': 119,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 15,\n",
       "   'setOffsetRange': 8,\n",
       "   'triggerExecution': 313,\n",
       "   'walCommit': 73},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4040}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4157}},\n",
       "    'numInputRows': 117,\n",
       "    'inputRowsPerSecond': 158.7516960651289,\n",
       "    'processedRowsPerSecond': 373.8019169329074}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:57.418Z',\n",
       "  'batchId': 33,\n",
       "  'numInputRows': 71,\n",
       "  'inputRowsPerSecond': 226.11464968152868,\n",
       "  'processedRowsPerSecond': 297.07112970711296,\n",
       "  'durationMs': {'addBatch': 72,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 13,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 239,\n",
       "   'walCommit': 71},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4157}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4228}},\n",
       "    'numInputRows': 71,\n",
       "    'inputRowsPerSecond': 226.11464968152868,\n",
       "    'processedRowsPerSecond': 297.07112970711296}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:57.658Z',\n",
       "  'batchId': 34,\n",
       "  'numInputRows': 89,\n",
       "  'inputRowsPerSecond': 370.83333333333337,\n",
       "  'processedRowsPerSecond': 289.90228013029315,\n",
       "  'durationMs': {'addBatch': 105,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 9,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 307,\n",
       "   'walCommit': 127},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4228}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4317}},\n",
       "    'numInputRows': 89,\n",
       "    'inputRowsPerSecond': 370.83333333333337,\n",
       "    'processedRowsPerSecond': 289.90228013029315}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:57.966Z',\n",
       "  'batchId': 35,\n",
       "  'numInputRows': 63,\n",
       "  'inputRowsPerSecond': 204.54545454545456,\n",
       "  'processedRowsPerSecond': 285.0678733031674,\n",
       "  'durationMs': {'addBatch': 88,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 11,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 221,\n",
       "   'walCommit': 49},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4317}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4380}},\n",
       "    'numInputRows': 63,\n",
       "    'inputRowsPerSecond': 204.54545454545456,\n",
       "    'processedRowsPerSecond': 285.0678733031674}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:58.188Z',\n",
       "  'batchId': 36,\n",
       "  'numInputRows': 72,\n",
       "  'inputRowsPerSecond': 324.3243243243243,\n",
       "  'processedRowsPerSecond': 108.43373493975903,\n",
       "  'durationMs': {'addBatch': 112,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 12,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 664,\n",
       "   'walCommit': 476},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4380}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4452}},\n",
       "    'numInputRows': 72,\n",
       "    'inputRowsPerSecond': 324.3243243243243,\n",
       "    'processedRowsPerSecond': 108.43373493975903}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:58.853Z',\n",
       "  'batchId': 37,\n",
       "  'numInputRows': 227,\n",
       "  'inputRowsPerSecond': 341.3533834586466,\n",
       "  'processedRowsPerSecond': 539.1923990498813,\n",
       "  'durationMs': {'addBatch': 164,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 14,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 421,\n",
       "   'walCommit': 68},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4452}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4679}},\n",
       "    'numInputRows': 227,\n",
       "    'inputRowsPerSecond': 341.3533834586466,\n",
       "    'processedRowsPerSecond': 539.1923990498813}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:59.275Z',\n",
       "  'batchId': 38,\n",
       "  'numInputRows': 79,\n",
       "  'inputRowsPerSecond': 187.20379146919433,\n",
       "  'processedRowsPerSecond': 199.49494949494948,\n",
       "  'durationMs': {'addBatch': 122,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 10,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 396,\n",
       "   'walCommit': 100},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4679}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4758}},\n",
       "    'numInputRows': 79,\n",
       "    'inputRowsPerSecond': 187.20379146919433,\n",
       "    'processedRowsPerSecond': 199.49494949494948}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:08:59.672Z',\n",
       "  'batchId': 39,\n",
       "  'numInputRows': 89,\n",
       "  'inputRowsPerSecond': 224.18136020151132,\n",
       "  'processedRowsPerSecond': 99.66405375139978,\n",
       "  'durationMs': {'addBatch': 508,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 12,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 893,\n",
       "   'walCommit': 136},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4758}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 4847}},\n",
       "    'numInputRows': 89,\n",
       "    'inputRowsPerSecond': 224.18136020151132,\n",
       "    'processedRowsPerSecond': 99.66405375139978}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:09:00.568Z',\n",
       "  'batchId': 40,\n",
       "  'numInputRows': 153,\n",
       "  'inputRowsPerSecond': 170.75892857142856,\n",
       "  'processedRowsPerSecond': 83.88157894736842,\n",
       "  'durationMs': {'addBatch': 208,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 30,\n",
       "   'setOffsetRange': 52,\n",
       "   'triggerExecution': 1824,\n",
       "   'walCommit': 1220},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 4847}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'numInputRows': 153,\n",
       "    'inputRowsPerSecond': 170.75892857142856,\n",
       "    'processedRowsPerSecond': 83.88157894736842}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:09:02.393Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 1,\n",
       "   'setOffsetRange': 6,\n",
       "   'triggerExecution': 7},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:09:12.402Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 2},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:09:22.409Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 2},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}},\n",
       " {'id': '917d1b3b-0691-4684-9cfc-8990bdf3d89c',\n",
       "  'runId': '8f317553-4356-4498-b5fa-86b789957e3d',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:09:32.414Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 2},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@ac86893'}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    for s in streams:\n",
    "        desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "        s.stop()\n",
    "        print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kill_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVER = 'spark-node-1.newprolab.com:6667'\n",
    "# KAFKA_BOOTSTRAP_SERVER = 'spark-master-1.newprolab.com:6667'\n",
    "INPUT_KAFKA_TOPIC = 'input_alexander.okhilkov'\n",
    "OUTPUT_KAFKA_TOPIC = 'alexander.okhilkov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_kafka_params = {\n",
    "    'kafka.bootstrap.servers': KAFKA_BOOTSTRAP_SERVER,\n",
    "    'subscribe': OUTPUT_KAFKA_TOPIC,\n",
    "    'startingOffsets': 'earliest'\n",
    "}\n",
    "kafka_sdf = (\n",
    "    spark\n",
    "    .read\n",
    "    .format('kafka')\n",
    "    .options(**read_kafka_params)\n",
    "    .load()\n",
    "    .cache()\n",
    ")\n",
    "kafka_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "|key|value|topic|partition|offset|timestamp|timestampType|\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_sdf.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Стримингоыфй вариант + МОДЕЛЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"lab3 lr ALS app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-3.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab3 lr ALS app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6f24f77128>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-node-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_alexander.okhilkov\",\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "\n",
    "# read readStream\n",
    "kafka_sdf_sh = spark.readStream.format(\"kafka\").options(**read_kafka_params).option(\"failOnDataLoss\", 'False').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.withColumn(\"value\", kafka_sdf_sh[\"value\"].cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('gender', StringType()), \n",
    "                     StructField('age', StringType()),\n",
    "                     StructField('uid', StringType()),\n",
    "                     StructField('user_json', StringType())\n",
    "                    ]\n",
    "                   )\n",
    "\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('value_parsed', \n",
    "                                   F.from_json(F.col('value'),\n",
    "                                               schema=schema)\n",
    "                                      )\n",
    "\n",
    "\n",
    "# kafka_sdf_sh=kafka_sdf_sh.withColumn('gender', kafka_sdf_sh['value_parsed']['gender'])\n",
    "# kafka_sdf_sh=kafka_sdf_sh.withColumn('age', kafka_sdf_sh['value_parsed']['age'])\n",
    "kafka_sdf_sh=kafka_sdf_sh.withColumn('uid', kafka_sdf_sh['value_parsed']['uid'])\n",
    "kafka_sdf_sh=kafka_sdf_sh.withColumn('user_json', kafka_sdf_sh['value_parsed']['user_json'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "visits_schema = StructType([\n",
    "    StructField(\"visits\", ArrayType(\n",
    "      StructType([\n",
    "          StructField(\"url\", StringType()),\n",
    "          StructField(\"timestamp\", LongType())\n",
    "      ])\n",
    "   ))\n",
    "]) \n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('visits', \n",
    "                                   F.from_json(F.col('user_json'),\n",
    "                                               schema=visits_schema)\n",
    "                                              )\n",
    "\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('urls' , kafka_sdf_sh['visits']['visits']['url'] )\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn(\"urls_hosts\", F.expr(\"transform(urls, x -> parse_url(x, 'HOST' ))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: string, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int, value_parsed: struct<gender:string,age:string,uid:string,user_json:string>, uid: string, user_json: string, visits: struct<visits:array<struct<url:string,timestamp:bigint>>>, urls: array<string>, urls_hosts: array<string>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh = pipeline_age.transform(kafka_sdf_sh)\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn(\"age\", F.when(F.col(\"pred_age\")==0, '18-24') \\\n",
    "                                       .when(F.col(\"pred_age\")==1, '25-34') \\\n",
    "                                       .when(F.col(\"pred_age\")==2, '35-44') \\\n",
    "                                       .when(F.col(\"pred_age\")==3, '45-54') \\\n",
    "                                       .otherwise(\">=55\")).select([\"uid\", \"age\", \"urls_hosts\"])\n",
    "kafka_sdf_sh = pipeline_gender.transform(kafka_sdf_sh)\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn(\"gender\", F.when(F.col(\"pred_gender\")==1, 'F').otherwise('M'))\n",
    "\n",
    "\n",
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kafka_sdf_sh = kafka_sdf_sh.select(['uid']).withColumn('gender', F.lit('M'))\\\n",
    "#                             .withColumn('age', F.lit('25-34'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('key',  F.lit(None) )\n",
    "kafka_sdf_sh = kafka_sdf_sh.withColumn('value',  F.to_json(F.struct(\"uid\",\"gender\",\"age\")) )                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf_sh = kafka_sdf_sh.select('key' , 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: null, value: string]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = kafka_sdf_sh \\\n",
    "        .select('key' , 'value').selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "        .writeStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", 'spark-node-1.newprolab.com:6667') \\\n",
    "        .option(\"topic\", 'alexander.okhilkov') \\\n",
    "        .option(\"checkpointLocation\", \"streaming/chk/chk_kafka/rr\" ) \\\n",
    "        .outputMode(\"append\")\n",
    "\n",
    "# .trigger(processingTime=\"10 seconds\") \\\n",
    "#         .option(\"checkpointLocation\", \"streaming/chk/chk_kafka\" ) \\\n",
    "#         .option(\"truncate\", \"false\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       " 'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       " 'name': None,\n",
       " 'timestamp': '2021-03-22T20:28:44.196Z',\n",
       " 'batchId': 41,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'getEndOffset': 0, 'setOffsetRange': 2, 'triggerExecution': 2},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "   'startOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "   'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:27:50.485Z',\n",
       "  'batchId': 1,\n",
       "  'numInputRows': 1,\n",
       "  'processedRowsPerSecond': 0.0759589821496392,\n",
       "  'durationMs': {'addBatch': 12620,\n",
       "   'getBatch': 10,\n",
       "   'queryPlanning': 64,\n",
       "   'triggerExecution': 13165},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5001}},\n",
       "    'numInputRows': 1,\n",
       "    'processedRowsPerSecond': 0.0759589821496392}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:03.711Z',\n",
       "  'batchId': 2,\n",
       "  'numInputRows': 405,\n",
       "  'inputRowsPerSecond': 30.621503099954634,\n",
       "  'processedRowsPerSecond': 76.96693272519956,\n",
       "  'durationMs': {'addBatch': 807,\n",
       "   'getBatch': 11,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 175,\n",
       "   'setOffsetRange': 3337,\n",
       "   'triggerExecution': 5262,\n",
       "   'walCommit': 672},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5001}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5406}},\n",
       "    'numInputRows': 405,\n",
       "    'inputRowsPerSecond': 30.621503099954634,\n",
       "    'processedRowsPerSecond': 76.96693272519956}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:08.974Z',\n",
       "  'batchId': 3,\n",
       "  'numInputRows': 190,\n",
       "  'inputRowsPerSecond': 36.101083032490976,\n",
       "  'processedRowsPerSecond': 231.990231990232,\n",
       "  'durationMs': {'addBatch': 466,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 88,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 819,\n",
       "   'walCommit': 136},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5406}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5596}},\n",
       "    'numInputRows': 190,\n",
       "    'inputRowsPerSecond': 36.101083032490976,\n",
       "    'processedRowsPerSecond': 231.990231990232}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:09.793Z',\n",
       "  'batchId': 4,\n",
       "  'numInputRows': 74,\n",
       "  'inputRowsPerSecond': 90.35409035409036,\n",
       "  'processedRowsPerSecond': 147.70459081836327,\n",
       "  'durationMs': {'addBatch': 194,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 106,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 501,\n",
       "   'walCommit': 101},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5596}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5670}},\n",
       "    'numInputRows': 74,\n",
       "    'inputRowsPerSecond': 90.35409035409036,\n",
       "    'processedRowsPerSecond': 147.70459081836327}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:10.295Z',\n",
       "  'batchId': 5,\n",
       "  'numInputRows': 32,\n",
       "  'inputRowsPerSecond': 63.745019920318725,\n",
       "  'processedRowsPerSecond': 61.65703275529865,\n",
       "  'durationMs': {'addBatch': 161,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 59,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 519,\n",
       "   'walCommit': 143},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5670}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5702}},\n",
       "    'numInputRows': 32,\n",
       "    'inputRowsPerSecond': 63.745019920318725,\n",
       "    'processedRowsPerSecond': 61.65703275529865}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:10.815Z',\n",
       "  'batchId': 6,\n",
       "  'numInputRows': 30,\n",
       "  'inputRowsPerSecond': 57.69230769230769,\n",
       "  'processedRowsPerSecond': 53.28596802841919,\n",
       "  'durationMs': {'addBatch': 183,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 162,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 563,\n",
       "   'walCommit': 74},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5702}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5732}},\n",
       "    'numInputRows': 30,\n",
       "    'inputRowsPerSecond': 57.69230769230769,\n",
       "    'processedRowsPerSecond': 53.28596802841919}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:11.378Z',\n",
       "  'batchId': 7,\n",
       "  'numInputRows': 85,\n",
       "  'inputRowsPerSecond': 150.97690941385437,\n",
       "  'processedRowsPerSecond': 174.53798767967146,\n",
       "  'durationMs': {'addBatch': 166,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 57,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 487,\n",
       "   'walCommit': 60},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5732}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5817}},\n",
       "    'numInputRows': 85,\n",
       "    'inputRowsPerSecond': 150.97690941385437,\n",
       "    'processedRowsPerSecond': 174.53798767967146}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:11.884Z',\n",
       "  'batchId': 8,\n",
       "  'numInputRows': 77,\n",
       "  'inputRowsPerSecond': 152.17391304347825,\n",
       "  'processedRowsPerSecond': 140.51094890510947,\n",
       "  'durationMs': {'addBatch': 204,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 170,\n",
       "   'setOffsetRange': 11,\n",
       "   'triggerExecution': 548,\n",
       "   'walCommit': 116},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5817}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5894}},\n",
       "    'numInputRows': 77,\n",
       "    'inputRowsPerSecond': 152.17391304347825,\n",
       "    'processedRowsPerSecond': 140.51094890510947}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:12.432Z',\n",
       "  'batchId': 9,\n",
       "  'numInputRows': 73,\n",
       "  'inputRowsPerSecond': 133.21167883211677,\n",
       "  'processedRowsPerSecond': 114.77987421383648,\n",
       "  'durationMs': {'addBatch': 181,\n",
       "   'getBatch': 2,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 81,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 612,\n",
       "   'walCommit': 171},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5894}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 5967}},\n",
       "    'numInputRows': 73,\n",
       "    'inputRowsPerSecond': 133.21167883211677,\n",
       "    'processedRowsPerSecond': 114.77987421383648}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:13.068Z',\n",
       "  'batchId': 10,\n",
       "  'numInputRows': 91,\n",
       "  'inputRowsPerSecond': 143.0817610062893,\n",
       "  'processedRowsPerSecond': 166.05839416058393,\n",
       "  'durationMs': {'addBatch': 162,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 72,\n",
       "   'setOffsetRange': 3,\n",
       "   'triggerExecution': 548,\n",
       "   'walCommit': 115},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 5967}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6058}},\n",
       "    'numInputRows': 91,\n",
       "    'inputRowsPerSecond': 143.0817610062893,\n",
       "    'processedRowsPerSecond': 166.05839416058393}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:13.616Z',\n",
       "  'batchId': 11,\n",
       "  'numInputRows': 104,\n",
       "  'inputRowsPerSecond': 189.7810218978102,\n",
       "  'processedRowsPerSecond': 190.82568807339447,\n",
       "  'durationMs': {'addBatch': 280,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 46,\n",
       "   'setOffsetRange': 4,\n",
       "   'triggerExecution': 545,\n",
       "   'walCommit': 104},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6058}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6162}},\n",
       "    'numInputRows': 104,\n",
       "    'inputRowsPerSecond': 189.7810218978102,\n",
       "    'processedRowsPerSecond': 190.82568807339447}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:14.161Z',\n",
       "  'batchId': 12,\n",
       "  'numInputRows': 75,\n",
       "  'inputRowsPerSecond': 137.61467889908255,\n",
       "  'processedRowsPerSecond': 175.2336448598131,\n",
       "  'durationMs': {'addBatch': 175,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 98,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 428,\n",
       "   'walCommit': 67},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6162}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6237}},\n",
       "    'numInputRows': 75,\n",
       "    'inputRowsPerSecond': 137.61467889908255,\n",
       "    'processedRowsPerSecond': 175.2336448598131}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:14.590Z',\n",
       "  'batchId': 13,\n",
       "  'numInputRows': 87,\n",
       "  'inputRowsPerSecond': 202.7972027972028,\n",
       "  'processedRowsPerSecond': 159.04936014625227,\n",
       "  'durationMs': {'addBatch': 173,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 43,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 547,\n",
       "   'walCommit': 41},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6237}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6324}},\n",
       "    'numInputRows': 87,\n",
       "    'inputRowsPerSecond': 202.7972027972028,\n",
       "    'processedRowsPerSecond': 159.04936014625227}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:15.196Z',\n",
       "  'batchId': 14,\n",
       "  'numInputRows': 90,\n",
       "  'inputRowsPerSecond': 148.5148514851485,\n",
       "  'processedRowsPerSecond': 94.83667017913594,\n",
       "  'durationMs': {'addBatch': 268,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 184,\n",
       "   'setOffsetRange': 81,\n",
       "   'triggerExecution': 949,\n",
       "   'walCommit': 309},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6324}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6414}},\n",
       "    'numInputRows': 90,\n",
       "    'inputRowsPerSecond': 148.5148514851485,\n",
       "    'processedRowsPerSecond': 94.83667017913594}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:16.146Z',\n",
       "  'batchId': 15,\n",
       "  'numInputRows': 142,\n",
       "  'inputRowsPerSecond': 149.47368421052633,\n",
       "  'processedRowsPerSecond': 272.55278310940497,\n",
       "  'durationMs': {'addBatch': 238,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 71,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 521,\n",
       "   'walCommit': 135},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6414}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6556}},\n",
       "    'numInputRows': 142,\n",
       "    'inputRowsPerSecond': 149.47368421052633,\n",
       "    'processedRowsPerSecond': 272.55278310940497}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:16.668Z',\n",
       "  'batchId': 16,\n",
       "  'numInputRows': 70,\n",
       "  'inputRowsPerSecond': 134.09961685823754,\n",
       "  'processedRowsPerSecond': 48.40940525587828,\n",
       "  'durationMs': {'addBatch': 376,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 921,\n",
       "   'setOffsetRange': 20,\n",
       "   'triggerExecution': 1446,\n",
       "   'walCommit': 58},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6556}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6626}},\n",
       "    'numInputRows': 70,\n",
       "    'inputRowsPerSecond': 134.09961685823754,\n",
       "    'processedRowsPerSecond': 48.40940525587828}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:18.114Z',\n",
       "  'batchId': 17,\n",
       "  'numInputRows': 134,\n",
       "  'inputRowsPerSecond': 92.66943291839557,\n",
       "  'processedRowsPerSecond': 222.96173044925126,\n",
       "  'durationMs': {'addBatch': 214,\n",
       "   'getBatch': 5,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 123,\n",
       "   'setOffsetRange': 12,\n",
       "   'triggerExecution': 601,\n",
       "   'walCommit': 189},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6626}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6760}},\n",
       "    'numInputRows': 134,\n",
       "    'inputRowsPerSecond': 92.66943291839557,\n",
       "    'processedRowsPerSecond': 222.96173044925126}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:18.716Z',\n",
       "  'batchId': 18,\n",
       "  'numInputRows': 122,\n",
       "  'inputRowsPerSecond': 202.65780730897012,\n",
       "  'processedRowsPerSecond': 232.38095238095238,\n",
       "  'durationMs': {'addBatch': 302,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 45,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 525,\n",
       "   'walCommit': 78},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6760}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6882}},\n",
       "    'numInputRows': 122,\n",
       "    'inputRowsPerSecond': 202.65780730897012,\n",
       "    'processedRowsPerSecond': 232.38095238095238}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:19.242Z',\n",
       "  'batchId': 19,\n",
       "  'numInputRows': 80,\n",
       "  'inputRowsPerSecond': 152.0912547528517,\n",
       "  'processedRowsPerSecond': 134.0033500837521,\n",
       "  'durationMs': {'addBatch': 170,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 48,\n",
       "   'setOffsetRange': 13,\n",
       "   'triggerExecution': 597,\n",
       "   'walCommit': 83},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6882}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 6962}},\n",
       "    'numInputRows': 80,\n",
       "    'inputRowsPerSecond': 152.0912547528517,\n",
       "    'processedRowsPerSecond': 134.0033500837521}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:19.848Z',\n",
       "  'batchId': 20,\n",
       "  'numInputRows': 99,\n",
       "  'inputRowsPerSecond': 163.36633663366337,\n",
       "  'processedRowsPerSecond': 56.25,\n",
       "  'durationMs': {'addBatch': 484,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 49,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1760,\n",
       "   'walCommit': 66},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 6962}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7061}},\n",
       "    'numInputRows': 99,\n",
       "    'inputRowsPerSecond': 163.36633663366337,\n",
       "    'processedRowsPerSecond': 56.25}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:21.614Z',\n",
       "  'batchId': 21,\n",
       "  'numInputRows': 326,\n",
       "  'inputRowsPerSecond': 184.59796149490373,\n",
       "  'processedRowsPerSecond': 346.8085106382979,\n",
       "  'durationMs': {'addBatch': 459,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 157,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 940,\n",
       "   'walCommit': 213},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7061}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7387}},\n",
       "    'numInputRows': 326,\n",
       "    'inputRowsPerSecond': 184.59796149490373,\n",
       "    'processedRowsPerSecond': 346.8085106382979}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:22.554Z',\n",
       "  'batchId': 22,\n",
       "  'numInputRows': 158,\n",
       "  'inputRowsPerSecond': 168.08510638297872,\n",
       "  'processedRowsPerSecond': 149.33837429111531,\n",
       "  'durationMs': {'addBatch': 234,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 65,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1058,\n",
       "   'walCommit': 655},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7387}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7545}},\n",
       "    'numInputRows': 158,\n",
       "    'inputRowsPerSecond': 168.08510638297872,\n",
       "    'processedRowsPerSecond': 149.33837429111531}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:23.613Z',\n",
       "  'batchId': 23,\n",
       "  'numInputRows': 157,\n",
       "  'inputRowsPerSecond': 148.2530689329556,\n",
       "  'processedRowsPerSecond': 296.2264150943396,\n",
       "  'durationMs': {'addBatch': 246,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 105,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 530,\n",
       "   'walCommit': 117},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7545}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7702}},\n",
       "    'numInputRows': 157,\n",
       "    'inputRowsPerSecond': 148.2530689329556,\n",
       "    'processedRowsPerSecond': 296.2264150943396}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:24.144Z',\n",
       "  'batchId': 24,\n",
       "  'numInputRows': 85,\n",
       "  'inputRowsPerSecond': 160.07532956685498,\n",
       "  'processedRowsPerSecond': 137.76337115072934,\n",
       "  'durationMs': {'addBatch': 248,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 57,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 617,\n",
       "   'walCommit': 72},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7702}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7787}},\n",
       "    'numInputRows': 85,\n",
       "    'inputRowsPerSecond': 160.07532956685498,\n",
       "    'processedRowsPerSecond': 137.76337115072934}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:24.761Z',\n",
       "  'batchId': 25,\n",
       "  'numInputRows': 91,\n",
       "  'inputRowsPerSecond': 147.4878444084279,\n",
       "  'processedRowsPerSecond': 46.09929078014184,\n",
       "  'durationMs': {'addBatch': 224,\n",
       "   'getBatch': 8,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 178,\n",
       "   'setOffsetRange': 33,\n",
       "   'triggerExecution': 1974,\n",
       "   'walCommit': 1377},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7787}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 7878}},\n",
       "    'numInputRows': 91,\n",
       "    'inputRowsPerSecond': 147.4878444084279,\n",
       "    'processedRowsPerSecond': 46.09929078014184}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:26.736Z',\n",
       "  'batchId': 26,\n",
       "  'numInputRows': 299,\n",
       "  'inputRowsPerSecond': 151.39240506329114,\n",
       "  'processedRowsPerSecond': 644.3965517241379,\n",
       "  'durationMs': {'addBatch': 229,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 46,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 464,\n",
       "   'walCommit': 121},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 7878}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8177}},\n",
       "    'numInputRows': 299,\n",
       "    'inputRowsPerSecond': 151.39240506329114,\n",
       "    'processedRowsPerSecond': 644.3965517241379}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:27.200Z',\n",
       "  'batchId': 27,\n",
       "  'numInputRows': 168,\n",
       "  'inputRowsPerSecond': 362.06896551724134,\n",
       "  'processedRowsPerSecond': 685.7142857142858,\n",
       "  'durationMs': {'addBatch': 122,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 44,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 245,\n",
       "   'walCommit': 34},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8177}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8345}},\n",
       "    'numInputRows': 168,\n",
       "    'inputRowsPerSecond': 362.06896551724134,\n",
       "    'processedRowsPerSecond': 685.7142857142858}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:27.446Z',\n",
       "  'batchId': 28,\n",
       "  'numInputRows': 46,\n",
       "  'inputRowsPerSecond': 186.9918699186992,\n",
       "  'processedRowsPerSecond': 32.07810320781032,\n",
       "  'durationMs': {'addBatch': 700,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 38,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1434,\n",
       "   'walCommit': 39},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8345}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8391}},\n",
       "    'numInputRows': 46,\n",
       "    'inputRowsPerSecond': 186.9918699186992,\n",
       "    'processedRowsPerSecond': 32.07810320781032}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:28.880Z',\n",
       "  'batchId': 29,\n",
       "  'numInputRows': 258,\n",
       "  'inputRowsPerSecond': 179.91631799163181,\n",
       "  'processedRowsPerSecond': 602.803738317757,\n",
       "  'durationMs': {'addBatch': 250,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 32,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 428,\n",
       "   'walCommit': 84},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8391}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8649}},\n",
       "    'numInputRows': 258,\n",
       "    'inputRowsPerSecond': 179.91631799163181,\n",
       "    'processedRowsPerSecond': 602.803738317757}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:29.309Z',\n",
       "  'batchId': 30,\n",
       "  'numInputRows': 152,\n",
       "  'inputRowsPerSecond': 354.31235431235433,\n",
       "  'processedRowsPerSecond': 183.13253012048193,\n",
       "  'durationMs': {'addBatch': 126,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 61,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 830,\n",
       "   'walCommit': 90},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8649}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 8801}},\n",
       "    'numInputRows': 152,\n",
       "    'inputRowsPerSecond': 354.31235431235433,\n",
       "    'processedRowsPerSecond': 183.13253012048193}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:30.139Z',\n",
       "  'batchId': 31,\n",
       "  'numInputRows': 222,\n",
       "  'inputRowsPerSecond': 267.4698795180723,\n",
       "  'processedRowsPerSecond': 497.7578475336323,\n",
       "  'durationMs': {'addBatch': 188,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 36,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 446,\n",
       "   'walCommit': 139},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 8801}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9023}},\n",
       "    'numInputRows': 222,\n",
       "    'inputRowsPerSecond': 267.4698795180723,\n",
       "    'processedRowsPerSecond': 497.7578475336323}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:30.586Z',\n",
       "  'batchId': 32,\n",
       "  'numInputRows': 88,\n",
       "  'inputRowsPerSecond': 196.86800894854585,\n",
       "  'processedRowsPerSecond': 341.08527131782944,\n",
       "  'durationMs': {'addBatch': 104,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 26,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 258,\n",
       "   'walCommit': 79},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9023}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9111}},\n",
       "    'numInputRows': 88,\n",
       "    'inputRowsPerSecond': 196.86800894854585,\n",
       "    'processedRowsPerSecond': 341.08527131782944}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:30.844Z',\n",
       "  'batchId': 33,\n",
       "  'numInputRows': 96,\n",
       "  'inputRowsPerSecond': 372.09302325581393,\n",
       "  'processedRowsPerSecond': 111.49825783972126,\n",
       "  'durationMs': {'addBatch': 106,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 34,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 861,\n",
       "   'walCommit': 248},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9111}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9207}},\n",
       "    'numInputRows': 96,\n",
       "    'inputRowsPerSecond': 372.09302325581393,\n",
       "    'processedRowsPerSecond': 111.49825783972126}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:31.705Z',\n",
       "  'batchId': 34,\n",
       "  'numInputRows': 253,\n",
       "  'inputRowsPerSecond': 293.8443670150987,\n",
       "  'processedRowsPerSecond': 615.5717761557178,\n",
       "  'durationMs': {'addBatch': 203,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 38,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 411,\n",
       "   'walCommit': 94},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9207}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9460}},\n",
       "    'numInputRows': 253,\n",
       "    'inputRowsPerSecond': 293.8443670150987,\n",
       "    'processedRowsPerSecond': 615.5717761557178}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.117Z',\n",
       "  'batchId': 35,\n",
       "  'numInputRows': 112,\n",
       "  'inputRowsPerSecond': 271.84466019417476,\n",
       "  'processedRowsPerSecond': 346.7492260061919,\n",
       "  'durationMs': {'addBatch': 150,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 58,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 323,\n",
       "   'walCommit': 64},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9460}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9572}},\n",
       "    'numInputRows': 112,\n",
       "    'inputRowsPerSecond': 271.84466019417476,\n",
       "    'processedRowsPerSecond': 346.7492260061919}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.441Z',\n",
       "  'batchId': 36,\n",
       "  'numInputRows': 107,\n",
       "  'inputRowsPerSecond': 330.2469135802469,\n",
       "  'processedRowsPerSecond': 502.3474178403756,\n",
       "  'durationMs': {'addBatch': 87,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 24,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 213,\n",
       "   'walCommit': 51},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9572}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9679}},\n",
       "    'numInputRows': 107,\n",
       "    'inputRowsPerSecond': 330.2469135802469,\n",
       "    'processedRowsPerSecond': 502.3474178403756}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.655Z',\n",
       "  'batchId': 37,\n",
       "  'numInputRows': 61,\n",
       "  'inputRowsPerSecond': 285.04672897196264,\n",
       "  'processedRowsPerSecond': 253.11203319502076,\n",
       "  'durationMs': {'addBatch': 93,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 39,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 241,\n",
       "   'walCommit': 66},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9679}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9740}},\n",
       "    'numInputRows': 61,\n",
       "    'inputRowsPerSecond': 285.04672897196264,\n",
       "    'processedRowsPerSecond': 253.11203319502076}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:32.897Z',\n",
       "  'batchId': 38,\n",
       "  'numInputRows': 46,\n",
       "  'inputRowsPerSecond': 190.0826446280992,\n",
       "  'processedRowsPerSecond': 174.90494296577947,\n",
       "  'durationMs': {'addBatch': 85,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 22,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 263,\n",
       "   'walCommit': 46},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9740}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9786}},\n",
       "    'numInputRows': 46,\n",
       "    'inputRowsPerSecond': 190.0826446280992,\n",
       "    'processedRowsPerSecond': 174.90494296577947}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:33.160Z',\n",
       "  'batchId': 39,\n",
       "  'numInputRows': 62,\n",
       "  'inputRowsPerSecond': 235.74144486692015,\n",
       "  'processedRowsPerSecond': 89.72503617945009,\n",
       "  'durationMs': {'addBatch': 101,\n",
       "   'getBatch': 1,\n",
       "   'getEndOffset': 0,\n",
       "   'queryPlanning': 26,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 690,\n",
       "   'walCommit': 475},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9786}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 9848}},\n",
       "    'numInputRows': 62,\n",
       "    'inputRowsPerSecond': 235.74144486692015,\n",
       "    'processedRowsPerSecond': 89.72503617945009}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:33.851Z',\n",
       "  'batchId': 40,\n",
       "  'numInputRows': 152,\n",
       "  'inputRowsPerSecond': 219.97105643994212,\n",
       "  'processedRowsPerSecond': 445.7478005865102,\n",
       "  'durationMs': {'addBatch': 100,\n",
       "   'getBatch': 0,\n",
       "   'getEndOffset': 1,\n",
       "   'queryPlanning': 29,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 341,\n",
       "   'walCommit': 44},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 9848}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'numInputRows': 152,\n",
       "    'inputRowsPerSecond': 219.97105643994212,\n",
       "    'processedRowsPerSecond': 445.7478005865102}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:34.192Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 1,\n",
       "   'triggerExecution': 1},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}},\n",
       " {'id': '343accf0-e41e-4888-a9fd-bbf925627256',\n",
       "  'runId': '6f82bb97-d49e-402d-84a1-62e8b387a9fc',\n",
       "  'name': None,\n",
       "  'timestamp': '2021-03-22T20:28:44.196Z',\n",
       "  'batchId': 41,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'getEndOffset': 0,\n",
       "   'setOffsetRange': 2,\n",
       "   'triggerExecution': 2},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'KafkaV2[Subscribe[input_alexander.okhilkov]]',\n",
       "    'startOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'endOffset': {'input_alexander.okhilkov': {'0': 10000}},\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'org.apache.spark.sql.kafka010.KafkaSourceProvider@1d03e1f'}}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    for s in streams:\n",
    "        desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "        s.stop()\n",
    "        print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

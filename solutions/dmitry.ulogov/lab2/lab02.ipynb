{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   69519728 2021-02-27 21:58 /labs/slaba02/DO_record_per_line.json\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba02/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 28153\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.json('/labs/slaba02/DO_record_per_line.json')\n",
    "print('Data size: {}'. format(data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StopWordsRemover\n",
    "tokenizer = Tokenizer(inputCol=\"desc\", outputCol=\"words\")\n",
    "data = tokenizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|               words|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|[this, course, in...|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|[this, online, co...|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|[this, course, is...|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|[we, live, in, a,...|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|[this, self-paced...|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol='words', outputCol='words_clean')\n",
    "data_removed = remover.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = HashingTF(inputCol=\"words_clean\", outputCol=\"features\", numFeatures=10000)\n",
    "data = ht.transform(data_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cache()\n",
    "idf = IDF(inputCol='features', outputCol='idf_features').fit(data)\n",
    "tfidf = idf.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"idf_features\", outputCol=\"normFeatures\", p=1.0)\n",
    "normalized_data = normalizer.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|               words|         words_clean|            features|        idf_features|        normFeatures|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|[this, course, in...|[course, introduc...|(10000,[36,42,63,...|(10000,[36,42,63,...|(10000,[36,42,63,...|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|[this, online, co...|[online, course, ...|(10000,[32,222,29...|(10000,[32,222,29...|(10000,[32,222,29...|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|[this, course, is...|[course, taught, ...|(10000,[30,41,246...|(10000,[30,41,246...|(10000,[30,41,246...|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|[we, live, in, a,...|[live, digitally,...|(10000,[493,721,8...|(10000,[493,721,8...|(10000,[493,721,8...|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|[this, self-paced...|[self-paced, cour...|(10000,[32,65,115...|(10000,[32,65,115...|(10000,[32,65,115...|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalized_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter by courses to make recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 28153\n",
      "Data size: 6\n",
      "Data size: 28147\n"
     ]
    }
   ],
   "source": [
    "print('Data size: {}'. format(normalized_data.count()))\n",
    "selected_courses = normalized_data.where(\"id in (23126, 21617, 16627, 11556, 16704, 13702)\")\n",
    "print('Data size: {}'. format(selected_courses.count()))\n",
    "other_courses = normalized_data.where(\"id not in (23126, 21617, 16627, 11556, 16704, 13702)\")\n",
    "print('Data size: {}'. format(other_courses.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Языки курсов\n",
    "\n",
    "- es\n",
    "- ru\n",
    "- en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es: 1372\n",
      "ru: 1229\n",
      "en: 24551\n"
     ]
    }
   ],
   "source": [
    "other_courses_es = other_courses.filter(other_courses.lang == 'es')\n",
    "other_courses_ru = other_courses.filter(other_courses.lang == 'ru')\n",
    "other_courses_en = other_courses.filter(other_courses.lang == 'en')\n",
    "print('es: {}'.format(other_courses_es.count()))\n",
    "print('ru: {}'.format(other_courses_ru.count()))\n",
    "print('en: {}'.format(other_courses_en.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 23126 - en\n",
    "- 21617 - en\n",
    "- 16627 - es\n",
    "- 11556 - es\n",
    "- 16704 - ru\n",
    "- 13702 - ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sparse vectors to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_id_lst = selected_courses.select('id').rdd.map(lambda x: x[0]).collect()\n",
    "sel_id_features = selected_courses.select('normFeatures').rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_other_id_lst = other_courses_en.select('id').rdd.map(lambda x: x[0]).collect()\n",
    "en_other_id_features = other_courses_en.select('normFeatures').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "es_other_id_lst = other_courses_es.select('id').rdd.map(lambda x: x[0]).collect()\n",
    "es_other_id_features = other_courses_es.select('normFeatures').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "ru_other_id_lst = other_courses_ru.select('id').rdd.map(lambda x: x[0]).collect()\n",
    "ru_other_id_features = other_courses_ru.select('normFeatures').rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cos(v1,v2):\n",
    "    try:\n",
    "        p = 2\n",
    "        return float(v1.dot(v2))/float(v1.norm(p)*v2.norm(p))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def related_courses(features_lang, id_lang, selected_id_ftr, selected_id):\n",
    "    \n",
    "    distances = []\n",
    "    for i in features_lang:\n",
    "        distances.append(sim_cos(selected_id_ftr, i))\n",
    "\n",
    "    dict_cosine = dict(zip(id_lang, distances))\n",
    "    val_list = list(dict_cosine.values())\n",
    "    key_list = list(dict_cosine.keys())\n",
    "    lst = sorted(dict_cosine.values(), reverse=True)[:10]\n",
    "    \n",
    "    course_recs = []\n",
    "    for i in lst:\n",
    "        position = val_list.index(i)\n",
    "        course_recs.append(key_list[position])\n",
    "    return selected_id, course_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English courses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23126"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_id_lst[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21617"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_id_lst[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23126 [13782, 13665, 24419, 20638, 2724, 25782, 2633, 2723, 13348, 15909]\n"
     ]
    }
   ],
   "source": [
    "id_23126, recs_23126 = related_courses(en_other_id_features, en_other_id_lst, sel_id_features[-1], sel_id_lst[-1])\n",
    "print(id_23126, recs_23126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_21617, recs_21617 = related_courses(en_other_id_features, en_other_id_lst, sel_id_features[-2], sel_id_lst[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spanish courses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11556"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_id_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16627"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_id_lst[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_11556, recs_11556 = related_courses(es_other_id_features, es_other_id_lst, sel_id_features[0], sel_id_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_16627, recs_16627 = related_courses(es_other_id_features, es_other_id_lst, sel_id_features[2], sel_id_lst[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Russian courses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16704"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_id_lst[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13702"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_id_lst[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_16704, recs_16704 = related_courses(ru_other_id_features, ru_other_id_lst, sel_id_features[3], sel_id_lst[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_13702, recs_13702 = related_courses(ru_other_id_features, ru_other_id_lst, sel_id_features[1], sel_id_lst[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = {str(id_23126): recs_23126,\n",
    "            str(id_21617): recs_21617,\n",
    "            str(id_16627): recs_16627,\n",
    "            str(id_11556): recs_11556,\n",
    "            str(id_16704): recs_16704, \n",
    "            str(id_13702): recs_13702\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23126': [13782, 13665, 24419, 20638, 2724, 25782, 2633, 2723, 13348, 15909],\n",
       " '21617': [21609,\n",
       "  21608,\n",
       "  21616,\n",
       "  21492,\n",
       "  21624,\n",
       "  21623,\n",
       "  21630,\n",
       "  21628,\n",
       "  21508,\n",
       "  21703],\n",
       " '16627': [11431, 12247, 13021, 25010, 11575, 5687, 5372, 12863, 9598, 22680],\n",
       " '11556': [16488, 13461, 468, 23357, 19330, 16929, 387, 10447, 11554, 9289],\n",
       " '16704': [1365, 20645, 1426, 1426, 8217, 1236, 1164, 1219, 8123, 875],\n",
       " '13702': [864, 1216, 7173, 1052, 8313, 17017, 19613, 21017, 17015, 8082]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('lab02.json', 'w') as fp:\n",
    "    json.dump(json_file, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put into server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/dmitry.ulogov\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/03/05 15:31:57 INFO fs.TrashPolicyDefault: Moved: 'hdfs://spark-de-master-1.newprolab.com:8020/user/dmitry.ulogov/lab02.json' to trash at: hdfs://spark-de-master-1.newprolab.com:8020/user/dmitry.ulogov/.Trash/Current/user/dmitry.ulogov/lab02.json\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm lab02.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwx------   - dmitry.ulogov dmitry.ulogov          0 2021-03-05 15:31 /user/dmitry.ulogov/.Trash\r\n",
      "drwxr-xr-x   - dmitry.ulogov dmitry.ulogov          0 2021-03-05 13:36 /user/dmitry.ulogov/.sparkStaging\r\n",
      "-rw-r--r--   3 dmitry.ulogov dmitry.ulogov         84 2021-02-26 21:44 /user/dmitry.ulogov/lab01.json\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/dmitry.ulogov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -put lab02.json /user/dmitry.ulogov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwx------   - dmitry.ulogov dmitry.ulogov          0 2021-03-05 15:31 /user/dmitry.ulogov/.Trash\r\n",
      "drwxr-xr-x   - dmitry.ulogov dmitry.ulogov          0 2021-03-05 13:36 /user/dmitry.ulogov/.sparkStaging\r\n",
      "-rw-r--r--   3 dmitry.ulogov dmitry.ulogov         84 2021-02-26 21:44 /user/dmitry.ulogov/lab01.json\r\n",
      "-rw-r--r--   3 dmitry.ulogov dmitry.ulogov        458 2021-03-05 15:32 /user/dmitry.ulogov/lab02.json\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/dmitry.ulogov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwxr-xr-x   - dmitry.ulogov dmitry.ulogov          0 2021-03-04 22:22 .sparkStaging\r\n",
      "-rw-r--r--   3 dmitry.ulogov dmitry.ulogov         84 2021-02-26 21:44 lab01.json\r\n",
      "-rw-r--r--   3 dmitry.ulogov dmitry.ulogov        419 2021-03-04 22:52 lab02.json\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls #/share/submission-files/slaba02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 items\r\n",
      "-rw-r--r--   3 hdfs hdfs       6750 2020-09-05 20:38 /labs/laba01/ml-100k/README\r\n",
      "-rw-r--r--   3 hdfs hdfs        716 2020-09-05 20:38 /labs/laba01/ml-100k/allbut.pl\r\n",
      "-rw-r--r--   3 hdfs hdfs        643 2020-09-05 20:38 /labs/laba01/ml-100k/mku.sh\r\n",
      "-rw-r--r--   3 hdfs hdfs    1979173 2020-09-05 20:38 /labs/laba01/ml-100k/u.data\r\n",
      "-rw-r--r--   3 hdfs hdfs        202 2020-09-05 20:38 /labs/laba01/ml-100k/u.genre\r\n",
      "-rw-r--r--   3 hdfs hdfs         36 2020-09-05 20:38 /labs/laba01/ml-100k/u.info\r\n",
      "-rw-r--r--   3 hdfs hdfs     236344 2020-09-05 20:38 /labs/laba01/ml-100k/u.item\r\n",
      "-rw-r--r--   3 hdfs hdfs        193 2020-09-05 20:38 /labs/laba01/ml-100k/u.occupation\r\n",
      "-rw-r--r--   3 hdfs hdfs      22628 2020-09-05 20:38 /labs/laba01/ml-100k/u.user\r\n",
      "-rw-r--r--   3 hdfs hdfs    1586544 2020-09-05 20:38 /labs/laba01/ml-100k/u1.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     392629 2020-09-05 20:38 /labs/laba01/ml-100k/u1.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1583948 2020-09-05 20:38 /labs/laba01/ml-100k/u2.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     395225 2020-09-05 20:38 /labs/laba01/ml-100k/u2.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1582546 2020-09-05 20:38 /labs/laba01/ml-100k/u3.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     396627 2020-09-05 20:38 /labs/laba01/ml-100k/u3.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1581878 2020-09-05 20:38 /labs/laba01/ml-100k/u4.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     397295 2020-09-05 20:38 /labs/laba01/ml-100k/u4.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1581776 2020-09-05 20:38 /labs/laba01/ml-100k/u5.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     397397 2020-09-05 20:38 /labs/laba01/ml-100k/u5.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1792501 2020-09-05 20:38 /labs/laba01/ml-100k/ua.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     186672 2020-09-05 20:38 /labs/laba01/ml-100k/ua.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1792476 2020-09-05 20:38 /labs/laba01/ml-100k/ub.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     186697 2020-09-05 20:38 /labs/laba01/ml-100k/ub.test\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/laba01/ml-100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"ZK Spark RDD app\") \n",
    "\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"ZK Spark RDD app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/labs/laba01/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['196\\t242\\t3\\t881250949',\n",
       " '186\\t302\\t3\\t891717742',\n",
       " '22\\t377\\t1\\t878887116',\n",
       " '244\\t51\\t2\\t880606923',\n",
       " '166\\t346\\t1\\t886397596',\n",
       " '298\\t474\\t4\\t884182806',\n",
       " '115\\t265\\t2\\t881171488',\n",
       " '253\\t465\\t5\\t891628467',\n",
       " '305\\t451\\t3\\t886324817',\n",
       " '6\\t86\\t3\\t883603013']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['196', '242', '3', '881250949'],\n",
       " ['186', '302', '3', '891717742'],\n",
       " ['22', '377', '1', '878887116'],\n",
       " ['244', '51', '2', '880606923'],\n",
       " ['166', '346', '1', '886397596']]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splited = data.map(lambda x: x.split(\"\\t\"))\n",
    "data_splited.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"movie_id\", IntegerType()),\n",
    "    StructField(\"score\", IntegerType()),\n",
    "    StructField(\"timestamp\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+---------+\n",
      "|user_id|movie_id|score|timestamp|\n",
      "+-------+--------+-----+---------+\n",
      "|    196|     242|    3|881250949|\n",
      "|    186|     302|    3|891717742|\n",
      "|     22|     377|    1|878887116|\n",
      "|    244|      51|    2|880606923|\n",
      "|    166|     346|    1|886397596|\n",
      "+-------+--------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_splited = data_splited.map(lambda x: (int(x[0]), int(x[1]), int(x[2]), int(x[3])))\n",
    "df = spark.createDataFrame(data_splited, schema=schema)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, movie_id: int, score: int, ip: int]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+---------+\n",
      "|user_id|movie_id|score|       na|\n",
      "+-------+--------+-----+---------+\n",
      "|    186|     302|    3|891717742|\n",
      "|    191|     302|    4|891560253|\n",
      "|     49|     302|    4|888065432|\n",
      "|     54|     302|    4|880928519|\n",
      "|     62|     302|    3|879371909|\n",
      "+-------+--------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"movie_id = 302\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|movie_id|score|count|\n",
      "+--------+-----+-----+\n",
      "|       1|    1|    8|\n",
      "|       1|    2|   27|\n",
      "|       1|    3|   96|\n",
      "|       1|    4|  202|\n",
      "|       1|    5|  119|\n",
      "+--------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_grouped = df.groupby('movie_id', 'score').count().sort(\"movie_id\",\"score\")\n",
    "\n",
    "data_grouped.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------+\n",
      "|score|count_total|count_302|\n",
      "+-----+-----------+---------+\n",
      "|    1|       6110|        2|\n",
      "|    2|      11370|       10|\n",
      "|    3|      27145|       46|\n",
      "|    4|      34174|      119|\n",
      "|    5|      21201|      120|\n",
      "+-----+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,when,count,sum\n",
    "\n",
    "df2 = df.groupBy(\"score\").agg(\n",
    "    count(\"movie_id\").alias(\"count_total\"),\n",
    "    count(when(col(\"movie_id\") == 302,1)).alias(\"count_302\")) \\\n",
    "    .sort(\"score\")\n",
    "\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------------------+\n",
      "|hist_film            |hist_all                          |\n",
      "+---------------------+----------------------------------+\n",
      "|[46, 2, 119, 120, 10]|[6110, 11370, 34174, 27145, 21201]|\n",
      "+---------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (df2.agg(\n",
    "#     F.collect_set(\"count_302\").alias(\"hist_film\"),\n",
    "#     F.collect_list(\"count_total\").alias(\"hist_all\"))\n",
    "#   .show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------------------+\n",
      "|hist_film            |hist_all                          |\n",
      "+---------------------+----------------------------------+\n",
      "|[2, 10, 46, 119, 120]|[6110, 11370, 27145, 34174, 21201]|\n",
      "+---------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window.partitionBy().orderBy('score')\n",
    "\n",
    "sorted_list_df = df2.withColumn('hist_film', F.collect_list('count_302').over(w))\\\n",
    "        .withColumn('hist_all', F.collect_list('count_total').over(w))\\\n",
    "        .groupBy() \\\n",
    "        .agg(F.max('hist_film').alias('hist_film'), \\\n",
    "             F.max('hist_all').alias('hist_all') \\\n",
    "            )\n",
    "sorted_list_df.show(truncate=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sample = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sample = {\"hist_film\": sorted_list_df.first()['hist_film'], \"hist_all\": sorted_list_df.first()['hist_all']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hist_film': [2, 10, 46, 119, 120],\n",
       " 'hist_all': [6110, 11370, 27145, 34174, 21201]}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab01.json', 'w') as fp:\n",
    "    json.dump(dict_sample, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

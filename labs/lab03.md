## Лаба 3. Рекомендательная система видеоконтента с implicit feedback – Spark ML

#### Дедлайн

Понедельник, 15 марта, 23:59

#### Дедлайн Github

Четверг, 18 марта, 23:59

#### Задача

В вашем распоряжении имеется уже предобработанный и очищенный датасет с фактами покупок абонентами телепередач от компании E-Contenta. По доступным вам данным нужно предсказать вероятность покупки других передач этими, а, возможно, и другими абонентами. 
При решении задачи запрещено использовать библиотеки pandas, sklearn (кроме sklearn.metrics), xgboost и другие. 
Если scikit-learn (например, но и другие тоже) обернут в классы Transformer и Estimator, то их можно использовать.

#### Описание данных

Для выполнения работы вам следует взять все файлы из папки на HDFS `/labs/slaba03/`. 

Давайте посмотрим, что у нас есть:

```
$ hdfs dfs -ls /labs/slaba03/
Found 4 items
-rw-r--r--   3 hdfs hdfs   91066524 2019-03-17 21:07 /labs/slaba03/laba03_items.csv
-rw-r--r--   3 hdfs hdfs   29965581 2019-03-17 21:07 /labs/slaba03/laba03_test.csv
-rw-r--r--   3 hdfs hdfs   74949368 2019-03-17 21:07 /labs/slaba03/laba03_train.csv
-rw-r--r--   3 hdfs hdfs  871302535 2019-03-17 21:07 /labs/slaba03/laba03_views_programmes.csv
```

- В `laba03_train.csv` содержатся факты покупки (колонка `purchase`) пользователями (колонка `user_id`) телепередач (колонка `item_id`). Такой формат файла вам уже знаком.

- `laba03_items.csv` — дополнительные данные по items. В данном файле много лишней или ненужной информации, так что задача её фильтрации и отбора ложится на вас. Поля в файле, на которых хотелось бы остановиться:

  - `item_id` — primary key. Соответствует `item_id` в предыдущем файле.
  - `content_type` — тип телепередачи (`1` — платная, `0` — бесплатная). Вас интересуют платные передачи.
  - `title` — название передачи, текстовое поле.
  - `year` — год выпуска передачи, число.
  - `genres` — поле с жанрами передачи, разделёнными через запятую.

- `laba03_test.csv` — тестовый датасет без указанного целевого признака `purchase`, который вам и предстоит предсказать.

- Дополнительный файл `laba03_views_programmes.csv` по просмотрам передач с полями:

  - `ts_start` — время начала просмотра.

  - `ts_end` — время окончания просмотра.

  - `item_type` — тип просматриваемого контента:

    - `live` — просмотр "вживую", в момент показа контента в эфире.
    - `pvr` — просмотр в записи, после показа контента в эфире.

#### Результат

Предсказание целевой переменной "купит/не купит" — хорошо знакомая вам задача бинарной классификации. Поскольку нам важны именно вероятности отнесения пары `(пользователь, товар)` к классу "купит" (`1`), то, на самом деле, вы можете подойти к проблеме с разных сторон:

1. Как к разработке рекомендательной системы: рекомендовать пользователю `user_id` топ-N лучших телепередач, которые были найдены по методике user-user / item-item коллаборативной фильтрации.
2. Как к задаче факторизации матриц: алгоритмы SVD, ALS, FM/FFM.
3. Как просто к задаче бинарной классификации. У вас есть два датасета, которые можно каким-то образом объединить, дополнительно обработать и сделать предсказания классификаторами (Spark ML).
4. Как к задаче регрессии. Поскольку от вас требуется предсказать не факт покупки, а его *вероятность*, то можно перевести задачу в регрессионную и решать её соответствующим образом.

#### Советы

1. На качество прогноза в большей степени влияет _качество признаков_, которые вы сможете придумать из имеющихся данных, нежели выбор и _сложность алгоритма_.
2. Качество входных данных также имеет сильное значени. Существует фраза "garbage in – garbage out". Мусор на входе – мусор на выходе. Потратьте время на подготовку и предобработку данных.
Путь к успеху в третьей лабораторной:
1. Сосредоточьтесь на формировании следующих фичей: по файлу 
laba03_train.csv сформируйте признаки, характеризирующие как интенсивно
покупает пользователь и "покупаемость" item'ов
2. возьмите достаточно мощную модель (например GBTRegressor из pyspark'а)

#### Проверка

Эта лаба проходит в формате соревнования. Для вас оно начинается, когда вы успешно пройдёте минимальный порог  — **AUC должен составить не менее 0.79**. После этого вы увидите лидерборд и сможете следить за результатами других участников.

Как уже было сказано, мы будем оценивать ваш алгоритм по метрике ROC AUC. Чекеру требуются *вероятности* в диапазоне `[0.0, 1.0]` отнесения пары `(пользователь, товар)` в тестовой выборке к классу "1" (купит).

**Важно!** Для точной проверки не забудьте отсортировать полученный файл по возрастанию идентификаторов пользователей (`user_id`), а затем — по возрастанию идентификаторов передач (`item_id`).
```
,user_id,item_id,purchase
0,1654,336,0.021805684684958027
1,1654,678,0.021805684684958027
2,1654,691,0.021805684684958027
3,1654,696,0.021805684684958027
...
```



Результат следует сохранить в файл `lab03.csv` в своей домашней директории.

Проверка осуществляется автоматическим скриптом из [Личного кабинета](http://lk-spark.newprolab.com/lab/slaba03).

Обязательное условие зачета лабораторной работы – это выкладка после дедлайна лабы своего решения в репозиторий через pull-request. Как это сделать, можно прочитать [здесь](/git.md). Если будут вопросы – спрашивайте в Slack.
